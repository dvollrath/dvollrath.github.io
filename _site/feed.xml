<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <link>http://localhost:4000/</link>
    <description></description>
    <pubDate>Mon, 09 Jan 2023 16:30:15 -0600</pubDate>
    
      <item>
        <title>The Slowdown in Europe via Human Capital</title>
        <link>http://localhost:4000/feed/2023/01/05/Europe-HC.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2023/01/05/Europe-HC.html</guid>
        <description>&lt;p&gt;This is the second part of a deep(ish) dive into the growth slowdown in Europe. The &lt;a href=&quot;https://growthecon.com/feed/2022/12/29/Europe-Grown.html&quot;&gt;first installment&lt;/a&gt; looked at the timing and basics of the slowdown. This post is going to dig into the role of human capital.&lt;/p&gt;

&lt;h3 id=&quot;hit-the-reset-button&quot;&gt;Hit the reset button&lt;/h3&gt;
&lt;p&gt;Before moving onto human capital in detail, I want to back up and revisit the basic story behind the slowdown. While the first post had some fun figures that I referenced to make some general statements about the origins of the slowdown, reading it back I was unhappy at how ambiguous I was about those statements. I want to put some harder numbers on things and make the cross-country comparisons more clear.&lt;/p&gt;

&lt;p&gt;I’m doing a basic breakdown of growth in GDP per capita according to the following&lt;/p&gt;

\[g_y = g_{Cap} + g_{Human} + g_{Prod},\]

&lt;p&gt;where $g_y$ is the growth rate of GDP per capita, $g_{Cap}$ is the contribution of physical capital accumulation, $g_{Human}$ the contribution of human capital, and $g_{Prod}$ the contribution of productivity.&lt;/p&gt;

&lt;p&gt;On top of that, I’m now going to add a further breakdown of human capital growth:&lt;/p&gt;

\[g_{Human} = g_{Educ} + g_{Hours} + g_{LFP} + g_{Aging}.\]

&lt;p&gt;I’ll describe the data behind those four components of human capital later in the post. For now, $g_{Educ}$ is the contribution of growth in years of education (and presumably in skills/effectiveness of labor). $g_{Hours}$ is the contribution of changes in average hours worked. $g_{LFP}$ is the contribution of changes in labor force participation, meaning the number of workers relative to the working-age population. $g_{Aging}$ is the contribution of changes in the size of the working-age population relative to the population as a whole. When I say “contribution”, I mean the amount of growth in GDP per capita that can be attributed to that specific component.&lt;/p&gt;

&lt;p&gt;This means that overall GDP per capita growth can be broken down as&lt;/p&gt;

\[g_y = g_{Cap} + g_{Prod} + g_{Educ} + g_{Hours} + g_{LFP} + g_{Aging}.\]

&lt;p&gt;Roughly speaking, how important was each component to the slowdown in growth? To answer that I have to be more specific about timing. I’m going to compare the growth rate of GDP per capita in the 20-year period from 1999-2019 to the growth rate in the 20-year period from 1979-1999. This cutoff is arbitrary, yes. I wanted to avoid anything that had an endpoint during the financial crisis (2009-2010). And when you see the data, this breakdown in time period seems to show a similar slowdown across countries.&lt;/p&gt;

&lt;p&gt;The data I’m going to show you is the &lt;em&gt;difference&lt;/em&gt; in growth rates between those two 20-year windows of time. For GDP per capita, for example, I’m calculating this:&lt;/p&gt;

\[\Delta g_y = g_{y,1999-2019} - g_{y,1979-1999}\]

&lt;p&gt;where $g_{y,1999-2019}$ is the average annual growth rate of GDP per capita from 1999-2019, and a similar definition holds for $g_{y,1979-1999}$ from 1979-1999. Because we observe a slowdown, that $\Delta g_y$ number is going to be negative; the growth rate fell. For each of the components of growth (physical capital, etc..) I’m going to calculate a similar $\Delta$ term for their growth rate.&lt;/p&gt;

&lt;p&gt;Here’s the data for the set of European countries and the US that I referenced in the first post. All the numbers here are in percentage point terms.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;800&quot; height=&quot;300&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/tab_europe.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;For Germany (DEU), this says that the growth rate fell by 0.67 percentage points from 1979-1999 to 1999-2019. The remaining terms in the table show where that -0.67 came from. For each of the remaining terms, you can interpret them as “how much would growth have changed from 1979-1999 to 1999-2019 if this was the only thing that changed”.&lt;/p&gt;

&lt;p&gt;You also have to be careful in reading this table. The numbers here are not growth rates, they are &lt;em&gt;changes&lt;/em&gt; in growth rates. In Germany, for example, the contribution of productivity growth is negative 1.32 percentage points. This does not imply that productivity in Germany fell. It means that the &lt;em&gt;growth rate&lt;/em&gt; of productivity was lower in 1999-2019 than in 1979-1999. Productivity kept rising in Germany from 1999-2019, it just didn’t rise as fast as it once did.&lt;/p&gt;

&lt;p&gt;Keep this in mind for all the different components of growth. A negative for education doesn’t mean education &lt;em&gt;fell&lt;/em&gt;. It means the &lt;em&gt;growth rate&lt;/em&gt; of education fell. Education (and presumably skills) kept rising, just at a lower rate than before. A positive for hours doesn’t mean average hours worked went &lt;em&gt;up&lt;/em&gt;, it means that the growth rate of hours was higher (i.e. less negative) from 1999-2019 than it was from 1979-1999. Big positives in LFP don’t necessarily mean LFP itself went up, they mean that the growth rate of LFP was higher in 1999-2019 (which could mean LFP grew or just shrunk at a slower rate).&lt;/p&gt;

&lt;h3 id=&quot;differences-in-the-us-and-europe&quot;&gt;Differences in the US and Europe&lt;/h3&gt;
&lt;p&gt;Maybe the most interesting thing to do with the above table is compare the US and Europe. Doing so is what motivate this post and the planned follow-up on productivity. If you look down the first column, you’ll see that Europe and the US had similar growth slowdowns in terms of size. Italy and Spain had more harsh slowdowns, Germany less so. But everyone is roughly in the same boat.&lt;/p&gt;

&lt;p&gt;Physical capital’s contribution and education’s contribution look kinda-sorta the same in Europe and the US. It’s the other terms that are quite different.&lt;/p&gt;

&lt;p&gt;For the US, the slowdown is mainly a story of labor force particiation, demographics, and hours. The decline in productivity growth in the US is minor by comparison. In &lt;a href=&quot;https://amzn.to/3C5J4Ry&quot;&gt;Fully Grown&lt;/a&gt; I zeroed in on the demographics, in part because I was combining the LFP and Aging components. The data in the table here is also a little different than what I used in Fully Grown (Penn World Tables versus national accounts) so there are going to be slight discrepancies.&lt;/p&gt;

&lt;p&gt;In contrast, the story of the slowdown in Europe is about productivity growth and aging, but with substantial offsets coming from LFP and hours. Changes in labor market activity, in general, prevented the slowdown in Europe from being even more devastating.&lt;/p&gt;

&lt;p&gt;To give you some idea of how important this offset was, consider a few simple counterfactuals. First, what is the “worst case” growth slowdown for Europe? That would be if the declines due to productivity growth and aging occurred, but the growth contribution of LFP and hours did not change at all (i.e. kept growing at the 1979-1999 rate). Second, what is the “best case” growth slowdown for Europe? That would be if the increases in growth due to LFP and hours occurred, but the growth contribution of productivity and aging did not change at all (i.e. kept growing at the 1979-1999 rate). In both worst and best case scenario, I’ll leave the growth rate change due to physical capital and education as they are.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;800&quot; height=&quot;300&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/tab_alt_europe.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;The table gives you the consequences. The first column is the actual slowdown in growth in each country (e.g. -0.67 percentage points in Germany). The worst case scenario is &lt;em&gt;very bad&lt;/em&gt; compared to the actual slowdown. For Germany, rather than losing 0.67 percentage points off the growth rate of GDP per capita, they would have lost 2.55 percentage points off the growth rate because of productivity and aging alone, without labor force changes to offset them. The growth rate of GDP per capita from 1999-2019 in Germany was actually 1.20 percent per year (0.67 pp lower than the 1.87 percent per year from 1979-1999). In the worst case it would have been &lt;em&gt;negative&lt;/em&gt; 0.68 percent per year. Living standards in Germany would have literally fallen in the worst case.&lt;/p&gt;

&lt;p&gt;In the best case, Germany’s growth rate would have &lt;em&gt;gone up&lt;/em&gt; by 1.31 percentage points if only the labor force changes occurred. Rather than 1.20 percent growth from 1999-2019, it would have been 3.18 percent growth in GDP per capita, which is a huge number for a developed country.&lt;/p&gt;

&lt;p&gt;The point is that the gross changes in the componenents of growth (productivity, labor force participation, etc..) were massive in Europe between 1979-1999 and 1999-2019. They turned out to offset each other in many cases, so that the net change in the growth rate of GDP per capita was “only” on the order of minus 1 percentage point for most of Europe.&lt;/p&gt;

&lt;p&gt;For this post, I’m going to take this breakdown of things as given. But I’ll be honest, the gross movements here are so big, and they offset in just the right way, that I’m nervous this is some kind of data error. I can’t find anything obviously wrong in the code or data I’m using, but it still smells a little off to me. Code and data are linked in the last section of the post, so if someone wants to take a crack at things, be my guest.&lt;/p&gt;

&lt;h3 id=&quot;seeing-the-changes-over-time&quot;&gt;Seeing the changes over time&lt;/h3&gt;
&lt;p&gt;Given the importance of the human capital elements in both driving (aging) and offsetting (LFP, hours) the growth slowdown, let me give you some more detailed evidence on their growth contributions over time. As I said earlier, I’ll look at productivity in a later post.&lt;/p&gt;

&lt;p&gt;First up is the growth rate of labor force participation, $g_{LFP}$. The figure shows the 10-year backward looking average of this for each country.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_LW.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;Consistent with the table, if you look at the period from around 1980 to 2000 these numbers tends to be just at or below zero, so that $g_{LFP} \approx 0$. From around 2000 to 2019 it seems to be that $g_{LFP}$ is around 0.005 to 0.01, or 0.5%-1.0%. Thus the difference in growth rates is around 0.5-1.0 percentage points. This is true even though the financial crisis knocks down $g_{LFP}$ around 2009 for everyone.&lt;/p&gt;

&lt;p&gt;Thinking about this in growth rates can be kind of annoying, so here’s a figure with the level of $LFP$ - employees divided by working-age population - for each country over time. No rolling growth rates, no nothing, just the actual meaures of $LFP$ I’m using.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_LWlevel.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;You can see the dip from 1980 to about 2000, and then the steady rise from 2000 to 2019. It’s not massive changes in the ratio we’re talking about here. But a rough sketch would be that $LFP$ fell from about 0.75 in the late 1970s to about 0.65 by the late 1990s, and then has risen back to about 0.75 by 2019. Thus the positive contribution to growth of $g_{LFP}$ that offsets the growth slowdown.&lt;/p&gt;

&lt;p&gt;If instead you look at the graph for aging, $g_{Aging}$, you get a tighter picture. Recall that $g_{Aging}$ is measuring the growth rate of the ratio of working-age population to all population.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_WN.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;Here there is a distinct “hump” (especially for Germany) in the period from 1980 to 2000, and then a decline after 2000, and the actual growth rate becomes negative. This generates the negative effets of aging on the growth slowdown seen in the table above. One thing to note here is that the US is not quite like the other countries. The US has a more substantial early bulge in the 1960s (the Baby Boom) and a less pronounced dip later on. In the US the pure effect of aging isn’t really negative until quite recently, but in Europe the negative effects kicked in closer to 2000.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_WNlevel.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;This is another case where the actual level is interesting. The figure above plots the actual ratio of working-age population to total population over time for all the countries. It is …. boring? You can see the rise from mid-1970s to mid-1990s, and then the decline. It doesn’t look very dramatic here, but nevertheless the change in growth rates contributed in a significant way to the growth slowdown. Just to give you a sense of the effect size here, consider the following stylized example. Let’s say in 2000 63% of your population was of working age, but by 2019 it was only 60%, something consistent with this figure. By itself, how much lower would this make GDP per capita? Well, the ratio of potential workers to all population is only 60/63 = 0.95, or 95% of what it was before. So GDP per capita - holding everything else constant - would in 2019 be only 95% of what is was in 2000. That translates to a drag on the growth rate of about -0.003, or about 3/10ths of one percent per year. Doesn’t seem like a lot? Remember that the growth rate on average fell by about 8/10ths of one percentage point during the slowdown. 3/10ths is a pretty big share of 8/10ths.&lt;/p&gt;

&lt;p&gt;Last, for hours worked let’s just jump right to the level. The figure shows average (annual) hours worked by country over time. From 1950 right through about 1990 it declines steadily. Let’s call it about 2000-2200 to about 1600-1800. And after 1990 it continues to decline in most countries, but at a much slower rate. The curves here are almost flattening out. The arrest of the decline in hours helped offset the negative effets of aging and productivity during the slowdown.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_avhlevel.html&quot;&gt;
&lt;/iframe&gt;

&lt;h3 id=&quot;labor-markets-saved-europe&quot;&gt;Labor markets saved Europe?&lt;/h3&gt;
&lt;p&gt;What’s the conclusion? What I’d say this data tell us is that labor market changes, particularly in labor force participation, were crucial in offsetting an even worse growth slowdown in Europe. Productivity growth fell a lot, and the aging of the population also pushed towards a substantial drop in the growth rate of GDP per capita. Increases in labor force participation and the levelling out of hours worked arrested some of the drop. The slowdown in Europe, in that sense, is due to productivity and aging. The net effect, however, was not as bad as it could have been because of labor market changes.&lt;/p&gt;

&lt;p&gt;The story for Europe is also quite different than for the US. In the US the drop in productivity growth was almost inconsequential. But hours and labor force participation helped contribute to the slowdown, along with aging. If anything, I’d have to revisit Fully Grown with less attention to the aging itself, and more attention to the changes in LFP.&lt;/p&gt;

&lt;p&gt;Regardless, you cannot simply port the argument in Fully Grown over to Europe. I’d still argue that the aging aspect of the European slowdown was to some extent a consequence of successes like contraception and women’s rights. But the productivity slowdown in Europe is way beyond what was seen in the US, and could well be something more “wrong” with the economies. As promised, I’ll try to tackle the productivity stuff in the next post.&lt;/p&gt;

&lt;h3 id=&quot;data-code-and-that-stuff&quot;&gt;Data, Code, and that stuff&lt;/h3&gt;
&lt;p&gt;As in the initial post, most data comes from the &lt;a href=&quot;https://www.rug.nl/ggdc/productivity/pwt/?lang=en&quot;&gt;Penn World Tables&lt;/a&gt;, and I access that directly using an R package. The script that produces all the figures and tables in the post is &lt;a href=&quot;/assets/2022-12-31-OECD-Europe.r&quot;&gt;here&lt;/a&gt;. What’s new in that script is that I pull in OECD data on age structure to do the calculations involving working-age population. The OECD data is stored in a CSV file &lt;a href=&quot;/assets/data/OECD_pop.csv&quot;&gt;here&lt;/a&gt;. I used a CSV because the OECD package in R takes a &lt;em&gt;long&lt;/em&gt; time to download. It means that to use the script you’ll have to edit the working directory to point to wherever you store the data file. The script was for my use, so caveat emptor.&lt;/p&gt;

&lt;p&gt;The basic accounting I do is the same as in the prior post. What I added here was the breakdown in human capital. In the prior post I referred to human capital per capita as $h$. Here the definition of that is:&lt;/p&gt;

\[h = e^{\phi S} \frac{Hours}{Employ}\frac{Employ}{WorkAge}\frac{WorkAge}{Pop}.\]

&lt;p&gt;The first term captures the effects of average years of schooling, $S$, through a Mincerian function, $e^{\phi S}$, where $\phi$ is the return to a year of schooling. I am just pulling this $e^{\phi S}$ term directly from the PWT. I’m simplifying my explanation of what they actually do, which involves different returns for different years of education. &lt;a href=&quot;https://www.rug.nl/ggdc/docs/human_capital_in_pwt_90.pdf&quot;&gt;Their documentation&lt;/a&gt; gives you the full details.&lt;/p&gt;

&lt;p&gt;Hours/employee is directly from the PWT. The numerator $Employ$ is the number of employees from the PWT, while $WorkAge$ is the number of 20-64 year olds reported by the OECD. $Pop$ is from the PWT. So one possible error in my calculations is that the two sources are distinct. However, the numbers I get for $Employ/WorkAge$ and $WorkAge/Pop$ are reasonable compared to other sources, so I’m pretty okay with that.&lt;/p&gt;

</description>
        <pubDate>Thu, 05 Jan 2023 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>Fully Grown - European Vacation!</title>
        <link>http://localhost:4000/feed/2022/12/29/Europe-Grown.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2022/12/29/Europe-Grown.html</guid>
        <description>&lt;p&gt;Before jumping into the proper post, some housekeeping. Thanks to a combination of Twitter’s situation and not missing Twitter while I took a hiatus this year, I really have no stake in staying over there. My account is still up, and for the time being I’ll keep the automated service that tweets out a link to my blog posts.&lt;/p&gt;

&lt;p&gt;However, my main online interactions will be via Mastodon at &lt;a href=&quot;https://econtwitter.net/@DietzVollrath&quot;&gt;@DietzVollrath@econtwitter.net&lt;/a&gt;, where the local econo-sphere has coalesced enough to make things worth following. I’ll link to any new blog posts over there as well.&lt;/p&gt;

&lt;p&gt;Does that mean I’m going to blog more regularly? As always, that’s the plan. By which I mean, “probably not”. But hope springs eternal.&lt;/p&gt;

&lt;p&gt;On with the show!&lt;/p&gt;

&lt;h3 id=&quot;growth-slowdowns&quot;&gt;Growth slowdowns&lt;/h3&gt;
&lt;p&gt;This post is something I’ve been thinking about for quite a while. In short, I want to do the same basic accounting for the growth slowdown in Europe that I did for the United States in my book, &lt;a href=&quot;https://amzn.to/3C5J4Ry&quot;&gt;Fully Grown&lt;/a&gt;. You, of course, already own multiple copies. But feel free to hit the Amazon page to get a “rescue present” for those friends of yours that assumed you &lt;em&gt;were&lt;/em&gt; on gift-giving terms, even though you thought you were &lt;em&gt;not&lt;/em&gt;. You can blame Amazon fulfillment and smooth over the whole awkward moment.&lt;/p&gt;

&lt;p&gt;Anyway, back to growth slowdowns. For the United States I delineated between a relatively fast-growth 20th century and a slow-growth 21st century. GDP per capita in the US grew at about 2.25% per year in the 20th, and about 1% per year in the 21st. This slowdown appeared to predate the financial crisis, starting some time around the year 2000.&lt;/p&gt;

&lt;p&gt;Does this look the same for Europe? Basically, yes. But Europe has a little more muck to wade through to get there. To start, let’s look at the US and France. In the figure below I’ve plotted the 10-year backward-looking annualized growth rate in each year. For example, in 2000 it plots the annual growth rate from 1990 to 2000. The US is just above 2% throughout the 20th century, with a bulge of growth around the late 1960s and early 1970s, but then the slowdown starts in earnest in the 1998-2008 window. There is an uptick in growth in 2009-2019, partly because the start date there is in the midst of the financial crisis.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_france.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;How about France? The plot looks slightly different in the early years. Between 1960 and 1980 the growth rate was generally higher than in the US, at closer to 4%. And remember this is the growth rate of GDP per capita, so the growth rate of GDP was even higher. After 1980 France looks a lot like the US, trending along at (not quite) 2% until the early 2000s and then it experiences a growth slowdown of similar proportions.&lt;/p&gt;

&lt;p&gt;Before moving on, a few technical notes. First, assuming I’ve done this correctly, the figure should be interactive in the sense that you can hover over points and see the precise measurement. You can also use the buttons at the top right to zoom or capture a snapshot of the figure. The data is from the Penn World Tables and the code to generate the figure is linked in the last section of this post.&lt;/p&gt;

&lt;h3 id=&quot;convergence-versus-slowdown&quot;&gt;Convergence versus slowdown&lt;/h3&gt;
&lt;p&gt;Back to France. There are really two different slowdowns in the figure. There is the 1970 to 1980 slowdown, and then there is the 2000 to 2010 slowdown. As in Fully Grown, I’m only concerned with the latter slowdown. The earlier slowdown is basically a function of France converging back to its balanced growth path after World War II. This earlier slowdown in growth is, to me, almost entirely explicable in terms of simple Solow model dynamics. This is “catch-up” growth, equivalent to running a little faster than the pack for a while because you had to stop and tie your shoe. As you catch up with your group you naturally slow down to their steady pace.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;For Europe in general we get the same story. This second figure is the same as the first, only with additional countries added. The choice of countries is somewhat arbitrary, but in poking around in the data I didn’t find any substantial deviations from this figure. There is a general period of rapid growth early on (1960 to 1980) reflecting convergence, steady growth at around 2% per year (ish) from 1980 to 2000, and then the notable growth slowdown that this post is all about.&lt;/p&gt;

&lt;p&gt;One more technical note. If you double click on a country code in the legend it will display only that country’s growth rate. You can then single click on another country code to add that to the plot. Double click on a country code to add all countries back to the plot.&lt;/p&gt;

&lt;p&gt;If you play around in the figure, you’ll find a few variations on the France theme.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The United Kingdom doesn’t have the same “catch-up” growth rate from 1960 to 1980. It looks like the US in having about 2%-ish growth from 1960 to 2000.&lt;/li&gt;
  &lt;li&gt;Germany and Italy don’t have a distinct period of steady growth from 1980 to 2000. They both start with relatively high growth around 1960, and then this declines continuously from then until the early 2000s. Italy has a distinct drop in the growth rate, similar to France, but Germany just kind of drifts into the slowdown. My working assumption is that Germany and Italy aren’t fundamentally different than the others, but that they just don’t have the same distinct levelling off of growth in the late 20th century.&lt;/li&gt;
  &lt;li&gt;Spain and the Netherlands both have distinct rebounds around 1980 in their growth rates, growing in the high 2.7-3% per year rate for much of the 1990s prior to their own slowdowns in the early 2000s. Again, I’m not assuming this reflects a truly different mechanism. But they will show up with some interesting differences in the accounting.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;break-it-down&quot;&gt;Break it down&lt;/h3&gt;
&lt;p&gt;Alright, much of western Europe experienced a growth slowdown similar to the US some time around the early 2000s. As I did in Fully Grown, I want to account for the sources of this growth slowdown across the following categories: physical capital accumulation, human capital accumulation, and productivity growth.&lt;/p&gt;

&lt;p&gt;To refresh your memory, what I found in Fully Grown for the US was that the vast majority - if not all - of the slowdown could be attributed to a slowdown in human capital growth. That, in turn, was the result of a burst of human capital growth in the 20th century as Boomers entered the labor force, and a drag on human capital growth in the 21st century as Boomers started their exit from the labor force. One way of seeing the US experience is that 20th century growth was abnormally &lt;em&gt;high&lt;/em&gt; because the employment to population ratio rose quickly due to Boomers, and the slowdown is a natural reaction to that temporary boost working its way out of the system.&lt;/p&gt;

&lt;p&gt;Can we do the same thing for Europe? Sure. I break down the growth rate of GDP per capita, $g_y$, as follows:&lt;/p&gt;

\[g_y = g_{Cap} + g_{Human} + g_{Prod}.\]

&lt;p&gt;The last section of the post gives you all the math about how I got here. For now you’re just going to trust me. $g_{Cap}$ is the contribution of the growth rate of the capital/output ratio. For the growth nerds, this $g_{Cap}$ term includes the elasticity adjustment, and you can see the final section for the full math.&lt;/p&gt;

&lt;p&gt;$g_{Human}$ is the growth rate of human capital. This combines growth in average education, growth in average hours worked per week (which may be negative), and growth in the employment/population ratio (which could be due to demographics or policy). Why does that employment/population ratio matter? Because we’re looking at growth in GDP &lt;em&gt;per capita&lt;/em&gt;, or per person, and so it matters how many of those persons are actually working.&lt;/p&gt;

&lt;p&gt;The last term is $g_{Prod}$, the growth rate of productivity. Like all measures of productivity growth it is just whatever it has to be to make this equation work out. It’s a residual measure, although we might be able to say some smart things about it once we do some extra work. And there is nothing different about “productivity” from “total factor productivity” or “multi-factor productivity”. I’m just too lazy to write those longer phrases out.&lt;/p&gt;

&lt;p&gt;What does the data say? This first figure gives you the combined effect of physical capital on the growth rate of GDP per capita. I deliberately made the scale of the y-axis the same as in the prior figures on GDP per capita growth so you can get make a comparison. It is pretty obvious that the contribution of $g_{Cap}$ is small throughout, and small for all countries.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_cap.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;There is a subtle dynamic at work here if you look closely. In the 1960-1980 period the growth rate is slightly positive, contributing to growth in living standards. From 1980 to about 2000 it tends to be negative or close to zero. After 2000 it is slightly positive again. If anything, the slight uptick in physical capital growth is offsetting other forces pushing down on the growth rate. And one last note here is that this figure doesn’t indicate a lack of growth in physical capital. It indicates that physical capital did not grow fast &lt;em&gt;relative to GDP&lt;/em&gt;. Because new capital is itself part of GDP, you want to measure the contribution of capital relative to GDP. I explained this in more detail in, you guessed it, my book.&lt;/p&gt;

&lt;p&gt;On to human capital. In the figure below I plot $g_{Human}$. Here I had to tweak the axis scale because there are several cases where $g_{Human}$ becomes quite negative. Regardless, there are a few stories here that stand out to me.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_hc.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;First, the United States is weird. If you select just the US you’ll see the rough story I outlined above. Relatively high growth in human capital during the middle of the 20th century (adding about 1.5-2% per year to growth) and then distinct negatives in the 21st century, with only a recent uptick (again, probably an artefact of the financial crisis). No other European country, though, looks like this.&lt;/p&gt;

&lt;p&gt;Germany has &lt;em&gt;negative&lt;/em&gt; human capital growth throughout the 20th century that became positive around 2000, &lt;em&gt;offsetting&lt;/em&gt; the growth slowdown. France also had negative growth around 1960, and then human capital growth tracks right around zero from there forward. The UK kinda-sorta looks like the German situation. The Netherlands experiences significant human capital growth into the 1990s and then a slow decline afterwards.&lt;/p&gt;

&lt;p&gt;Italy has a massive burst of human capital growth in the late 20th century, and then it cratered later in the 21st century. Spain has a huge wave of human capital growth in the late 20th century which then drops off a cliff into the early 21st, providing at least some of the explanation for their slowdown. These two are probably the most similar to the US, but the scale and timing is not that close. In the US you can see a slow decline in human capital growth prior to 2000, consistent with aging, while in Italy and Spain the drop appears more sudden and the timing is such that it looks more like a response to the financial crisis than anything else.&lt;/p&gt;

&lt;p&gt;Last, how about productivity growth? The figure below shows that relative to the US, a decline in productivity growth is more apparent for Europe around the time of the slowdown. If you look at the US, productivity growth rises up until about 2005, and then starts to abate. But if you look at the UK or France, as examples, their productivity growth just sort of tracks 2% up until about 2006, and then it drops down close to zero percent per year, and at times is negative. That’s a far more dramatic drop in productivity growth than the US.&lt;/p&gt;

&lt;iframe frameborder=&quot;0&quot; width=&quot;900&quot; height=&quot;600&quot; scrolling=&quot;no&quot; src=&quot;/assets/plotly/fig_europe_prod.html&quot;&gt;
&lt;/iframe&gt;

&lt;p&gt;From all these figures, I come up with a few tentative conclusions.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Changes in the accumulation of physical capital were not important for Europe’s growth slowdown.&lt;/li&gt;
  &lt;li&gt;Changes in human capital growth were important for Europe’s growth slowdown, but that effect varies by country. This also doesn’t tell me whether it was demographics (as in the US) or some other factor in human capital, like changes in education or working hours.&lt;/li&gt;
  &lt;li&gt;A significant source of the growth slowdown in Europe is due to a drop in productivity growth, pretty much universally. This drop is larger than in the US.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This doesn’t actually tell us a whole lot, I know. What I see this post as doing as establishing the basic facts that have to be looked at to explain Europe’s slowdown. I know I’m terrible about keeping up with posts, but I also feel leaving it open-ended like this provides me with more motivation to do the follow up posts. What I have in mind going forward is a couple of additional topics. One is likely to be breaking down the human capital term and asking how much can be accounted for by demographics in each country. My gut reaction is that this will be less important for Europe as a whole than the US, but there will probably be a few examples where it is relevant.&lt;/p&gt;

&lt;p&gt;A second will be on the productivity decline, and how much of that could be attributed to structural factors like shifts into services. My gut reaction here is that this kind of structural shift will be less important than in the US, as it is hard to slow-moving structural shifts with the dramatic drop in productivity growth that occurred.&lt;/p&gt;

&lt;p&gt;That’s the plan, at least. I’m sure this means the productivity post will come out in 2026 or something. But for now I’m forging ahead!&lt;/p&gt;

&lt;h3 id=&quot;technical-stuff&quot;&gt;Technical stuff&lt;/h3&gt;
&lt;p&gt;The data all comes from the &lt;a href=&quot;https://www.rug.nl/ggdc/productivity/pwt/?lang=en&quot;&gt;Penn World Tables&lt;/a&gt; version 10.0, as this provides consistent data across countries. The GDP data are in constant &lt;em&gt;national&lt;/em&gt; prices (not PPP) because I only do within-country accounting of the growth rates. I’m not comparing levels of GDP per capita across countries.&lt;/p&gt;

&lt;p&gt;I did all the analysis in R, which has a nice package called “pwt10” that automatically pulls the PWT data into a dataframe. You can download the script &lt;a href=&quot;/assets/2022-12-29-PWT-Europe.r&quot;&gt;here&lt;/a&gt;. The plots in the post are all built using Plotly and then hosted on my own site. All the necessary packages are listed in the script, and it &lt;em&gt;should&lt;/em&gt; be self-contained so that you can run “as-is”.&lt;/p&gt;

&lt;p&gt;To do the accounting, I start with a Cobb-Douglas production function&lt;/p&gt;

\[Y = K^{\alpha}(AH)^{1-\alpha}\]

&lt;p&gt;where $K$ is physical capital, $A$ is productivity, and $H$ is the aggregate amount of human capital used (it combines number of workers, their education, and the time they spend working). In what is a fairly standard technique in any growth textbook (like &lt;a href=&quot;https://amzn.to/3hWmsMG&quot;&gt;this one&lt;/a&gt;) you can divide both sides by $Y^{\alpha}$ and re-arrange to get&lt;/p&gt;

\[Y = \left(\frac{K}{Y} \right)^{\frac{\alpha}{1-\alpha}} A H\]

&lt;p&gt;and then divide through by $N$, the population, to get GDP per capita, $y$:&lt;/p&gt;

\[y = \left(\frac{K}{Y} \right)^{\frac{\alpha}{1-\alpha}} A h\]

&lt;p&gt;where $h = H/N$ is the amount of human capital per person in the economy.&lt;/p&gt;

&lt;p&gt;To get this in growth rates, take the log of both sides, and then the time derivative to get&lt;/p&gt;

\[g_y = \frac{\alpha}{1-\alpha} g_{KY} + g_A + g_h\]

&lt;p&gt;In the post, I call $g_{Cap} = \alpha/(1-\alpha)g_{KY}$, which is the growth rate of the capital/output ratio scaled by a term involving the elasticity of output with respect to capital, $\alpha$. How big is $\alpha$? Well, that’s a great question that would require a lot of time to answer definitively. For the purposes of this post I set it to 0.3. Why 0.3? Well, you should go read &lt;a href=&quot;https://growthecon.com/wp/2021/04/01/paper-Elasticity.html&quot;&gt;my paper&lt;/a&gt; on this.&lt;/p&gt;

&lt;p&gt;The growth rate of human capital is $g_{Human} = g_h$, and the growth rate of productivity is $g_{Prod} = g_A$. In the future posts I’ll be more specific about how $g_h$ breaks down.&lt;/p&gt;

</description>
        <pubDate>Thu, 29 Dec 2022 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>Review of DeLong's &quot;Slouching Towards Utopia&quot;</title>
        <link>http://localhost:4000/feed/2022/10/11/DeLong-Review.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2022/10/11/DeLong-Review.html</guid>
        <description>&lt;p&gt;Brad Delong recently published his long-gestating economic history of the long 20th century, &lt;a href=&quot;https://amzn.to/3SSuTWv&quot;&gt;Slouching Towards Utopia&lt;/a&gt;. If you are reading this blog, you are almost certainly aware of that, and I would guess the probability that you’ve read it (or are reading it) are around 50/50. It has garnered well-deserved high praise from a variety of people. To avoid just repeating what everyone else is saying, let me simply say that it is a necessary book to read if you are at all interested in the subject of economic growth. It is informative and thought-provoking. If you are one of those 50% who have not read it, go do so now.&lt;/p&gt;

&lt;p&gt;One of the things DeLong has been asking online is what he got “big time wrong”. While I don’t think there is anything that is big time &lt;em&gt;wrong&lt;/em&gt;, I do think there is a feature of the 1870-2010 period that does not get sufficient attention. I doubt it is because DeLong doesn’t appreciate the relevance, but at some point in a 500-odd page book, choices must be made. Somewhere in the multiverse is a reality where DeLong has bludgeoned his editor to death and produced a 1500 page tome that includes a few chapters on what I’ll expand on below. One way to consider this post is something a supplement for the STU volume that manifested itself in this particular strand of the multiverse.&lt;/p&gt;

&lt;p&gt;DeLong makes clear that it wasn’t until around 1870 that productivity growth finally grew large enough to outpace the increased population growth that had always previously occurred in response to higher living standards. Productivity growth outpacing the population growth response made possible historically unprecendented growth in living standards after 1870. DeLong attributes that increased pace of productivity growth to some combination of the research lab, the corporation, and globalization.&lt;/p&gt;

&lt;p&gt;I’m sure we can quibble about the precise natures of timing or the importance of those three factors in productivity growth. But what I’m more interested in is that very relevant and ultimately very &lt;em&gt;necessary&lt;/em&gt; change in how population growth responded to living standards that occurred around the same time.&lt;/p&gt;

&lt;p&gt;What happened around 1870 was not just that productivity growth was able to outpace population growth, but that population growth started to &lt;em&gt;fall&lt;/em&gt; in response to increase in productivity. This was a fundamental flip in the typical Malthusian relationship that had held up until (roughly) that point in time. Prior to this inflection point, productivity growth had increased before, but every time had induced a response of higher population growth rates, eroding any gains in per-person living standards. After this inflection point, when productivity growth increased it induced &lt;em&gt;lower&lt;/em&gt; population growth rates, &lt;em&gt;accelerating&lt;/em&gt; the gains in per-person living standards. Without this flip in the population response, the productivity growth associated with the research lab, corporations, and globalization would not have generated the sustained growth in living standards that form a core part of STU.&lt;/p&gt;

&lt;p&gt;It’s not that DeLong ignores the population response. Throughout the book he points to the demonstrable decline in fertility rates, using the vivid description that prior to 1870 the typical woman might spend 20 years of her adult life either pregnant or breastfeeding, while by the mid-20th century it might be only four years. What I’m nitpicking here is that this decline in fertility deserves equal billing with the research lab, corporation, and globalization. Without the flip to an “anti-Malthusian” negative relationship of fertility and productivity, you don’t even slouch towards utopia, you stagnate.&lt;/p&gt;

&lt;p&gt;Consider that with material needs taken care of, human populations are capable of a shocking rate of growth. A common example to trot out here is the Hutterites. Between 1880 and 1950 - so exactly during the period when productivity growth had accelerated demonstrably - their population increased at a rate of over 4 percent per year. Each woman had approximately 10 children, and given that they did not marry until their early 20s, its is conceivable that they could reach a growth rate of 4.5 percent or more, with each woman having 12 to 14 kids.&lt;/p&gt;

&lt;p&gt;The point here is not that this is an ideal to aspire to. The point is that it was entirely possible for human populations to respond to the productivity growth inherent in the research lab, corporations, and globalization by doing what they had done throughout history. It was plausible to respond to increased abundance by having more kids - a lot more kids. DeLong’s rough index of productivity growth is that it grew by about 2.1 percent per year from 1870 to 2010. One does not need to imagine that everyone was a Hutterite to think that human populations could sustain 2.1 percent growth or more over long periods of time, thus offsetting the productivity growth in a most Malthusian way.&lt;/p&gt;

&lt;p&gt;It was not enough that productivity growth accelerated around 1870. It was an acceleration in productivity &lt;em&gt;combined&lt;/em&gt; with a decline in population growth that put us on a slow trudge towards utopia. The decline in population growth was entirely a-historical at that point. Without this anti-Malthusian response the research lab, corporation, and globalization cannot provide sustained growth. But it is also the case that without the research lab, corporation, and globalization the anti-Malthusian response would not have occurred. My case is not that the demographic response is primary or more important, but that it is a necessary complement to those productivity boosters.&lt;/p&gt;

&lt;h3 id=&quot;making-kids-cost-more&quot;&gt;Making kids cost more&lt;/h3&gt;
&lt;p&gt;My preferred structure to think about the population response to productivity is that it follows the following rough formula&lt;/p&gt;

\[\text{Pop growth} = \textit{Parameter} \times \frac{\text{Income}}{\text{Price per child}}\]

&lt;p&gt;This is really an expression for fertility, and I could add something explicit accounting for mortality rates, but this ultimately gets the right intuition. The price per child is a measure of the material costs to parents of getting a child “up to speed” with life. Basic food, clothing, and shelter, yes. Along with enough cultural and technical knowledge to care for themselves (and often for the parent in old age). In other words, the price of a child is the price of getting them to be a functioning adult.&lt;/p&gt;

&lt;p&gt;In a Malthusian setting, in general what we get is that productivity growth increased income, but did not have a significant effect on the price per child. Hence an increase in income increased population growth, and ultimately any productivity growth was eaten away (literally, to some extent) by congestion and crowding and diminishing returns to resources. At that point ncomes fell back to the point that population growth was just keeping pace with productivity growth. When productivity growth is positive then this allows population growth to be net positive (births just outpacing deaths), implying that income is stagnant but above some biological subsistence level, and that the size of the population goes up every year.&lt;/p&gt;

&lt;p&gt;Holding the price per child constant, the faster is productivity growth in this Malthusian setting, the higher is that stagnant income level. This gives a way of understanding how living standards could creep up over time even as everyone remained tied down by the Malthusian logic. Before 1870, J.S. Mill and others were all underwhelmed by the living standards that rapid (relative to history at that point) technological change had wrought. Each was convinced that the Malthusian logic held and perhaps doomed the common man to stagnant living standards even as science and technology remade the world.&lt;/p&gt;

&lt;p&gt;After 1870, though, we get something new. Productivity growth did increase in speed, raising incomes even faster than before. This, &lt;em&gt;by itself&lt;/em&gt;, would not change the overall logic. It would have allowed a somewhat higher - but ultimately still stagnant - level of income per person. Humans could have procreated fast enough to make this happen.&lt;/p&gt;

&lt;p&gt;The key change is that productivity growth, starting around 1870, reached down and profoundly &lt;em&gt;raised&lt;/em&gt; the price of bringing a child to adulthood. I have in mind a few forces here.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Technological change led to demand for education. To riff on DeLong’s characterization, around 1870 we had innovated away from using our human backs (with new energy sources) and fingers (with machines) to do things, and were innovating ways to replace some of our cognitive skills. Working with those new technologies required more abstract skills, which in turn led to more demand for education. More education per child raises the price child. Alternatively, you could argue (as we in higher education often do) that education enables you to deal more easily with rapid technological changes. The acceleration of productivity growth in 1870 would have raised the return to education in that sense, raising the cost of a child.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Urbanization. People had been moving to cities for centuries, of course, but corporations, globalization, and research labs accelerated that move. Urban areas are often argued to have higher child-rearing costs. That may be direct costs (relative price of food or shelter/space may be high compared to rural areas) or indirect costs (they may not have as much use as household workers compared to rural areas). Either way, by changing the location of economic activity it raised the cost of children.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Health and nutrition improved. Child mortality changed in a fundamental way, and for any given number of desired adult children, you could have fewer pregnancies, good for moms. But beyond that, it meant that investments in those children - education, skills, migration - were likely to pay off. That raised the desired investment per child, raising the price of each child.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Beckerian time costs. Kids take time. As incomes levels increased due to productivity growth, this increases the opportunity cost of time for parents, perhaps limiting their willingness to have kids. More practically, it probably works to increase marriage age as people acquire more resources/skills/experience prior to starting a family.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There should be like 1000 citations attached to these points. But I’m trying to finish this off today so my apologies to all the people whose work I didn’t explicitly cite (except, I guess, Gary Becker).&lt;/p&gt;

&lt;p&gt;Regardless, I think a crucial aspect of the story from 1870 forward is not just the acceleration of productivity growth, but the fundamental effect of this productivity growth on the price of kids. This generated the anti-Malthusian response which was necessary to the sustained increase in living standards behind STU.&lt;/p&gt;

&lt;h3 id=&quot;lets-really-have-some-fun&quot;&gt;Let’s really have some fun&lt;/h3&gt;
&lt;p&gt;In the book, DeLong sets up Hayek and Polanyi (at some point forced into an awkward reconciliation by Keynes) as the intellectual poles of the story. Hayek and Polanyi, and to a great extent Keynes, were writing and thinking about economic growth well after this flip to an anti-Malthusian population response has occurred. While they all would certainly recognize Malthus’ argument and understand the logic, what I think is notable is that they all generally took the anti-Malthusian population response of their contemporary period as a given.&lt;/p&gt;

&lt;p&gt;Moreover, I think that their positions are in some sense dependent on the anti-Malthusian population response. Take Hayek: the market giveth, the market taketh away, blessed be the market. This became a viable theory only when the market had in fact delivered a series of demonstrably good outcomes. Hayek could look backwards and point at definitive improvements in living standards and attribute them (often, but not always, correctly) to markets. With the anti-Malthusian response, the productivity gains after 1870 does not just allow for higher living standards, but &lt;em&gt;noticeably&lt;/em&gt; higher living standards.&lt;/p&gt;

&lt;p&gt;There were markets in existence well before 1870, and well before the Industrial Revolution. There is a whole other post I have some intention of writing about the a-historical nature of claims that people existed in some kind of pre-market or non-market economy prior to like 1800 (I’m looking at you, Karl Polanyi). Regardless, prior to about 1870 it would be hard to make the Hayekian claim about markets because they were not delivering the massive growth in the pie that let you elide distributional questions associated with pie-slicing. Markets at that point were just another way of slicing a pie that appeared to be somewhat constant in size.&lt;/p&gt;

&lt;p&gt;Hayek could even make the case (&lt;em&gt;Beware, completely untested hypothesis follows&lt;/em&gt;) that the market was the reason for the flip to anti-Malthusian population responses. Once markets put a more explicit price on children (education costs, etc..) that was when people flipped their behavior, ridded themselves of the Malthusian response, and delivered the boost to growth in living standards observed after 1870. Filtering family decisions through the market was exactly how we were able to slouch much closer to utopia. Without making the costs of children explicit through markets, we’d be stuck with continued Malthusian stagnation.&lt;/p&gt;

&lt;p&gt;Okay, that’s Hayek. What about Polanyi?&lt;/p&gt;

&lt;p&gt;I read Polanyi as being about identity. We are very protective of our identities, and those identities often coalesce around occupations (farmer, doctor, weaver, etc.) and place (the family farm, a block or neighborhood, a region). In many cases the pieces of those identities overlap; they didn’t call them the Pittsburgh Steelers by accident.&lt;/p&gt;

&lt;p&gt;The danger that markets pose is that they want to treat people and places as interchangable and substitutable. The “labor market” wants to treat each individual as an identity-less lump of labor effort. The “land market” wants to treat each place as an identity-less location. The market will find the most efficient allocation of that identity-less labor across a bunch of identity-less places.&lt;/p&gt;

&lt;p&gt;Those people and locations will, according to Polanyi, refuse at some point to be treated in such a manner and will protect those identities. Steelworkers in Pittsburgh defined themselves to a great degree by those two characteristics, and their families and children defined themselves by those characteristics even if they were not (a) steelworkers or (b) living in Pittsburgh. It is important to people that those identities are maintained even if the market is demanding that steel work be done in Mumbai. Those steelworkers will act in ways - organizing politically to put up trade barriers, for example - to save those identities.&lt;/p&gt;

&lt;p&gt;What does population growth have to do with this? (&lt;em&gt;Beware, completely untested hypothesis follows&lt;/em&gt;) When population growth remains high it is (more) plausible to maintain identities in the face of market changes. I don’t need &lt;em&gt;all&lt;/em&gt; my children to farm our ancestral land so long as &lt;em&gt;some&lt;/em&gt; of my children farm the ancestral land. I don’t need &lt;em&gt;all&lt;/em&gt; my children to become steelworkers so long as &lt;em&gt;some&lt;/em&gt; of my children carry on the family trade. When productivity goes up, the Malthusian response generates more kids, allowing some to remain in place and in roles that they’d traditionally be expected to occupy. It also allows some set of kids to move off to new locations and try new jobs. With the Malthusian population response it is plausible to generate a slow transition of occupations and locations. Places decline and occupations disappear, but they decline and disappear over generations, not years. Steelworkers get to retire &lt;em&gt;as steelworkers&lt;/em&gt; in the homes they raised their families in &lt;em&gt;in Pittsburgh&lt;/em&gt;. With a generational transition, old identities can be retained while new identities are built in new jobs and new places.&lt;/p&gt;

&lt;p&gt;When we flip over to the anti-Malthusian response, however, the disruptions caused to identities by productivity growth translate into smaller families. Both my kids move off the farm, or both are unable to get jobs as steelworkers. Even worse, the steelworker may have move to Atlanta (seriously, the Falcons?) to find a new job as …. very much not a steelworker. The anti-Malthusian response causes living standards to rise rapidly, but also causes the disruptions of that to happen in years, not generations.&lt;/p&gt;

&lt;p&gt;As Polanyi speculated, threatened identities will try to defend themselves. This might be through unions or tariffs or some other attempt to slow down and moderate the effects of the pure market; all gumming up the market. In the worst cases that defense ends up turning into things like anti-immigrant attitudes, racism, or as Polanyi suggests, fascism. These are all things dominated by the concept of maintaining &lt;em&gt;some&lt;/em&gt; kind of identity. Those ugly versions of identity defense often explicitly deal with questions of fertility and population growth, by the way. They get hung up on things like race replacement or racial purity and almost invariably promote large families as some kind of ideal. Population growth is the visible confirmation your identity is thriving.&lt;/p&gt;

&lt;p&gt;Both poles of the ideological spectrum that STU uses to interpret the long 20th century are, in this framing, ideologies that exist because of the anti-Malthusian population resposne. Or maybe exist is a strong word. Some sort of Hayek and some sort of Polanyi were probably bound to occur. But without the anti-Malthusian population response, there would have been less for them to argue about. The flip to family size declining with prosperity generated conditions where their ideas were more salient, to the point that DeLong could usefully and capably view much of the long 20th century through their eyes.&lt;/p&gt;

&lt;p&gt;Take this whole section for what it is, pure speculation. You should go read Slouching Toward Utopia and learn something about how the economy evolved since 1870. While you are doing that, keep in the back of your head the population responses required to generate the economic growth observed.&lt;/p&gt;
</description>
        <pubDate>Tue, 11 Oct 2022 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Implications of additive growth</title>
        <link>http://localhost:4000/feed/2022/08/09/Additive.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2022/08/09/Additive.html</guid>
        <description>&lt;p&gt;Well, after a massive break from most social media and this blog, I am stretching my neck back out of the shell. This first post back is very much a “teaching post”, in that it’s a rough draft of how I might talk about this topic in a class. I have some ideas for more topical posts to come, but for the moment this is helping to limber up the old blogging muscles.&lt;/p&gt;

&lt;p&gt;Back in April Thomas Philippon released a working paper on &lt;a href=&quot;https://www.nber.org/papers/w29950&quot;&gt;additive growth&lt;/a&gt;. It takes on a common stylized fact in economic growth - constant exponential growth - and shows that there is a better option - constant additive growth. In words, the &lt;em&gt;addition&lt;/em&gt; to productivity (TFP) is roughly the same every year over decades, and the &lt;em&gt;growth rate&lt;/em&gt; of TFP is steadily declining.&lt;/p&gt;

&lt;p&gt;The main result is very easy to see. The figure below shows the actual time path of TFP from 1948 to 2019 (labelled TFPNQ in the dark solid line). “Model G” is the implied path of TFP with exponential growth estimated using growth from 1948 to 1983 (small blue dashes). As you can see, that estimate wildly overestimates TFP levels by 2019, and hence implies that there was some kind of slowdown.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/phil1b.jpg&quot; alt=&quot;Linear TFP&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“Model D” is the implied path of TFP with additive growth (orange dashes), also estimated using the data from 1948 to 1983. This tracks the actual path of TFP much better. On the basis of the additive growth projection, there was no slowdown. That is, productivity in 2019 was exactly what an additive growth model would have predicted.&lt;/p&gt;

&lt;p&gt;What follows in the paper is a series of variations on this to assure the reader that this overall finding is robust. This includes applying the same kind of methodology to other countries, with the result that all of them also present the characteristics of additive growth.&lt;/p&gt;

&lt;p&gt;There is nothing in the paper that proves additive growth is correct and exponential growth is incorrect. That’s not a slight on the paper. It’s not possible to say exactly what the right model of growth should be. It’s plausible that despite Philippon’s work the world is characterized by constant growth rates, and it just so happens that there &lt;em&gt;was&lt;/em&gt; a consistent slowdown in those constant growth rates over the 20th century. What he’s providing is not proof, but rather an extended argument that it is far easier to forecast growth using the additive model. Given that, it probably makes sense to think about how and why economic growth looks to follow that additive model.&lt;/p&gt;

&lt;p&gt;So let’s take Philippon’s result seriously. There are a number of interesting implications of these results. One is that additive growth eliminates the apparent drop in volatility in TFP growth after World War II. The &lt;em&gt;growth rate&lt;/em&gt; of GDP is very volatile from 1890 to 1940 (or so). It jumps around in a range that goes from -10% to positive 10%, even though the average is around 1.2%. After WWII the range is only -1% to 4% (or so). I’ve seen this kind of data before, and I always assumed it had to do with poor measurement of things like capital and labor prior to WWII (which would pass through into poor measurement of TFP). Philippon finds that the &lt;em&gt;addition&lt;/em&gt; to TFP is in fact pretty steady over time, with no weird drop after WWII.&lt;/p&gt;

&lt;p&gt;That is, with one exception. There is a distinct jump in the &lt;em&gt;addition&lt;/em&gt; to TFP around 1930 (or so). You can see the consequences of this most easily in another one of his figures.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/phil9.jpg&quot; alt=&quot;GPT&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From 1890 to 1930-ish, the &lt;em&gt;addition&lt;/em&gt; to TFP was about 0.017 per year (using 1890 = 1). After that break the &lt;em&gt;addition&lt;/em&gt; to TFP is around 0.057, and that lasts consistently until 2019. What Philippon chalks this up to the long-run application of electricity to the economy. There’s a whole other story to explore about why electricity generated this distinct jump in the increment to TFP (and why didn’t IT, or chemicals, or something else?).&lt;/p&gt;

&lt;p&gt;These are all worthy of exploration, and my guess is we’ll get several papers in the next few years tackling these. What I’ve got for you here is some new data to throw some sand in the gears, and then the implications of Philippon’s work for growth theory.&lt;/p&gt;

&lt;h3 id=&quot;demographics-and-gdp-per-capita&quot;&gt;Demographics and GDP per capita&lt;/h3&gt;
&lt;p&gt;Everything Philippon does is in terms of GDP per worker, or GDP per hour, depending on dataset and sources. The measures of TFP are calculated using workers or hours as well. More directly, he does the assessment of labor productivity (GDP per worker) he finds the same support for additive growth. Here’s his figure for GDP per worker. It’s basically telling the identical story to the picture for TFP shown first in this post.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/phil2b.jpg&quot; alt=&quot;Labor productivity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What I’m interested in is whether this pattern shows up with respect to GDP &lt;em&gt;per capita&lt;/em&gt;. Do we see additive growth in living standards (which GDP per capita is probably a better measure of)?&lt;/p&gt;

&lt;p&gt;What I did was replicate Philippon’s procedure using data on GDP per capita. Mine only runs through 2016 because of the dataset I used, but that isn’t going to be a big issue. I estimated both a “Model G” assuming exponential growth and a “Model D” assuming additive growth for the period 1948-1983. Then I forecast GDP per capita on the basis of the two models from 1983 to 2016.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/philcomparison.jpg&quot; alt=&quot;GDP per capita&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here’s my figure, and I tried to use similar colors/lines so the comparison was clear. I didn’t normalize the y-axis to be 1 in 1948, as Philippon does, but that doesn’t change anything.&lt;/p&gt;

&lt;p&gt;In terms of GDP per capita, the case for additive growth is less clear. From 1983 to about 2000 the exponential growth forecast looks pretty good. Up until the financial crisis in 2008 you can probably make a good case that it holds. After the financial crisis it looks more like the additive growth model is relevant? But there isn’t a clear answer like there is for Philippon’s use of labor productivity or TFP.&lt;/p&gt;

&lt;p&gt;Why is this relevant? For one, it’s not obvious that we should care more about labor productivity (GDP per worker) than GDP per capita. The latter is more relevant to the state of overall living standards. The former is more relevant to worker productivity ignoring any demographic changes.&lt;/p&gt;

&lt;p&gt;This distinction wouldn’t be important if demographic changes were basically random fluctuations in the ratio of workers to population. All that would mean was that there was some noise separating GDP per worker and GDP per capita. But we know that those demographics are &lt;em&gt;not&lt;/em&gt; random, and that there is this massive demographic shift at work throughout the 20th and into the 21st century.&lt;/p&gt;

&lt;p&gt;The pro-Philippon view on this would be as follows. Underlying TFP or labor productivity follows an additive model. But because of the surge in Baby Boomers during the 20th century (increasing the ratio of workers to population) this generating additional upward force on GDP per capita and gave us the &lt;em&gt;illusion&lt;/em&gt; of exponential growth in GDP per capita up until around 2010. Following that, and the accelerating removal of Baby Boomers from the labor force (lowering the ratio of workers to population), this illusion is “clearing up” and GDP per capita itself is reverting to what we might expect to be an additive process going forward.&lt;/p&gt;

&lt;p&gt;My figure doesn’t tell you that Philippon is wrong. It does offer another way of visualizing how massive the effect of the Baby Boom was on the economy. If you were focused on GDP per capita (and that would be a legitimate thing to worry about) you might have been over-confident on how relevant the exponential model was for growth, solely because of the surge in Baby Boomers. Demographics can be as powerful as a general-purpose technology like electricity in changing observed growth in GDP per capita.&lt;/p&gt;

&lt;p&gt;Someone should &lt;a href=&quot;https://amzn.to/3JLlXP2&quot;&gt;write a book&lt;/a&gt; featuring those demographic changes as a big factor in how economic growth changed from the 20th to the 21st century.&lt;/p&gt;

&lt;h3 id=&quot;connecting-rd-to-productivity&quot;&gt;Connecting R&amp;amp;D to productivity&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;(Added note on 8/16: this section is based on stuff in the Philippon paper, and in turn he cites a comment by Chad Jones for suggesting it. The original blog post may make it sound like I came up with this myself. I did not! - DV)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Perhaps the most interesting thing about the Philippon paper, to me, is that it turns a very bright flashlight on the connection of productivity (TFP) with the production of knowledge or ideas. In a standard textbook treatment of ideas and economic growth - like, for example, in my &lt;a href=&quot;https://amzn.to/3dhEjL1&quot;&gt;book with Chad Jones&lt;/a&gt; - the model is as follows. TFP is proportional to the number of ideas; a 10% increase in ideas means a 10% increase in TFP. The percent increase in ideas depends on the amount of research effort - which produces new ideas - relative to the existing stock of ideas; the more research effort you put in, the higher the percent increase in ideas (holding the stock constant).&lt;/p&gt;

&lt;p&gt;Over time this creates something a race between research effort and ideas. Increasing research effort produces an increase in the number of new ideas being added every year. But those new ideas also keep increasing the stock of existing ideas, which pulls down the percent change in ideas that the new ideas imply. Having 100 new ideas given a stock of 1000 gives you a percent change of 10% in ideas (and hence a 10% change in TFP). Having 105 new ideas (because of more research effort) next year on a stock of 1100 ideas gives you a percent change of 9.5% (lower) in both ideas and productivity. And so on and so on.&lt;/p&gt;

&lt;p&gt;With a setup like this, the &lt;em&gt;growth rate&lt;/em&gt; of ideas (and hence of TFP) settles down until it becomes constant. That constant is proportional to the &lt;em&gt;growth rate&lt;/em&gt; of research effort. Exponential growth in research effort is able to generate exponential growth in TFP.&lt;/p&gt;

&lt;p&gt;This is what Philippon’s paper finds is counter-factual. So what in my above story has to change to match Philippon’s facts? The story makes it “too easy” for TFP to keep up with research effort. TFP rises proportionally with ideas, and new ideas flow proportionally to research effort. The data suggest that we have to add some friction into this model to slow down TFP growth enough such that it becomes additive.&lt;/p&gt;

&lt;p&gt;To do that, you could make the link from TFP to ideas suffer from some severe decreasing returns. What I mean by severe is that a 10% increase in ideas leads to a less than 10% increase in TFP &lt;em&gt;and&lt;/em&gt; (this is crucial) that the percentage increase in TFP is declining as we get more and more ideas. So a 10% increase in TFP in 1900 generated a 7% increase in TFP, but in 2000 generated only a 3% increase in TFP, and in 2050 will presumably generate only a 1% increase in TFP.&lt;/p&gt;

&lt;p&gt;Why might this be the case? Well, there is nothing magic that says that ideas = TFP or that they are proportional. That’s always been an assumption made for convenience. You could think of the severe decreasing returns as embodying an idea like complexity. As we accumulate more and more ideas, they make us more productive, but each new idea has to interact with so many other ideas that the gain in productivity gets smaller and smaller. Think of self-driving cars. If we lived in a featureless plane with no obstacles, the ideas behind self-driving cars (the cameras, the software, etc.) would represent a massive increase in how productive we could be. But the self-driving car has to work out how to operate in a world populated by all sorts of obstacles that represent the benefits of &lt;em&gt;other&lt;/em&gt; great ideas (like houses and traffic laws and paved roadways). So perhaps what Philippon’s data is telling us is that the link between TFP and ideas involves massive decreasing returns; new ideas don’t contribute as much over time because they have to be embedded in a system with other ideas.&lt;/p&gt;

&lt;p&gt;The end result is that with sufficient severe decreasing returns in the connection from TFP to ideas you can end up with additive growth. The &lt;em&gt;addition&lt;/em&gt; to TFP will become constant and proportional to the &lt;em&gt;growth rate&lt;/em&gt; of research effort in the long run.&lt;/p&gt;

&lt;p&gt;Taking Philippon’s results as gospel, their value is in narrowing down the range of acceptable ways to link TFP to ideas. I the next section I talk about what this means in math, but the upshot is that his paper tells us that the strict proportionality of TFP and ideas is wrong. Even more valuable, it gives us a very good idea of what the &lt;em&gt;right&lt;/em&gt; mathematical representation of their link should be (log, for the win!).&lt;/p&gt;

&lt;h3 id=&quot;math&quot;&gt;Math!&lt;/h3&gt;
&lt;p&gt;I tried to do the entire above section in words, as I know some readers shy away from math. But for those equation-inclined among you, here’s the prior section again in more technical detail.&lt;/p&gt;

&lt;p&gt;The existing model would tell you that TFP (A) is proportional to the number of ideas (I), as in $A = I$. It would also tell you that the change in ideas, $dI$, in a given time period is proportional to the research effort (R), so that $dI = R$. The first relationship implies that $dA = dI$, so it also implies that $dA = R$. Divide both sides by $A$ and you have&lt;/p&gt;

\[\frac{dA}{A} = \frac{R}{A}\]

&lt;p&gt;or the growth rate of TFP (the left-hand side) depends on the ratio of $R/A$. If $R$ is growing at a constant rate $g_R$, then the above equation tells us that in the long run the ratio $R/A$ will settle down to a constant and that $dA/A = g_R$ in the long run as well. The logic here is that if A is really small, it grows very fast (and hence R/A falls). If A is really large, then it grows very slowly (and hence R/A rises). Wherever you start, you always end up in this stable outcome with $dA/A = g_R$. But this outcome is one with a constant &lt;em&gt;growth rate&lt;/em&gt; of TFP.&lt;/p&gt;

&lt;p&gt;How do you generate constant &lt;em&gt;additions&lt;/em&gt; to TFP? As above, we need decreasing returns, and severe ones. If instead it is the case that $A = ln(I)$, or that TFP depends on the log of ideas, then we get that $dA = dI/I$, or the &lt;em&gt;addition&lt;/em&gt; to TFP depends on the growth rate of ideas. The growth rate of ideas is $dI/I = R/I$, and for the same logic I just went through above we’d get that in the long run $dI/I = g_R$. This in turn implies that $dA = g_R$ in the long run. Ideas grow exponentially, but this only generates constant &lt;em&gt;additions&lt;/em&gt; to TFP because the increase in ideas hits such decreasing returns in generating TFP.&lt;/p&gt;

&lt;p&gt;Why does this work? One way to think about this is that we have exponential growth in ideas over time. We need to “cancel out” that exponential growth in ideas to generate additive growth in TFP. The log operator cancels exponentials, so that works. A different way to see this is to take this equation, $dA = dI/I$ and re-arrange it a little. First, you can write this as&lt;/p&gt;

\[\frac{dA}{dI}I = 1\]

&lt;p&gt;which doesn’t mean much by itself. But divide both sides by $A$ and you get&lt;/p&gt;

\[\frac{dA}{dI}\frac{I}{A} = \frac{1}{A}.\]

&lt;p&gt;On the left is the elasticity of TFP with respect to ideas. On the right, you can see that this elasticity falls as TFP rises. This generates the action I mentioned in the prior section, that a 10% increase in ideas has to generate less than a 10% increase in TFP, and that the percent increase in TFP is falling as we get more and more ideas (and higher and higher TFP).&lt;/p&gt;

&lt;p&gt;As another aside, we need the log operator in our $A = ln(I)$ to make this all work. Just having &lt;em&gt;some&lt;/em&gt; decreasing returns isn’t enough. If instead we had $A = I^{\phi}$, with $\phi&amp;lt;1$, we’d have decreasing returns. The problem is that with this setup, the elasticity of A with respect to I is exactly $\phi$, a constant. As we get more and more ideas, the elasticity stays the same. In this case the presence of $\phi$ scales down the growth rate of $A$ in the long run, but not enough to eliminate the fact that $A$ would still grow exponentially. It’s only by asserting that $A = ln(I)$ that we generate enough friction to get to additive growth.&lt;/p&gt;

&lt;h3 id=&quot;the-right-kind-of-paper&quot;&gt;The right kind of paper&lt;/h3&gt;
&lt;p&gt;I like this paper a lot. I would imagine that the specifics of the estimations and presentations will change as the paper goes through refereeing for publication, but it seems hard to overlook the general pattern. To me it creates, at a minimum, an open question that any growth model would have to address going forward (i.e. is your model consistent with additive growth?).&lt;/p&gt;

&lt;p&gt;This is a great example of just digging backwards through assumptions to see if they hold up. In that sense the paper is enraging (in a good way), because anyone could have done the initial investigation of this at any point in like the last 20 years.&lt;/p&gt;

&lt;p&gt;Taking the results as a given, a significant contribution is to provide a solid empirical basis for narrowing theory to a specific structure for the relationship of TFP and ideas, the $A = ln(I)$ stuff from the math section. That’s cool! That connection from TFP to ideas was always fuzzy, and now we might at least put some mathematical discipline on how they are related, even if we don’t have the specific story worked out in detail.&lt;/p&gt;

&lt;p&gt;It leaves big questions on the table as well. Why did electricity (and not any other invention) result in a significant shift in additive growth? Was it in fact electricity that did this (and not, say, mass immigration and urbanization)? Is it possible to generate another shift in the additive growth increment?&lt;/p&gt;

</description>
        <pubDate>Tue, 09 Aug 2022 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>The return to public capital spending</title>
        <link>http://localhost:4000/feed/2021/05/18/Return-Spending.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2021/05/18/Return-Spending.html</guid>
        <description>&lt;p&gt;In the time-honored tradition of the Growth Economics Blog, I am coming into a discussion about four weeks late. In this case it has to do with the value of spending on “infrastructure” or public capital, which came up because of the proposed Biden infrastructure bill.&lt;/p&gt;

&lt;p&gt;At that time I had a brief exchange with someone asking, roughly, “How many dollars of GDP do you get for one dollar of infrastructure?”. We went back and forth via e-mail on this, looking for a good back-of-the-envelope kind of calculation. I don’t think I gave that person a really coherent answer, although I’m pretty sure all the pieces were there in some form. This post is an attempt to make a more coherent case for how to think about this.&lt;/p&gt;

&lt;p&gt;I generally support the proposed infrastructure bill. A secondary purpose of this post is to establish the logic behind that support, and perhaps more important to establish why I might be wrong. If you want to talk me out of that support, you can tell me which specific assumption(s) I’m making that are wrong and how that changes my calculation.&lt;/p&gt;

&lt;p&gt;The first thing to do is to be more clear about the question. What I want to ask is “What is the net present value (NPV) of the additional GDP - in dollars - you get over time for one dollar of public capital spending today?”&lt;/p&gt;

&lt;p&gt;Why the present discounted value of GDP over time, as opposed to the extra GDP I would get today (or say, in 2022)? Because we’re talking about capital goods, and it doesn’t make sense to evaluate the return on a capital good only in the year it was built. Whether a dollar of public capital is “worth it” or not depends on the flow of GDP you get from it over its life. You don’t ask whether buying a car is “worth it” by evaluating how useful it is to get to work &lt;em&gt;today&lt;/em&gt;, you evaluate how useful it is to get to work over the next few years.&lt;/p&gt;

&lt;p&gt;The other thing to point out here is that I’m not interested in the fiscal position of the federal goverment, I’m interested in whether the public capital spending is worth it for the economy as a whole. If we were worried about the fiscal position of the US government the question would be something like “What is NPV of the taxes that can be collected given a one dollar increase in public capital?”.&lt;/p&gt;

&lt;p&gt;The question of interest to me is whether it is worth allocating real resources - labor, existing capital - to produce public capital goods versus allocating them to produce …. something else like consumption goods or private capital goods. That idea of the opportunity cost of public capital is going to be important when we get to figuring out how to discount the flow of GDP back to today.&lt;/p&gt;

&lt;p&gt;As an aside, the general idea here is very similar to what &lt;a href=&quot;https://ideas.repec.org/h/nbr/nberch/14422.html&quot;&gt;Jones and Summers&lt;/a&gt; just did for the returns to R\&amp;amp;D spending. Matt Clancy has a &lt;a href=&quot;https://mattsclancy.substack.com&quot;&gt;nice explainer&lt;/a&gt; on that.&lt;/p&gt;

&lt;h3 id=&quot;calculating-the-return&quot;&gt;Calculating the return&lt;/h3&gt;
&lt;p&gt;How do I find the NPV of one dollar of public capital?&lt;/p&gt;

&lt;p&gt;If I spend one dollar on public capital, I get $1/p_X$ real units of public capital, where $p_X$ is the price of a unit.&lt;/p&gt;

&lt;p&gt;Those units of public capital (presumably) get used in production and so the next thing I want to know is how many units of real GDP I get from each unit of public capital. For that I need the marginal product of public capital, $MPX$. So in real terms I’m getting $MPX \times 1/p_X$ units of extra GDP from spending one dollar on public capital. To put that in dollar terms, I need to multiply this by the price of a unit of GDP, $p_Y$. So the dollars of GDP I get from one dollar of public capital are $MPX \times p_Y/p_X$.&lt;/p&gt;

&lt;p&gt;This calculation only tells me how many dollars of GDP I get &lt;em&gt;this year&lt;/em&gt;. But the public capital doesn’t disappear after I use it, and I can use it next year (and the year after that and so on). It probably does depreciate, however, so assume that every year a fraction $\delta$ of the public capital becomes useless or fails or whatever. What I am going to assume (and will justify below) is that the actual $MPX \times p_Y/p_X$ doesn’t change over time. The dollars of GDP I get from public capital decline over time due just to depreciation of the public capital I purchased.&lt;/p&gt;

&lt;p&gt;I need to discount those future flows of extra GDP back to the present, so I need some discount rate $r$. Without going into the math behind calculating a net present value (NPV), here’s what I’m going to get:&lt;/p&gt;

\[NPV = \frac{MPX \times p_Y/p_X}{r+\delta}\]

&lt;p&gt;The $\delta$ in the denominator is accounting for the fact that the public capital declines over time, and notice that the higher the depreciation rate the lower the NPV.&lt;/p&gt;

&lt;p&gt;The discount rate $r$ is going to end up more interesting, and I’ll go through this in more detail below. But keep in mind that it is the return we could get on our dollar of spending from an alternative investment.&lt;/p&gt;

&lt;h3 id=&quot;marginal-product-of-public-capital&quot;&gt;Marginal product of public capital&lt;/h3&gt;
&lt;p&gt;Start with the $MPX$, the real addition to GDP from one additional unit of public capital. As a general rule, I can find the $MPX$ from $MPX = \beta Y / X$, where $\beta$ is the elasticity of GDP with respect to public capital (% change in GDP for a % change in X) times the GDP/public capital ratio (Y/X).&lt;/p&gt;

&lt;p&gt;How would I figure out these values? My colleague German Cubas has a &lt;a href=&quot;https://academic.oup.com/ej/advance-article-abstract/doi/10.1093/ej/ueaa079/5860275?redirectedFrom=fulltext&quot;&gt;very nice paper&lt;/a&gt; where he calculates stocks of public capital across countries, and does some work to back out a value for $\beta$. What he finds is that the ratio $Y/X$ for rich countries like the US is about 2 (or the public capital to output ratio is only about 1/2). For comparison, the $Y/X$ ratio for private capital is probably like 0.3, so this means there is a lot more private capital compared to GDP than public capital compared to GDP. Which makes sense, as private capital includes everyone’s homes and all commercial buildings.&lt;/p&gt;

&lt;p&gt;For the value of $\beta$, he gets a value of $\beta \approx 0.09$. A 1% increase in public capital leads to a 0.09% increase in GDP. The elasticity for private capital is around 0.30, for what it is worth.&lt;/p&gt;

&lt;p&gt;This means the $MPX \approx 0.09 \times 2 \approx 0.18$. That holds as of now. Implicitly in the equation I gave you above, I’m assuming that this $MPX$ stays the same over time. But wouldn’t the addition of more X push down the Y/X ratio? And wouldn’t the value of $\beta$ change, possibly, in response? I’m going to appeal to some theory and some back-of-the-envelope calculations to suggest that the $MPX$ stays about the same over time, so we can use 0.18 in the equation above.&lt;/p&gt;

&lt;p&gt;A Y/X ratio of 2 implies that public capital is around 11 trillion nominal dollars, given a GDP of about 22 trillion nominal dollars. The Biden plan is roughly 2.3 trillion nominal dollars, but that is spread out over 8-10 years, and not all of it is actually for public capital. So the potential absolute increase in the public capital stock in a given year isn’t huge, meaning the Y/X ratio isn’t going to change much.&lt;/p&gt;

&lt;p&gt;From a theory side, a standard growth model with a role for public capital would tell you that the ratio Y/X is stable along a balanced growth path, and since I think the U.S. is roughly on a balanced growth path, then Y/X isn’t going to move a whole lot. We’re not China engaging on a capital-building spree to catch up to the West. These are more marginal adjustments.&lt;/p&gt;

&lt;p&gt;Finally, I’m assuming that $\beta$ stays constant over time because …. I really have no alternative. I don’t think we have good estimates of how that elasticity might change (if it does) as public capital is accumulated.&lt;/p&gt;

&lt;h3 id=&quot;relative-price-of-infrastructure&quot;&gt;Relative price of infrastructure&lt;/h3&gt;
&lt;p&gt;One of the big questions for this calculation is the relative price of public capital, $p_Y/p_X$. This figure from FRED gives you a little sense of the scale of that change using a few different measures of the price of capital goods.&lt;/p&gt;

&lt;iframe src=&quot;https://fred.stlouisfed.org/graph/graph-landing.php?g=E5R6&amp;amp;width=670&amp;amp;height=475&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; style=&quot;overflow:hidden; width:670px; height:525px;&quot; allowtransparency=&quot;true&quot; loading=&quot;lazy&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;The top line (in green) is the price index for GDP, with 1947 set at the initial value of 100. The three lines below that (blue, red, and purple) are different measures of the cost of capital goods. The first is the price of non-residential private capital goods, the second is the price of all private capital goods. The last is the price of government capital goods at the Federal level. I could add several more lines like this (state and local, private equipment, etc..) but the story always comes out about the same. Starting in the mid-1980s there is a sustained divergence in the price levels of GDP and capital goods, with capital goods becoming less and less expensive relative to GDP.&lt;/p&gt;

&lt;p&gt;You can’t make too much of the actual numbers in this figure. I set all series to have 1947=100, which means I assumed that capital goods and the generic basket of all goods making up GDP were identical in price in 1947. That might be wrong. But we can say that capital goods have been becoming relatively cheap over time. In other words, I’m really confident that $p_Y/p_X$ fell over time, but I cannot be as sure that $p_Y/p_X$ is less than one. We’ll play with that one.&lt;/p&gt;

&lt;h3 id=&quot;the-discount-rate&quot;&gt;The discount rate&lt;/h3&gt;
&lt;p&gt;The last piece, $r$, is probably the most interesting. In a normal NPV calculation this would be something like the interest rate that you can borrow at, or possibly an internal cost of capital.&lt;/p&gt;

&lt;p&gt;The temptation here is to use something like a Treasury bond rate, as that is what the government can borrow at. But I think that’s not quite right. I’m not after whether the infrastructure “pays for itself” at the federal level by increasing tax receipts enough to offset the borrowing costs. If that were the case, then yes I’d want to use the government’s borrowing costs as the discount rate. But then I’d also want to incorporate a tax rate into the calculation.&lt;/p&gt;

&lt;p&gt;What I want here is whether the infrastructure spending makes sense for the economy as a whole. In that sense it isn’t much different than asking whether &lt;em&gt;any&lt;/em&gt; capital spending makes sense. Because of this, what I want as the discount rate is the opportunity cost of this infrastructure spending. That is, if the government doesn’t do this infrastructure spending, what kind of return could we get by using those resources as either consumption, or on some other kind of capital goods.&lt;/p&gt;

&lt;p&gt;Here there are a few options. One is the “full crowding out” option, where we assume that the new public capital goods come at the expense of a set of private capital goods that would otherwise be built. By “expense” here I mean that the labor and existing capital that go into building the public capital are not able to be used to build private capital. We are just substituting one type of capital for another. In this case we’d set $r = MPK - \delta$, or the discount rate should be the marginal return to private capital adjusted for depreciation.&lt;/p&gt;

&lt;p&gt;The paper I referenced above by Cubas gives some numbers for the return to private capital as well. Based on an elasticity of 0.3, and a Y/K ratio of 0.28, you get an MPK of 0.084. Even though the elasticity for private capital is higher, we have a lot more of it (a lower Y/K ratio), so the MPK is smaller than the MPX. That by itself doesn’t tell us the public capital spending is worth it. We have to use this MPK value in the calculation of the NPV of the public capital to know.&lt;/p&gt;

&lt;p&gt;Given that, the “full crowding out” discount rate would be this MPK minus depreciation. Cubas also finds that the depreciation rate is similar for public and private capital, so $r = 0.084 - 0.046 \approx 0.038$ in this case.&lt;/p&gt;

&lt;p&gt;At the other end of the spectrum would be an “idle resource” option, where we assume that the new public capital goods are built by employing otherwise idle workers and capital. In this case there is no opportunity cost to building public capital. We’re not substituting for any private capital (or substituting for anything at all), and the right discount rate would be $r = 0$. In this case, the return on our idle assets (r) is equal to zero in the absence of the public capital spending.&lt;/p&gt;

&lt;p&gt;As is normal, the truth is probably somewhere in between, but these values give you some sense of the range we could be working with.&lt;/p&gt;

&lt;h3 id=&quot;a-range-of-estimates&quot;&gt;A range of estimates&lt;/h3&gt;
&lt;p&gt;Start with a pessimistic estimate. Let’s say we know the MPX is 0.18, as described above. And let’s say that $p_Y/p_X = 1/2$, meaning public capital goods cost twice as much as a bundle of GDP. Let’s assume the “full crowding out” option holds, and beyond that let’s assume that private capital doesn’t even have any depreciation involved, so that $r = 0.038$. The last thing we need is a depreciation rate, and the Cubas paper above gives a number of $\delta = 0.046$ for public capital.&lt;/p&gt;

&lt;p&gt;This stacks the deck against public capital about as much as seems plausible. What’s the NPV of one dollar of public capital spending?&lt;/p&gt;

\[NPV = \frac{MPX \times p_Y/p_X}{r+\delta} = \frac{0.18 \times 1/2}{0.038 + 0.046} = 1.07\]

&lt;p&gt;In this case, for each one dollar of public goods spending you get $1.07 in NPV of GDP. One of the reasons I’m supportive of the infrastructure bill in general is because even under this pessimistic case the investments seem to make sense.&lt;/p&gt;

&lt;p&gt;If you take an optimistic case, we could still have the MPX be 0.18. But now let’s set $p_Y/p_X = 2/1$, meaning public capital costs only half as much as a bundle of GDP, and assume that we’re in the “idle resource” world, with $r = 0$. Now the calculation is&lt;/p&gt;

\[NPV = \frac{MPX \times p_Y/p_X}{r+\delta} = \frac{0.18 \times 2/1}{0 + 0.046} = 7.83\]

&lt;p&gt;Now we get $7.83 in net present value for each dollar of public capital spent. That is a huge return, on the order of what you get from some calculations about the social value of R\&amp;amp;D.&lt;/p&gt;

&lt;p&gt;To me the least likely part of that optimistic scenario is the discount rate of zero. Even if we have idle resources now, we probably won’t over the lifetime of the public capital. So let’s try an intermediate case where we use the same MPX and the same relative price ratio. But now set the discount rate to 0.06, which is roughly the long-run return on equity, as a rough gauge of the opportunity cost of public capital.&lt;/p&gt;

\[NPV = \frac{MPX \times p_Y/p_X}{r+\delta} = \frac{0.18 \times 2/1}{0.06 + 0.046} = 3.39\]

&lt;p&gt;Still a big return, but not quite as big as before. In general, I think the basic structure here is going to deliver an NPV bigger than one under a reasonable set of parameter choices. The return to public capital appears large relative to the alternatives.&lt;/p&gt;

&lt;h3 id=&quot;why-might-i-be-wrong&quot;&gt;Why might I be wrong?&lt;/h3&gt;
&lt;p&gt;You can play around with these numbers all you want. It is entirely possible to generate an NPV that is less than one dollar. Just make public capital relatively expensive, or assume the MPX is lower, or increase the discount rate and/or depreciation rate. The question is whether your estimates of those values can be justified. I think, given what I explained above, that my numbers are “right” in a very rough, to-a-first-order-approximation kind of way, and deliver a result that suggests this kind of spending could be positive for the economy. As with the last example, I think the return is high enough (like 3 dollars in NPV for 1 dollar in spending) that even if I’m a little wrong on some parameters it still passes the smell test.&lt;/p&gt;

&lt;p&gt;Maybe the most uncertain element of this whole calculation is that elasticity $\beta$. Cubas’ number might make sense as a long-run average, but perhaps could be different depending on specific projects or times/places. A “bridge to nowhere” kind of project would presumably have a $\beta$ close to zero, and hence lower the NPV. On the other hand, the value of $\beta$ might be very large for specific projects that reduce transportation time between busy ports or for something like rural broadband that expands the available pool of labor for certain businesses.&lt;/p&gt;

&lt;p&gt;Last caveat. This calculation is made based on “public capital”, and not everything in the proposed Biden infrastructure bill fits in that narrow definition. The point here is not to debate what the real meaning of the word “infrastructure” is, but that to do the NPV calculation for things like expanding long-term care you’d need to come up with different estimates of the marginal product of that program for GDP, the relative price of purchasing long-term care, etc. Things like that are more human capital than public capital, and it is certainly possible to estimate the marginal product of human capital, the depreciation of human capital, and the relative price of purchasing human capital. I might get into that in a different post some day. But we’re over 2500 words at this point, so that’s all you get.&lt;/p&gt;

</description>
        <pubDate>Tue, 18 May 2021 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>How sensitive is GDP to capital?</title>
        <link>http://localhost:4000/feed/2021/04/28/Elasticity.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2021/04/28/Elasticity.html</guid>
        <description>&lt;p&gt;This is an odd post because it is an advertisement for a new paper that is …. in an advanced draft state? “Finished” is wrong because I’m about to embark on the roller-coaster that is submission and publication. But there are actual pages of text, and tables, and figures, and bibliography.&lt;/p&gt;

&lt;p&gt;The paper itself is titled &lt;a href=&quot;https://growthecon.com/assets/Elasticity-Master.pdf&quot;&gt;The Elasticity of Aggregate Output with Respect to Capital and Labor&lt;/a&gt;. Code and data for it can be found on &lt;a href=&quot;https://github.com/dvollrath/Elasticity&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you’re a bit of a growth geek and somehow find that title intriguing, you can jump right to the link and read. Happy to receive comments. Otherwise, the rest of this post is an extended abstract explaining the main findings and how I got them.&lt;/p&gt;

&lt;h3 id=&quot;alpha-equals-what&quot;&gt;Alpha equals what?&lt;/h3&gt;
&lt;p&gt;From a macro/policy perspective, it would be nice to know how sensitive GDP is to the stock of capital or the amount of labor used. Focusing on capital, I’d like to know the elasticity of GDP with respect to capital, or&lt;/p&gt;

\[\frac{d \ln Y}{d \ln K} = ??.\]

&lt;p&gt;Knowing that ?? number would inform me about things like the possible impact of a federal infrastructure bill, or the consequences of changes in savings behavior based on capital gains taxes, or the possible implications of demographic changes that influence home purchases and construction (capital goods). It’s got implications for how fast countries converge to steady state over time. It has a first-order effect on how we calculate TFP growth. It’s a relevant, important number, and you can make the same argument for why the elasticity of GDP with respect to labor is important.&lt;/p&gt;

&lt;p&gt;Probably the most commonly used assumption in macro, and maybe in all of economics, is that this elasticity with respect to capital is equal to one-third. It’s even got it’s own greek letter. Hence you’ll see “alpha equals one-third” in a million macro papers, which refers to the coefficient $\alpha$ on capital in a Cobb-Douglas production function. If you’ve taken an intermediate macro course, you’ve seen this,&lt;/p&gt;

\[Y = K^{\alpha}(AL)^{1-\alpha},\]

&lt;p&gt;or something very, very close to it. If you take logs of this, you can figure out that $d \ln Y/ d \ln K = \alpha$.&lt;/p&gt;

&lt;p&gt;That holds in general. Where does this idea that $\alpha = 1/3$ come from? That requires two big assumptions. First, it requires that there is such a thing as an aggregate production function. The existence of an aggregate production function requires a &lt;em&gt;lot&lt;/em&gt; of underlying assumptions to be true. &lt;a href=&quot;http://jesusfelipe.com/wp-content/uploads/2019/09/The-Aggregate-Production-Function-Not-Even-Wrong.pdf&quot;&gt;Felipe and McCombie&lt;/a&gt; refer to the aggregate production function as “not even wrong”, echoing Pauli’s assertion about a theory that was too incomplete to be used to make predictions. I think the best way to think about the issue is that an aggregate production function is pretending to be a statement about a physical relationship (e.g. combine two units of capital with three workers to get 12 widgets) as if it were a chemical formula. But because output is aggregate across goods using relative prices (and capital is handled similarly) the analogy just doesn’t hold.&lt;/p&gt;

&lt;p&gt;Second, the rule of thumb about $\alpha = 1/3$ depends on the assumption that there are no economic profits in the economy. Without economic profits, it would be the case that $1-\alpha = wL/Y$ if the economy were cost-minimizing, with $wL$ being total labor compensation. Since we see that $wL/Y$ is about 2/3 in the data (or was until recently), that means $1-\alpha$ is about 2/3, and therefore $\alpha$ is about 1/3.&lt;/p&gt;

&lt;p&gt;The common answer that “alpha equals on-third” delivers an answer to the question of what is the elasticity of GDP with respect to capital. But is it a meaningful answer, given that the assumptions it relies on are tenuous? It might be the right answer for a fictional economy that only exists on paper, but not in real life.&lt;/p&gt;

&lt;h3 id=&quot;higher-faster-farther&quot;&gt;Higher, faster, farther&lt;/h3&gt;
&lt;p&gt;Can we do better? Yes. Thanks to recent work in a series of papers by David Baqaee and the late Emmanuel Farhi (see &lt;a href=&quot;https://ideas.repec.org/a/wly/emetrp/v87y2019i4p1155-1203.html&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/25688.html&quot;&gt;here&lt;/a&gt; for what I think are the right places to start) it is possible to break with the strict assumptions lying behind the aggregate Cobb-Douglas function and the rule of thumb “alpha equals one-third”.&lt;/p&gt;

&lt;p&gt;In my paper, I’m taking their theory and calculating the elasticity $d \ln Y/ d \ln K$ (and a similar one for labor) while relaxing a bunch of the assumptions embedded in the rule of thumb. In particular, what do Baqaee and Farhi allow for?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Different units with different cost structures&lt;/strong&gt;. In my case, the economy will have a bunch of different industries, each responding to capital and labor in a unique way. There is no need to assume that all industries have a similar Cobb-Douglas formula, or that it is Cobb-Douglas at all. Conceptually the theory could allow one to do this with information on all firms or establishments, I just don’t have that kind of detail.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Input-output relationships&lt;/strong&gt;. Those industries can be suppliers to one another, as in real life. This means that the impact of some additional capital in one industry (e.g. a new truck) can have a cascade of effects on other industries by making their costs (e.g. of shipping) lower. The effect of capital on GDP depends on the network that connects these industries, and the aggregate elasticity I’m after is not just adding up the individual effects.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Frictions or markups&lt;/strong&gt;. One of the big problems above was that it assumed zero economic profits, which a whole host of recent research (and baseline intuition) tells us is wrong. Each industry may be charging a markup of price over costs, and that could be due to market power or some other friction. The Baqaee/Farhi setting is flexible enough that the source of that markup doesn’t matter.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Baqaee/Farhi show how to find the aggregate elasticity I want from the industry-level information on costs of labor and capital. Before we move on, a couple of comments. First, this is like one tiny sliver of the Baqaee/Farhi theoretical setting. There are a ton of additional insights to work with. Second, my implementation of this is &lt;em&gt;better&lt;/em&gt; than the rule of thumb, but it is not &lt;em&gt;perfect&lt;/em&gt;. If you had data on each individual establishment and worker you could conceptually do this in an even more refined manner, improving on the numbers I’ll show you below.&lt;/p&gt;

&lt;h3 id=&quot;garbage-in-garbage-out&quot;&gt;Garbage in, garbage out&lt;/h3&gt;
&lt;p&gt;Okay, so I implement what Baqaee/Farhi came up with. Was that really that hard? Yes, because the data you need to stick into the formula that Baqaee/Farhi come up with is not immediately available from any national account. The core pieces of information you need are, for each industry, their cost of labor, their cost of intermediates purchased from other industries, and their cost of capital.&lt;/p&gt;

&lt;p&gt;It’s this last one - the cost of capital - that creates the issue. The cost of capital is not reported in the national accounts, in large part because what we as economists consider the cost of capital is &lt;em&gt;not&lt;/em&gt; what businesses think of when they talk about costs. Here’s one way to think about this.&lt;/p&gt;

&lt;p&gt;When economists think of breaking down the value-added of an industry (it’s contribution to GDP) they do so in the following way&lt;/p&gt;

\[VA_i = COST_{iL} + COST_{iK} + EPROF_{i}\]

&lt;p&gt;or the value-added of industry $i$ gets accounted for by costs of labor (the first term), costs of capital (the second term), or economic profits (the last term). Those economic profits are often called “rents”, and refer to earnings the industry makes over and above the strict cost of production (labor and capital).&lt;/p&gt;

&lt;p&gt;When businesses or the BEA breaks down value-added of an industry they do so more like this&lt;/p&gt;

\[VA_i = COST_{iL} + GOS_{i}\]

&lt;p&gt;where the cost of labor is the same, but the second term is “Gross Operating Surplus”. That gross operating surplus combines the cost of capital and the economic profits of the industry. Why? Think of an industry (or firm) who owns their capital outright (as opposed to renting it in). There is no “cost of capital” to record in the books. Everything that isn’t a cost of labor is an accounting profit for them, and the distinction between accounting profits they make due to owning capital versus earning economic profits is irrelevant.&lt;/p&gt;

&lt;p&gt;But to do the Baqaee/Farhi calculation you have to have $COST_{iK}$. Gross operating surplus doesn’t cut it. So the game I play in my paper is coming up with various assumptions about how industries work to come up with estimates of $COST_{iK}$, and looking at what they imply for the elasticity of GDP with respect to capital.&lt;/p&gt;

&lt;p&gt;I can’t come up with a single elasticity. I instead provide you, dear reader, with a set of bounds between which the real elasticity probably lives. What are the bounds?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;No-profit upper bound&lt;/strong&gt;. The first assumption is to assume that economic profits are zero. In that case you can see from the two prior equations that $COST_{iK} = GOS_i$, so this is measurable from the national accounts. But wait, isn’t this just what I said the rule of thumb did wrong? Yes! It was one of the assumptions in the rule of thumb. But even with this I’m still able to allow for the multiple industries and the input-output relationships, so this is a mild improvement over the rule of thumb. With this no-profit assumption note that the cost of capital is as large as it could be, and hence the elasticity of GDP with respect to capital is going to be as large as it could be. Thus this represents an upper bound.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Depreciation lower bound&lt;/strong&gt;. The national accounts data don’t have a true cost of capital measure. But they have &lt;em&gt;some&lt;/em&gt; information on costs of capital. In particular, they report the depreciation of capital for each industry, which is something like the minimal cost of capital that each industry faces - stuff breaks or wears out. Using depreciation to proxy for $COST_{iK}$, I can calculate the elasticity of GDP with respect to capital. Because this is like the minimal amount of capital cost each industry faces, it also represents the lower bound for the elasticity.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I could also bore you for a while with having to match industry-level data up bewteen the input-output tables and the national accounts, which is tedious and annoying and I hated it and it took by far the most time in all of this. But none of you want to hear about that.&lt;/p&gt;

&lt;p&gt;What do I find? The figure below shows you the core result. The dashed line on top is the estimated elasticity of GDP with respect to capital when I use the no-profit assumption described, and the solid line on the bottom is the elasticity using the depreciation cost assumption. The real elasticity lives somewhere in that gray zone in between them. Note this isn’t a confidence interval, and there is nothing telling us that the real elasticity must be in the middle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/fig_cap_base_comparison.png&quot; alt=&quot;Base results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that for most of this period the elasticity lies below one-third, or the rule of thumb is probably over-stating how sensitive GDP is to capital. That possible changed around 1998, when the bounds both start to drift up. It doesn’t prove the actual elasticity changed, but starts to imply it. The rule of thumb isn’t exactly right, and it probably makes sense to think of this elasticity being lower than one-third, but not by a lot.&lt;/p&gt;

&lt;p&gt;Incidentally, the labor elasticity is just the reverse of this, as the labor elasticity is going to be one minus the capital elasticity. So turn your phone upside down and look at the figure and you’ll get the bounds for the labor elasticity.&lt;/p&gt;

&lt;p&gt;There are a lot of variations one can run with this, and that is a lot of what the paper does. One version that I find interesting is to consider the elasticity of private business sector output with respect to capital. The private business sector is GDP minus housing and the government. The next figure shows you the same kinds of bounds (no-profit and depreciation) for this more limited slice of the economy.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/fig_cap_priv_comparison.png&quot; alt=&quot;Base results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The range is shifted down by about 0.05 or so everywhere. That means the private business sector is less sensitive to capital than the economy as a whole. Why? Mainly because housing value-added is very, &lt;em&gt;very&lt;/em&gt;, sensitive to capital. Remember, the BEA imputes the value-added from housing as the rents that you would pay yourself for living in your home. That imputed rent almost all ends up being attributed as a capital cost rather than a labor cost. A big reason that one-third is even plausible as an upper bound for the elasticity is because housing is extremely sensitive to capital. Absent that, the economy appears to be less sensitive as a whole.&lt;/p&gt;

&lt;h3 id=&quot;um-so-who-cares&quot;&gt;Um, so who cares?&lt;/h3&gt;
&lt;p&gt;One of the things that this elasticity gets used for is in backing out TFP growth. The standard way to calculate TFP growth is as follows&lt;/p&gt;

\[d \ln TFP_t = d \ln Y_t - \epsilon_K d \ln K_t - \epsilon_L d \ln L_t\]

&lt;p&gt;which shows that TFP growth is just what is “left over” after you subtract off the growth of capital and labor from the growth in GDP. The weights on the growth rate of capital and labor are the elasticities, $\epsilon_K$ and $\epsilon_L$. These elasticities are what I was calculating above, and I’m just using the greek letters here as shorthand.&lt;/p&gt;

&lt;p&gt;If you go to the BLS and look at their TFP growth estimates, they infer $\epsilon_K$ and $\epsilon_L$ using a similar rule of thumb to $\alpha = 1/3$. They don’t assume that $\epsilon_K$ is literally fixed for all time, but they do assume that they can back out the value of $\epsilon_L$ and $\epsilon_K$ using the no-profit assumption. That means they are using the highest possible estimate for $\epsilon_K$, and the lowest possible one for $\epsilon_L$. But we know this is an extreme assumption, so it may well be over or understating TFP growth.&lt;/p&gt;

&lt;p&gt;What do you get if you use different estimates of $\epsilon_K$ and $\epsilon_L$, based on the Baqaee/Farhi calculations I do? Then this changes the implied growth rate of TFP, and hence the implied path of TFP over time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/fig_tfp_comparison.png&quot; alt=&quot;TFP&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this figure, the lowest line matches what the BLS calculates for the level of TFP over time (starting from a baseline of 100 in 1948). The other lines show the implied path of TFP when you use different estimates of $\epsilon_K$ and $\epsilon_L$ depending on the assumptions about capital costs. The top solid line is when you use depreciation costs to measure capital costs, and the implied elasticity on capital is lower (and the elasticity on labor is higher). TFP ends up higher by about 20% (a little over 300 versus about 250 in 2018). The intermediate cases are based on some other assumptions about capital costs that lead to different estimates of $\epsilon_K$ and $\epsilon_L$.&lt;/p&gt;

&lt;p&gt;Nothing about this changes the general picture of TFP growth over time. There’s a slowdown in the 1970s into the 1980s. There is more rapid growth in the late 1990s. There is another slowdown in the 21st century. But the implied growth rate the BLS gets is almost certainly a &lt;em&gt;lower&lt;/em&gt; bound to actual TFP growth. Which means the level of TFP is higher today than the BLS would imply, and that the trend growth rate is slightly higher than they would tell you.&lt;/p&gt;

&lt;p&gt;I think there are a number of other applications of these elasticities. The Baqaee/Farhi setting gives you the ability to talk about a very complex production side of the economy (I/O relationships, multiple industries, markups) in a very concise way. These elasticities give you the sensitivity of the aggregate economy to capital and labor with all those complications already embedded in them. It means you can answer questions about policy, demographics, and TFP for an economy with all those complications, but without having to &lt;em&gt;model&lt;/em&gt; all those complications explicitly. The elasticities are sufficient for a lot of purposes.&lt;/p&gt;

&lt;p&gt;As I said above, this is not definitive. One could drill down even further and come up with even more refined estimates of those elasticities. But it is an improvement on the rule of thumb, and gives some sense of how that rule of thumb likely overshoots the right elasticity with respect to capital (and undershoots it with respect to labor).&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Apr 2021 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Pandemic relief and potential GDP (plus CBO methodology appendices!)</title>
        <link>http://localhost:4000/feed/2021/03/24/CBO-Potential.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2021/03/24/CBO-Potential.html</guid>
        <description>&lt;p&gt;The figure below is from the &lt;a href=&quot;https://www.hamiltonproject.org/blog/the_macroeconomic_implications_of_bidens_1.9_trillion_fiscal_package&quot;&gt;Hamilton Project&lt;/a&gt; but you could have found something similar in a lot of evaluations of the relief bill. It compares the projected path of GDP with the relief bill to the CBO projection of potential GDP formed in January 2020, prior to the pandemic.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/hamiltonfig1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see it projects that the relief bill will put us the earlier CBO projection by the end of 2021 and early in 2022. This is one argument used against the bill, or at least against the size of the bill. The idea is that the relief bill will “overheat” the economy or cause the economy to run “over potential”. Some leave that complaint as is, assuming it is self-evident that this would be bad. Others take time to explain that they think running above potential raises the risk of inflation.&lt;/p&gt;

&lt;p&gt;The problem is that while the CBO refers to their projection as “potential GDP”, that is misleading. When most people think of “potential GDP” they think “The maximum GDP that we could produce before running into physical constraints”, or “The maximum GDP that we can produce before firms start jacking up prices rather than expanding real production”. That is the notion of “potential GDP” that lies at the heart of this particular inflation-based argument against the relief bill.&lt;/p&gt;

&lt;p&gt;However, what the CBO projection actually means is “The GDP you might get if the economy was sorta like in 2005, but we took into account population aging”. It has nothing to do with physical limits, and nothing to do with firms being willing or able to increase output.&lt;/p&gt;

&lt;p&gt;I’m going to walk through how the CBO projection is formed, and why my slightly snarky definition is in fact the correct one. And it might come off like I’m dumping on the CBO. I’m not. Aside from some quibbles about semantics, the numbers they produce are useful for specific purposes. The problem is that people use these numbers for the &lt;em&gt;wrong&lt;/em&gt; purposes, mainly because they don’t understand how these projections are formed.&lt;/p&gt;

&lt;p&gt;I’m not dismissing &lt;em&gt;all&lt;/em&gt; arguments about inflation risks from the relief bill, I’m just working through this &lt;em&gt;one&lt;/em&gt; argument about inflation risk, and why it is probably unfounded.&lt;/p&gt;

&lt;p&gt;Oh, since apparently you are only allowed to have an opinion on inflation risks if you were alive during the 1970s, I’ll just say that I have sat in a car waiting in a gas line, watched the original Muppet Show when it was on broadcast TV, and at some point owned plaid bell-bottom pants.&lt;/p&gt;

&lt;p&gt;Having established my macro credentials, let’s get started.&lt;/p&gt;

&lt;h3 id=&quot;you-have-no-potential&quot;&gt;You have no potential&lt;/h3&gt;
&lt;p&gt;The answer, as always, is to read the f$&amp;amp;#ing manual. You can find the CBO methodology from 2018 &lt;a href=&quot;https://www.cbo.gov/publication/53558&quot;&gt;here&lt;/a&gt;. That site includes software and data you can download to replicate their projections, although it is written for EViews. So for the four of you out there that still use EViews, it is your time to shine. There is also a supplement on estimating labor force participation &lt;a href=&quot;https://www.cbo.gov/system/files/115th-congress-2017-2018/workingpaper/53616-wp-laborforceparticipation.pdf&quot;&gt;here&lt;/a&gt; that is relevant to the process.&lt;/p&gt;

&lt;p&gt;“Potential GDP” is a terrible description for what the CBO estimates. “Smoothed historical GDP” is more accurate. The figure below is from the methodology paper linked above. The dashed blue line is “potential GDP”, and you can see that it is a smoothed version of actual GDP. Their goal is just to remove business cycle effects.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/cbofig8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can also see that we have to distinguish between the historical series of potential GDP (1950-2018), and the projected series of potential GDP (after 2018). The projected series, which is what went into that Hamilton Project figure that I started with, is based on information from the historical series, along with assumptions about things like productivity growth.&lt;/p&gt;

&lt;p&gt;That projected series is what is important here, as it forms the basis of the argument that the relief bill will “overheat” the economy. So let’s break down how the CBO forms that projection.&lt;/p&gt;

&lt;p&gt;Projected GDP for the CBO comes from a basic Cobb-Douglas production function&lt;/p&gt;

\[Y^{Proj} = A^{Proj} \left(K^{Proj}\right)^{\alpha} \left(E^{Proj}\right)^{1-\alpha}.\]

&lt;p&gt;To create an estimate of projected GDP they need an estimate of the projected size of each of these three items: TFP (A), capital (K), and employed labor (E). In each case they are extrapolations and/or flat-out guesses based on the smoothed historical series, and &lt;em&gt;not&lt;/em&gt; based on some notion of physical capacity or limits on production.&lt;/p&gt;

&lt;p&gt;Let’s start with TFP. “The agency therefore applies a substantial degree of judgement to its projections of potential TFP rather than simply projecting the most recent estimated trend,” (p. 35 in the 2018 report). Well, of course they do. There is no way to project TFP into the future that isn’t just a wild-ass guess. As the CBO notes in their report, TFP tends to grow at a steady rate for a while….until it doesn’t. And you don’t know when one of these jumps up or down in the growth rate of TFP is going to occur.&lt;/p&gt;

&lt;p&gt;What the CBO does is assume that the rate of TFP growth will converge from its recent short-run trend (say about 0.7% per year) to a long-run average growth rate (say about 1.2% per year). This isn’t any worse or better than just assuming the rate will stay at 0.7%, or jump to 2%, or anything else.&lt;/p&gt;

&lt;p&gt;But it is clear that this isn’t an estimate of how fast TFP &lt;em&gt;could&lt;/em&gt; grow. It’s not an upper bound on the rate of TFP growth, above which the economy couldn’t possibly go.&lt;/p&gt;

&lt;h3 id=&quot;work-it&quot;&gt;Work it&lt;/h3&gt;
&lt;p&gt;The second, and more relevant, piece of information going into the CBO projection is employment, E. In principle, what the CBO is projecting for employment is&lt;/p&gt;

\[E^{Proj} = (1-u^{Proj}) \times LFPR^{Proj} \times POP^{Proj}\]

&lt;p&gt;where $u^{Proj}$ is the projected unemployment rate, $LFPR^{Proj}$ is the labor force participation rate, and $POP^{Proj}$ is the working-age population. In practice, this is a sum of employment projections for 516 different sub-groups distinguished by age, sex, race/ethnicity, and education. The second link above about labor force projections gives you all the info you want about how those sub-groups are formed.&lt;/p&gt;

&lt;p&gt;Regardless, the game for the CBO projection goes like this. First, get the projected working age population, $POP^{Proj}$. That’s pretty easily done from normal demographic tables, and in that sense there is little that is controversial about it.&lt;/p&gt;

&lt;p&gt;Next they need to come up with a projected labor-force participation rate and projected unemployment rate (for each group). Here is where the CBO’s meaning of “potential” comes into focus, and why it does not mean what you think it means.&lt;/p&gt;

&lt;h4 id=&quot;participation-rates&quot;&gt;Participation rates&lt;/h4&gt;
&lt;p&gt;The projected labor-force participation rate is found primarily by taking the average or smoothed LFPR from the past for each sub-group, while also incorporating a few actual projections by the CBO of the effects of federal policies. But the projection is not what the LFPR &lt;em&gt;could&lt;/em&gt; be, it is what the LFPR &lt;em&gt;was&lt;/em&gt; during “normal” economic times in the past. For example, if married females with young children had a low LFPR in the past, then the CBO projects them to have a low LFPR in the future. There is no sense of potential LFPR here, in the sense of asking what the LFPR of married females with young children &lt;em&gt;could&lt;/em&gt; be.&lt;/p&gt;

&lt;p&gt;The same idea holds with all the LFPR projected on the basis of race/ethnicity, disability, education attainment, birth-year, and the like. The CBO embeds all the accrued historical factors leading to variation in the LFPR across groups into their projection. It’s a sensible way to approach the projection. And it is probably a good projection of what LFPR will be in the next few years. But it is not a measure of some physical upper bound on how much the economy could produce.&lt;/p&gt;

&lt;p&gt;Take the birth-year cohort effects they embed in their projection. This is the observation that some cohorts happen to have lower LFPR than others, presumably because of past experiences in the job market. Think of kids born around 1988-1992, who graduated from HS or college around 2009-10, had no luck finding entry level jobs, and now are more likely to be out of the labor force because of that experience. The CBO projection assumes that this cohort will &lt;em&gt;always&lt;/em&gt; participate less in the labor force in the future. It is as if there is a fixed technological limit to their participation.&lt;/p&gt;

&lt;p&gt;Age effects dominate the projection of LFPR by the CBO. Given historical patterns of LFPR, the aging of Baby Boomers is projected to lower the LFPR by 2.8 percentage points from 2017-2028. The historical pattern implies that LFPR starts to fall at age 50, well before standard retirement age. Does this mean that this represents a physical limit on the ability to work by people aged 50+? Is it literally impossible that more people over 50 might continue to work? If the answer is no, then the CBO projection doesn’t represent an upper bound on LFPR.&lt;/p&gt;

&lt;p&gt;Again, the CBO is not doing anything wrong. The mistake lies is interpreting the CBO projection of LFPR as some unbreakable limit on labor-force participation (and hence GDP).&lt;/p&gt;

&lt;h4 id=&quot;unemployment-rates&quot;&gt;Unemployment rates&lt;/h4&gt;
&lt;p&gt;The last bit involved in the projection of employment is the unemployment rate, $u^{Proj}$. Again, the CBO is going to actually project the unemployment rate for all the different sub-groups they track, and again they are going to assume that historical unemployment rates during “normal” economic times will continue in the future.&lt;/p&gt;

&lt;p&gt;What constitutes “normal”? Well, here is a screenshot of Appendix B of the CBO’s 2018 documentation on potential GDP calculations, and you can use the link above to go look it up yourself.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/cboapp1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The “natural rate” for each one of the sub-groups tracked by the CBO is assumed to be whatever the unemployment rate was for that group in …. 2005? Because 2005 was the year when unemployment rates were “natural” and unaffected by a business cycle, apparently. Let that settle in for a little bit, and think about it. This has all of the same issues as the projection of LFPR.&lt;/p&gt;

&lt;p&gt;The unemployment rate for those with less than a HS diploma, aged 25+, was 7.4% in December 2005. The CBO methodology assumes that this is the natural rate of unemployment for that group, hence they project that the unemployment rate for this group will be 7.4% in the future. As with LFPR, does this imply that 7.4% is a physical limit on how low the unemployment rate can go for those with less than a HS diploma? No, of course not.&lt;/p&gt;

&lt;p&gt;There is no sense that the CBO projection represents a lower bound on unemployment (and hence an upper bound on employment). It’s just using a guess as to what a “normal” economy might look like. It is a mistake to use this projection as an upper bound on what the economy &lt;em&gt;could&lt;/em&gt; do in the future.&lt;/p&gt;

&lt;h3 id=&quot;so-what-is-it&quot;&gt;So what is it?&lt;/h3&gt;
&lt;p&gt;What, then, is the CBO projection found in the first figure of this post telling us? At the beginning of the post I said it was: “The GDP you might get if the economy was sorta like in 2005, but we took into account population aging.” And that is the right way to look at it.&lt;/p&gt;

&lt;p&gt;Their projection involves a guess about the future path of TFP growth. Not an unreasonable guess, but a guess. Their projection then involves a projection of labor-force participation rates based on historical experience, and population aging implies that this participation rate will continue to fall. Last, they plug in unemployment numbers from 2005 to figure out how many people will actually be working. I didn’t cover their assumptions about capital services because those get really into the weeds and from what I can tell have only a marginal impact on their projection.&lt;/p&gt;

&lt;p&gt;Unfortunately they call this projection “potential GDP” and I think that screws a lot of people up. The words “potential GDP” connote some sort of upper bound or hypothetical limit. The CBO projections are nothing of the sort. Using “potential GDP” as a reference point to argue about the likelihood of inflation is wrong. Not wrong-technically-but-kinda-sorta-okay-anyway, just wrong.&lt;/p&gt;

&lt;p&gt;It is quite possible for actual GDP to be above their potential GDP and yet no increase in inflation can occur. We just saw almost four years of that being the case. It also is quite possible for actual GDP to be &lt;em&gt;below&lt;/em&gt; CBO potential GDP and yet see an increase in inflation, perhaps because Jay Powell starts doing shrooms. There is no mechanical relationship between actual GDP, CBO potential GDP, and inflation. There isn’t even a solid empirical regularity.&lt;/p&gt;

&lt;p&gt;Here is where I am going to chuck some rocks in the CBO’s direction. Even &lt;em&gt;they&lt;/em&gt; succumb to this notion that their projection has some real meaning regarding upper bounds. They use a form of this definition at various points throughout their documentation.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Potential output is the amount of real GDP that can be produced if labor and capital are employed at maximum sustainable rates.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What is the definition of “sustainable”? None is given by the CBO. It implies that their projection represents some sort of hard limit we must be wary of crossing lest …. some undefined entity be not sustained. Like, if the unemployment rate for people without HS diplomas drops below 7.4% will the sun explode? If TFP growth turns out to be higher than that guess, does &lt;em&gt;that&lt;/em&gt; mean the sun explodes? Should I be worried about a Chernobyl type incident?&lt;/p&gt;

&lt;p&gt;If you want to jump in with “sustainable means not increasing the inflation rate”, then you better be prepared to explain why 2005 is the crux of all macroeconomic history around which inflation expectations were formed. You also have to explain why people forming inflation expectations are savvy enough to account for population aging and other demographic trends, but too stupid to understand when TFP growth over- or under-shoots a guess made by the CBO. Oh, you’d also need to come up with a coherent explanation for why 1-1.5% inflation is okay, why 2-2.5% inflation is not, and why if inflation did get to 2-2.5% the Fed would suddenly lose the ability to influence said inflation rate.&lt;/p&gt;

&lt;p&gt;I love you, CBO peeps. But you gotta clean up the language on this, because the projections are getting misused to make bad economic arguments.&lt;/p&gt;

&lt;p&gt;Your projections are “The GDP you might get if the economy was sorta like in 2005, but we took into account population aging.” That’s a really useful set of numbers! It just isn’t a set of numbers that have much, if anything, to do with the prospects of future inflation.&lt;/p&gt;

</description>
        <pubDate>Wed, 24 Mar 2021 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Judge me by my TFP, do you?</title>
        <link>http://localhost:4000/feed/2021/02/01/TFP-Again.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2021/02/01/TFP-Again.html</guid>
        <description>&lt;p&gt;I told you in the last post that I’m agnostic about the relationship of TFP and innovation. That was part of an on-going debate, mainly with &lt;a href=&quot;https://twitter.com/elidourado&quot;&gt;Eli Dourado&lt;/a&gt;. I want to pause at the outset to say that this debate is &lt;em&gt;great&lt;/em&gt;. It’s been respectful, interesting, and forced me to think hard about some things. So welcome to the 0.0001% of the internet that does not make you want to gouge your eyes out.&lt;/p&gt;

&lt;p&gt;In the spirit of that, I’m going to start by telling you about how Eli is &lt;em&gt;right&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;And then I’m going to blow another 1200 words saying “Well, actually….”. It is a &lt;em&gt;debate&lt;/em&gt;, after all.&lt;/p&gt;

&lt;h3 id=&quot;seeing-the-light&quot;&gt;Seeing the light&lt;/h3&gt;
&lt;p&gt;I’m paraphrasing what has been happening on Twitter and the blog, but I think I have all the important aspects of the discussion. The general question is whether TFP (or growth in TFP) is (a) something that is a useful metric for how innovative we have been and (b) is a useful thing to &lt;em&gt;target&lt;/em&gt; as part of future innovation. The recent debate and this post are mainly about (b). Should we innovate with the goal of making TFP growth higher?&lt;/p&gt;

&lt;p&gt;Let’s say that we have just two industries: Good and Services. Goods are, say, 33% of GDP, and Services are the other 67%. The question was then, would you rather have 10% productivity growth in Goods (and 1/3 x 10% = 3.3% TFP growth), or 10% productivity growth in Services (and 2/3 x 10% = 6.67% TFP growth)?&lt;/p&gt;

&lt;p&gt;Eli’s answer was that because of the larger GDP share of Services, you’d want to focus there, as it would ensure maximum TFP growth. My initial response was that this wasn’t necessarily true, and it depended on things like elasticities of demand and such.&lt;/p&gt;

&lt;p&gt;In thinking about it more, Eli is right under most reasonable assumptions about the world. I might be &lt;em&gt;technically&lt;/em&gt; correct that it depends, but only in weird edge cases that don’t seem applicable.&lt;/p&gt;

&lt;p&gt;Why is he right? Because the weights in GDP are …. the weights in GDP. If Services account for 2/3 of our output, then increasing productivity by 10% for 2/3 of what we produce is better than increasing productivity by 10% for 1/3 of what we produce. That is going to be true whether Goods and Services are complements or substitutes.&lt;/p&gt;

&lt;p&gt;One thing I brought up in the last post is that the weights might change in response. That’s fine here, as per Eli’s algorithm you just keep pushing for productivity increases in the larger industry each period. So if you chose 10% productivity growth in Services today when they are 2/3 of GDP, that might cause (because things are complements) their share of GDP to fall to 1/3 (and Goods to rise to 2/3). Then &lt;em&gt;tomorrow&lt;/em&gt; you would want to push for 10% productivity growth in Goods, as it would be the larger industry. With complements you are bouncing around trying to push up productivity in &lt;em&gt;all&lt;/em&gt; industries over time because you care about consuming all things.&lt;/p&gt;

&lt;h3 id=&quot;research-effetiveness&quot;&gt;Research effetiveness&lt;/h3&gt;
&lt;p&gt;This is not my Damascene conversion, however. While acknowledging Eli’s point, I think there are other reasons it is not the appropriate way to think about using TFP to guide or measure innovation.&lt;/p&gt;

&lt;p&gt;The first is that it isn’t possible to choose between “10% productivity growth in Goods or 10% productivity growth in Services”. Our actual choice is about how to allocate scarce resources: R&amp;amp;D dollars, time, and brainpower. How those resources translate into productivity growth is not obvious, and there is no reason to believe that this translation is similar in both Goods and Services. 10 “units” of R&amp;amp;D may deliver 9% growth in Goods productivity, but perhaps only 3% in Services.&lt;/p&gt;

&lt;p&gt;There is plenty of prima facie evidence that productivity growth in Services is much harder to achieve than in Goods. Baumol’s original work on the cost disease was centered around why this was the case. I did a &lt;a href=&quot;https://growthecon.com/blog/What-You-Spend/&quot;&gt;long post&lt;/a&gt; on this, and why the nature of time/labor use in different activities makes productivity growth easier or harder to achieve. More broadly, there is nothing to suggest that an equal amount of research effort on any specific project would yield precisely the same productivity improvement as another project.&lt;/p&gt;

&lt;p&gt;What we really need to know is the relationship of productivity growth to R&amp;amp;D resources (or brainpower or time) for each industry individually. Here’s a quick example. If we put all our R&amp;amp;D resources into Goods, we could achieve 9% productivity growth, but if we put them towards Services we get only 3% productivity growth. Now, given the same GDP shares above, which is better?&lt;/p&gt;

&lt;p&gt;The math is pretty straightforward. 1/3 times 9% is 3% growth in overall TFP if we choose Goods. 2/3 times 3% is 2% growth in overall TFP if we choose Services. In this case it would be better to choose Goods. More generally, if the effectiveness of R&amp;amp;D resources in Services in less than half of what it is in Goods, then you should choose Goods.&lt;/p&gt;

&lt;p&gt;That decision point changes as the GDP shares change, as you’d expect. But the general point remains, and this isn’t some weird edge case I’m talking about. This is the observation that if you want to use TFP to allocate your R&amp;amp;D, you have to know the relationship of that R&amp;amp;D to productivity growth in all the different possible avenues for that R&amp;amp;D. The size of the industry is necessary to decide where you target R&amp;amp;D (big is good), but it is not sufficient.&lt;/p&gt;

&lt;p&gt;How would you know the effectiveness of R&amp;amp;D resources? It depends on expected values of possible research projects, their probabilities of succeeding, and the cost of each one. In other words, there is no way you could assess all the possibilities. This is the kind of thing where I think you want prices to work their magic, in all their Hayekian information-discovery glory, and let the market figure out what the most efficient allocation of R&amp;amp;D resources would be.&lt;/p&gt;

&lt;p&gt;Which doesn’t mean you can’t push in certain directions, but hold onto that idea for a moment.&lt;/p&gt;

&lt;h3 id=&quot;the-magic-of-miscellaneous-profession-services&quot;&gt;The magic of miscellaneous profession services?&lt;/h3&gt;
&lt;p&gt;If we leave aside this issue of R&amp;amp;D effectiveness, there is still the question of using the GDP shares to target things. Which GDP shares? There are multiple ways to break down GDP across industries, sub-industries, and so on. The input/output account at the BEA tracks 71 industries, but also has a more refined breakdown across about 400 sub-industries. Which one do we use to target R&amp;amp;D?&lt;/p&gt;

&lt;p&gt;If we stick with the 71, are we sure these are comparable? The NAICS codes that define these 71 industries were an outgrowth of SIC codes, and both sets of codes are skewed towards tracking manufacturing. Meaning that they are much more fine-grained within manufacturing than they are within services. So all the manufacturing industries will tend to look small because they are separated.&lt;/p&gt;

&lt;p&gt;In 2018 the largest share is for “Misc. professional, technical, and scientific services”, at 13.6%. Wholesale trade is 10.9%. “Other Real Estate” is 9.8%, while “Housing” is 9.7%. “Admin and support services” is 8.9%.&lt;/p&gt;

&lt;p&gt;Just for comparison, “Electrical equipment” is 1%. “Data processing, internet publication, etc.” is 2.5%. “Publishing (incl. software)” is 1.6%. “Hospitals” are 2.4%. “Ambulatory health care” is 3.8%. “Chemical products (incl. pharma)” is 4.6%. If I add up all the industries associated with energy production, I get to about 7%.&lt;/p&gt;

&lt;p&gt;Do we use these shares to make our decisions? Does focusing on “Misc. professional, technical, and scientific services” sound right compared to energy? Do we want innovation in “Other real estate” relative to hospitals, pharmaceuticals, or health care in general?&lt;/p&gt;

&lt;p&gt;If I add up &lt;em&gt;all&lt;/em&gt; the manufacturing industries, I can get to a number like 25-30%. So does that mean we should focus on manufacturing over Wholesale Trade? Or do I add Wholesale and Retail together? Do we focus on manufacturing to exclusion of everything other industry, because when disaggregated they happen to be smaller?&lt;/p&gt;

&lt;p&gt;Our attempt to try and focus R&amp;amp;D using possible TFP growth is going to be arbitrary, as there is no “right” way to classify economic activity. The classification is a choice, and we could justify all sorts of R&amp;amp;D spending allocations by making different choices, even if we had perfect information on the effectiveness of R&amp;amp;D.&lt;/p&gt;

&lt;h3 id=&quot;unpriced-goods&quot;&gt;Unpriced goods&lt;/h3&gt;
&lt;p&gt;Ok, the last section was a little snotty, I admit. I have a long-standing annoyance with industrial classification systems that are too focused on “industrial” due to inertia and a notion that the only thing that counts as “real” economic activity involves steel. Which is entirely besides the point.&lt;/p&gt;

&lt;p&gt;More relevant for this post is how even if we &lt;em&gt;did&lt;/em&gt; trust our industrial classifications, they probably don’t point us towards a welfare-maximizing allocation of R&amp;amp;D. That’s because a lot of what we (I think) hope to innovate on is unpriced and not included in GDP.&lt;/p&gt;

&lt;p&gt;The clear example here is energy and climate change. Based solely on its contribution to GDP, the energy industry would not attract a ton of innovation. As I noted above, it is only about 7% of GDP. Energy is already cheap. That’s not the problem. The problem is that it’s dirty.&lt;/p&gt;

&lt;p&gt;From an overall welfare standpoint we care about &lt;em&gt;clean&lt;/em&gt; energy. But because the cleanliness of energy doesn’t show up in GDP, it doesn’t show up in TFP. Hence TFP could well be underweighting the importance of innovation in energy relative to other areas.&lt;/p&gt;

&lt;p&gt;Go back to the original question above. Let’s say that the hypothetical 10% increase in productivity in Services does just that, but has no impact on the environment. But the hypothetical 10% increase in productivity of Goods &lt;em&gt;also&lt;/em&gt; involved a reduction in emissions or pollution (e.g. solar panels make electricity cheaper &lt;em&gt;and&lt;/em&gt; cleaner). Then the value of doing innovation on Goods could well be higher than doing innovation on Services, even though Services make up a larger part of GDP, and even though innovating on Goods would result in lower measured TFP growth.&lt;/p&gt;

&lt;p&gt;“Could well be higher” is the problem. We don’t know the weight to put on the environmental benefits from Goods innovation. But not knowing the weight doesn’t mean the weight is zero. Unfortunately looking only at TFP assumes that weight is exactly zero.&lt;/p&gt;

&lt;p&gt;The most concise way of stating it is that GDP (and GDP share) is measured at market prices, and those market prices don’t incorporate (all) externalities. To the extent you can, you want to institute subsidies and taxes to build in those externalities. Those externalities would make the GDP share of dirty or unhealthy industries higher, and the GDP share of clean or healthy industries lower. Eli’s decision mechanism would get closer to the right answer on innovation if the shares reflected the externalities.&lt;/p&gt;

&lt;p&gt;But even if you did that you’d still have the problem with unknown research effectiveness. At this point, though, if we got the prices to reflect the externalities you could let the Hayek-info-discovery price mechanism do it’s magic, and it would shunt resources towards the highest value innovations. Which I don’t think Eli would disagree with. He’s right that you want to push R&amp;amp;D towards the most valuable use. I think we just disagree on how to establish that value.&lt;/p&gt;

&lt;p&gt;I’m clinging to my TFP agnosticism for now.&lt;/p&gt;

&lt;p&gt;Oh, remember that nice comment about the quality of the debate and the 0.0001% of the internet that doesn’t suck? Yeah, about that:&lt;/p&gt;

&lt;p&gt;Ted Cruz is a seditious grifter who should resign.&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Feb 2021 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>TFP Agnosticism</title>
        <link>http://localhost:4000/feed/2021/01/29/TFP-Future.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2021/01/29/TFP-Future.html</guid>
        <description>&lt;p&gt;In some recent Twittering, &lt;a href=&quot;https://twitter.com/elidourado&quot;&gt;Eli Dourado&lt;/a&gt; pointed to the “Gordon/Vollrath” view that stagnation is normal, healthy, and a sign of success. I guess it is kind of cool that I have a notable view, and being associated in some way with Bob Gordon is a nice honor for me (not sure how he feels about it). I made a few attempts to clarify what I thought about that view, but in the end I didn’t think I could pin it down on Twitter, so here we are.&lt;/p&gt;

&lt;p&gt;The overall question of how we should view measures of TFP and innovation ranges beyond just this discussion with Eli. I’m going to pool Eli and others into a group I’ll call “TFP Believers”. As for myself, I’m going to call myself a “TFP Agnostic”.&lt;/p&gt;

&lt;p&gt;The Believers and I agree on the following. Innovation is crucial to improving well-being. We need innovation to cure diseases, clean the environment, and do all sorts of other things that would make life better. There is a &lt;a href=&quot;https://www.economist.com/leaders/2021/01/16/why-a-dawn-of-technological-optimism-is-breaking&quot;&gt;growing sense&lt;/a&gt; that a new burst of innovation is occurring or coming, and that to be encouraged by and excited about. Innovations are what make life better.&lt;/p&gt;

&lt;p&gt;Here’s where I think we disagree. Believers think TFP growth is a meaingful measure of that innovation. Hence, if there is a coming burst of innovation it will show up as higher measured TFP growth. Moreover, we should be actively trying to raise measured TFP growth through policies or whatever is at hand.&lt;/p&gt;

&lt;p&gt;I, on the other hand, do not think that TFP growth measures innovation, per se. Hence, I do not worry much about the rate of TFP growth. I would use policy or whatever is at hand to encourage innovation, whether that has a meaningful effect on TFP growth or not.&lt;/p&gt;

&lt;p&gt;We have the same ultimate goal, which is for innovation to lead to greater well-being. I think all we really disagree about is how to measure that.&lt;/p&gt;

&lt;p&gt;I don’t deny that innovation plays a part in TFP. My problem is that so many &lt;em&gt;other&lt;/em&gt; things go into TFP that it ends up a very noisy, imperfect measure of innovation. Using TFP to measure innovation is like using a pedometer to measure your VO2 max. Is there a connection? Yes, to the extent that having a high VO2 max means you &lt;em&gt;could&lt;/em&gt; take more steps. Is that connection confounded by a host of other factors? Yes. Could you conceive of a very particular set of assumptions and conditions under which the number of steps you take is perfectly correlated with your VO2 max? Sure, in a bio-mechanics lab somewhere. Does we actually live in a bio-mechanics lab? No.&lt;/p&gt;

&lt;p&gt;TFP isn’t built to measure innovation, just like a pedometer isn’t built to measure VO2 max. Hence my agnosticism.&lt;/p&gt;

&lt;h3 id=&quot;turtles-all-the-way-down&quot;&gt;Turtles all the way down&lt;/h3&gt;
&lt;p&gt;TFP is the sum of technical efficiency and allocative efficiency. Technical efficiency is the weighted average of industry-specific productivity growth rates. Allocative efficiency is an adjustment for whether factors of production like labor or capital are misallocated or not.&lt;/p&gt;

&lt;p&gt;Where does innovation fit in here? It presumably is what drives the industry-specific productivity growth rates. But since industries are made up of sub-industries, that means industry-specific productivity growth rates are a weighted average of sub-industry-specific productivity growth rates plus an adjustment for allocative efficiency within that industry. So innovation could be what drives &lt;em&gt;sub&lt;/em&gt;-industry-specific productivity growth rates.&lt;/p&gt;

&lt;p&gt;But sub-industry-specific productivity growth rates are made up of sub-sub-industry-specific productivity growth rates plus an allocative efficiency piece. So innovation could really be what drives &lt;em&gt;sub-sub&lt;/em&gt;-industry-specific productivity growth rates. And so on. It’s turtles all the way down.&lt;/p&gt;

&lt;p&gt;What is the right level to stop at to measure real innovation? At what point in the disaggregation do we reach the point where innovation &lt;em&gt;actually&lt;/em&gt; occurs. We don’t know. But if you want TFP to measure innovation you have to know. You’ll get different answers for aggregate technical efficiency depending on how disaggregated your data are. Does it make sense that our measure of innovation should depend on which level NAICS code the BLS decided to use?&lt;/p&gt;

&lt;p&gt;The only way the disaggregation &lt;em&gt;doesn’t&lt;/em&gt; matter is if all those allocative efficiency terms at every level are zero. They are zero in an economy where all factors of production (capital, labor, etc.) are allocated such that marginal products are perfectly equal across units. Which is the economic equivalent of the bio-mechanics lab. We don’t live in that lab.&lt;/p&gt;

&lt;h3 id=&quot;weights-and-measures&quot;&gt;Weights and measures&lt;/h3&gt;
&lt;p&gt;The disaggregation issue is my first problem. The second is that the weights in those various weighted averages &lt;em&gt;change&lt;/em&gt; due to innovation, and thus the growth rate of TFP could change even if the amount of innovation does not.&lt;/p&gt;

&lt;p&gt;I think this is easiest to see with an example. Let’s have two industries, A and B. Then aggregate TFP growth is&lt;/p&gt;

\[g_{TFP} = w_A g_{A,TFP} + w_B g_{B,TFP} + AE.\]

&lt;p&gt;The weights are $w_A$ and $w_B$, and the growth rate of TFP in the two industries are $g_{A,TFP}$ and $g_{B,TFP}$. That “AE” is the allocative efficiency stuff I’ll get to later.&lt;/p&gt;

&lt;p&gt;We’re going to ignore all the disaggregation problems I just cited and assume that $g_{A,TFP}$ and $g_{B,TFP}$ are in fact picking up the effect of innovation on the productivity of industries A and B. A is going to be our “innovative” industry, with $g_{A,TFP}$ of 3%, and B is going to be our “stagnant” industry with $g_{B,TFP}$ of 0%.&lt;/p&gt;

&lt;p&gt;The important part here is that these two industry-specific productivity growth rates are going to stay constant over time. Since they measure innovation - by assumption - that means the amount of innovation is staying constant over time as well.&lt;/p&gt;

&lt;p&gt;What about the weights? Those are roughly the share of GDP accounted for by each industry. I say roughly because in practice those weights depend on how the industries interact through input/output relationships, but share of GDP is a good approximation.&lt;/p&gt;

&lt;p&gt;We’re going to start with the innovative industry as 50% of GDP, and the normal industry as 50%, so&lt;/p&gt;

\[g_{TFP} = 0.5 (0.03) + 0.5 (0) = 0.015.\]

&lt;p&gt;1.5% TFP growth. That shouldn’t be surprising as industry A accounts for half of GDP.&lt;/p&gt;

&lt;p&gt;Here comes the TFP agnosticism. &lt;em&gt;What happens to the weights tomorrow&lt;/em&gt;?&lt;/p&gt;

&lt;p&gt;The answer comes down to what you think about preferences for A and B. If A and B are complements, then people take advantage of the lower price of A (or the higher quality for the same price) to buy a few more &lt;em&gt;units&lt;/em&gt; of A but overall spend &lt;em&gt;less&lt;/em&gt; on A. They take those savings and buy a little more of B and overall spend &lt;em&gt;more&lt;/em&gt; on B. The weights shift in B’s favor. Let’s say that the weight on A is now 40% and on B 60%. TFP growth is&lt;/p&gt;

\[g_{TFP} = 0.4 (0.03) + 0.6 (0) = 0.012.\]

&lt;p&gt;Only 1.2% TFP growth. The TFP growth rate has &lt;em&gt;fallen&lt;/em&gt; even though we just established above that innovation is constant, given that the TFP growth rates of each individual industry remain the same. TFP growth can change even though innovation does not.&lt;/p&gt;

&lt;p&gt;If we continue over time like this the weight on A is going to get smaller and smaller and the weight on B is going to get bigger and bigger and eventually the share of A is going to approach zero. At that point aggregate TFP growth will be &lt;em&gt;zero&lt;/em&gt; as well. But innovation will have continued to deliver $g_{A,TFP}$ of 3% every period.&lt;/p&gt;

&lt;p&gt;This kind of dynamic is precisely what was behind agriculture’s decline as a share of economic activity. Agriculture in the 20th century, and in particular since World War II, has been one of the &lt;em&gt;most&lt;/em&gt; innovative industries in the economy, and has experienced massive increases in TFP. The result? Agriculture accounts for maybe 2% of GDP today, down from 15% around 1950, and down from around 30-40% (or possibly more) around 1900. The contribution of all that innovation to overall TFP growth has dwindled to almost zero. But that doesn’t mean the innovation didn’t happen. And it doesn’t mean innovation in agriculture stopped. All that happened is that the weights changed.&lt;/p&gt;

&lt;p&gt;Assuming that A and B are substitutes, so that the share of A goes &lt;em&gt;up&lt;/em&gt; as it gets more productive, doesn’t eliminate the problem. Then the growth rate of aggregate TFP starts at 1.5% and &lt;em&gt;rises&lt;/em&gt; over time even though, again, the underlying rates of innovation are constant.&lt;/p&gt;

&lt;p&gt;The only way to avoid this problem is to assume that the GDP shares of the two industries are constant, meaning the elasticity of substitution between A and B for consumers is precisely one. And that is another case of something that works only in the bio-mechanics lab.&lt;/p&gt;

&lt;h3 id=&quot;nothing-is-perfect&quot;&gt;Nothing is perfect&lt;/h3&gt;
&lt;p&gt;So the first problem was disaggregation. The second problem was that the weights change over time in response to innovation.&lt;/p&gt;

&lt;p&gt;And that brings us to the last problem, which is the “AE” term I left floating around up there. This, recall, refers to allocative efficiency, or the effect of any distortions in prices (of products or factors) on economic activity. Those distortions can be things like monopoly markups, or taxes, or frictions in labor markets, or anything that means marginal products for factors of production are not equalized across different uses.&lt;/p&gt;

&lt;p&gt;If these distortions are changing over time, this can have a significant impact on aggregate TFP growth. What is it telling you about innovation? Nothing we can make sense of. Innovation could occur that lowers market power, as when a new competitor enters an industry, and this could increase aggregate TFP. Or innovation could increase market power, as when someone creates a new product entirely and is the monopoly provider of that.&lt;/p&gt;

&lt;p&gt;Even leaving the actual distortions as they are, innovation can alter the allocation of factors across different industries or firms. This is the same process as changing the weights I described above. If industry A is more innovative, and spending on it declines, A will shed labor and capital to industry B. Does that increase TFP or lower it? It depends.&lt;/p&gt;

&lt;p&gt;If B has higher markups, then paradoxically this would &lt;em&gt;increase&lt;/em&gt; TFP growth. But if B has lower markups, it will &lt;em&gt;lower&lt;/em&gt; TFP growth. The logic here is kind of funky, but I tried to explain it in some posts a while back, see &lt;a href=&quot;https://growthecon.com/blog/Paradox/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://growthecon.com/blog/Paradox-2/&quot;&gt;here&lt;/a&gt;. Either way, the point is that innovation screws with allocative efficiency in ways that are not always positive for TFP growth.&lt;/p&gt;

&lt;h3 id=&quot;here-comes-the-sun&quot;&gt;Here comes the sun&lt;/h3&gt;
&lt;p&gt;Given those three issues - disaggregation, weights, and allocative efficiency - I don’t see how aggregate TFP growth is a good indicator of innovation. An increase in innovation can increase TFP growth, lower TFP growth, or leave TFP growth about the same. So you can’t reason backwards from TFP growth to infer anything about the speed of innovation.&lt;/p&gt;

&lt;p&gt;Hence I am a TFP agnostic. I’m not &lt;em&gt;against&lt;/em&gt; growth in aggregate TFP. That would be great, because it means we’re getting more out of less. But you cannot use aggregate TFP growth to judge whether we are innovative or not, and making it your metric for innovation is doomed to disappoint.&lt;/p&gt;

&lt;p&gt;Let’s take solar energy as an example. I am all on board the solar train. What has occurred in the last ten years is nothing short of amazing. All of the hype about solar, like &lt;a href=&quot;https://noahpinion.substack.com/p/why-im-so-excited-about-solar-and&quot;&gt;Noah’s post&lt;/a&gt; is well deserved.&lt;/p&gt;

&lt;p&gt;I’m excited about solar &lt;em&gt;even if it doesn’t increase TFP growth&lt;/em&gt;. Why? Because it is freaking  carbon-free energy! Even if we get &lt;em&gt;nothing&lt;/em&gt; out of it in terms of increased TFP growth, it is completely and utterly worth installing. The &lt;em&gt;point&lt;/em&gt; of solar energy is not to make the economy more efficient, it is to reduce our reliance on fossil fuels. By our own actions - subsidies that distort the cost of solar - we’ve shown that we are willing to sacrifice efficiency and TFP growth in order to get our hands on that solar energy.&lt;/p&gt;

&lt;p&gt;Twenty years from now, in 2041, let’s say I want to see how far we’ve gone towards having a carbon-free solar economy. I’d look at the percent of KWh produced by solar, not the average annual growth rate of TFP between 2021-2041. And if I &lt;em&gt;did&lt;/em&gt; look at the growth rate of TFP, how would I know? Does 1.2% TFP growth mean we have a carbon-free economy, and 1.1% means we don’t?&lt;/p&gt;

&lt;p&gt;TFP is an incredibly useful statistic to know, and higher TFP growth is way better than low TFP growth. But it is not a meaingful measure of the speed of &lt;em&gt;innovation&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;And lest we forget, Ted Cruz is a seditious grifter who should resign.&lt;/p&gt;

</description>
        <pubDate>Fri, 29 Jan 2021 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>The 1965 shift in growth</title>
        <link>http://localhost:4000/feed/2021/01/08/BLS-TFP-Again.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2021/01/08/BLS-TFP-Again.html</guid>
        <description>&lt;p&gt;Well, insurrection in the nation’s literal Capitol was not the context I expected for my next blog entry. But with lots of nervous energy and few useful outlets for it (I, alas, am not authorized to arrest Ted Cruz) I figured I’d work on this post.&lt;/p&gt;

&lt;p&gt;This is a follow up to my &lt;a href=&quot;https://growthecon.com/blog/BLS-TFP/&quot;&gt;last post&lt;/a&gt; from early December, where I was digging deeper into some data on total factor productivity (TFP) growth rates. The reason for &lt;em&gt;that&lt;/em&gt; post was that I participated in a discourse on &lt;a href=&quot;https://www.pairagraph.com/dialogue/ee04c261817f45f39e1d0bb5f63e0b90&quot;&gt;Pairagraph&lt;/a&gt; with &lt;a href=&quot;https://twitter.com/elidourado&quot;&gt;Eli Dourado&lt;/a&gt; of the Center for Growth and Opportunity. The prompt was “Economic growth is stagnating, but there’s more to the story.” We were talking about interpretations of slow growth.&lt;/p&gt;

&lt;p&gt;The upshot of the December post was that the growth rate of TFP started to drag far earlier than the discourse with Eli - or much of the current discourse around slow growth - assumed. Rather than slow TFP growth starting after the Great Recession, or after 2000, it appears to have started in the early 1970s.&lt;/p&gt;

&lt;p&gt;I want to revise that earlier post a little to push back the slowdown even further to the mid-1960s, and talk more about &lt;em&gt;why&lt;/em&gt; the slowdown started so early, and lingered so long. The short answer is: Baby Boomers.&lt;/p&gt;

&lt;p&gt;Standard disclaimer about this being utter speculation applies.&lt;/p&gt;

&lt;h3 id=&quot;decomposing-growth&quot;&gt;Decomposing growth&lt;/h3&gt;
&lt;p&gt;I’m using the same data from the December post, and that Eli and I talked briefly about in our posts on Pairagraph. This is the BLS series on multi-factor productivity, which is just a different word for TFP. You can see the December post for links to a version of that data hosted by John Fernald at the San Fran Fed that includes some adjustments for capacity utilization. That adjustment isn’t terribly important to what I’m doing here.&lt;/p&gt;

&lt;p&gt;When the BLS (or John with his adjusted data) calculate the growth rate of TFP for a year, they use a formula that looks like this&lt;/p&gt;

\[gTFP = gGDP - a gK - (1-a) gLQ - (1-a) gHours.\]

&lt;p&gt;That is, the growth rate of TFP ($gTFP$) is equal to the growth rate of GDP ($gGDP$) minus the growth that can be accounted for by capital and labor (all the rest of those terms). The value of $a$ serves as a weight on how important growth in capital is ($gK$) and how important the two pieces of labor are ($gLQ$ and $gHours$). That value can change year to year, but is generally around 0.33. I have thoughts - long, tedious, boring thoughts - about why that number is probably too high, but this is not the time or place to subject you to them.&lt;/p&gt;

&lt;p&gt;Those two parts of labor are $gHours$, which measures the growth in the raw hours worked by people in the economy, and $gLQ$, which measures the “labor quality” of those people. This labor quality is inferred from changes in relative wages, and is meant to reflect any change in how valuable firms find workers. This would be capturing any increase due to education, or skill acquisition outside of formal education, or experience effects, or … whatever else might make labor useful to a firm &lt;em&gt;beyond&lt;/em&gt; the raw hours that labor works.&lt;/p&gt;

&lt;p&gt;This little table shows the values of each piece of that equation for three different time periods: 1948-65, 1966-2000, and 2001-2018. All the growth rates are in percent form, to avoid lots of things to four and five decimal places.&lt;/p&gt;

&lt;table style=&quot;width:100%&quot;&gt;
	&lt;colgroup&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 15%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
    &lt;/colgroup&gt;
  &lt;tr&gt;
    &lt;th&gt;Years&lt;/th&gt;
    &lt;th&gt;gGDP&lt;/th&gt; 
    &lt;th&gt;agK &lt;/th&gt;
    &lt;th&gt;(1-a)gLQ&lt;/th&gt;
    &lt;th&gt;(1-a)gHours&lt;/th&gt;
    &lt;th&gt;gTFP&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;48-65&lt;/td&gt;
    &lt;td&gt;3.46&lt;/td&gt; 
    &lt;td&gt;3.02&lt;/td&gt;
    &lt;td&gt;0.41&lt;/td&gt;
    &lt;td&gt;0.38&lt;/td&gt;
    &lt;td&gt;2.01&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;66-00&lt;/td&gt;
    &lt;td&gt;3.29&lt;/td&gt; 
    &lt;td&gt;3.98&lt;/td&gt;
    &lt;td&gt;0.37&lt;/td&gt;
    &lt;td&gt;1.55&lt;/td&gt;
    &lt;td&gt;0.75&lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;01-18&lt;/td&gt;
    &lt;td&gt;2.05&lt;/td&gt; 
    &lt;td&gt;2.54&lt;/td&gt;
    &lt;td&gt;0.42&lt;/td&gt;
    &lt;td&gt;0.44&lt;/td&gt;
    &lt;td&gt;0.61&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Take a look at what happens, in particular, at the transition from 1948-65 to 1966-00. GDP growth falls &lt;em&gt;a little&lt;/em&gt;, from 3.46% per year to 3.29% per year. But capital growth &lt;em&gt;increases&lt;/em&gt; by almost one whole percentage point, from 3.02 to 3.98% per year. Labor quality growth doesn’t change much, but the growth rate of hours sees a very large &lt;em&gt;increase&lt;/em&gt;, from 0.38% per year to 1.55% per year.&lt;/p&gt;

&lt;p&gt;The net effect of (a) the growth rate of GDP staying about the same and (b) the growth rate of inputs rising is to lower the implied growth rate of TFP. It drops from 2.01% per year to only 0.75%. This is a significant slowdown in productivity growth, and it happens in the mid-1960s, not in the late 1970s, the early 2000s, or after the Great Recession.&lt;/p&gt;

&lt;p&gt;Note from the third line that the growth rate of TFP does drop in 01-18 to 0.61%, but that drop from 0.75% is much smaller than the drop that occurs starting in 1966. We’ll come back to the other pieces of this later.&lt;/p&gt;

&lt;p&gt;Going back to the change in 1965, the point I want to make is that productivity growth dropped - in accounting terms - because input growth went up but we did not see any increase in output. The economy absorbed more and more workeres and more and more capital, but it didn’t translate into more and more output growth.&lt;/p&gt;

&lt;h3 id=&quot;boomers&quot;&gt;Boomers!&lt;/h3&gt;
&lt;p&gt;The choice of 1965 wasn’t an accident. That year is when the first Boomers turned 20. I chose it because it represents a point at which the Baby Boom generation really started to hit the labor force. Yes, some of them would have been working at younger than age 20 (and hence in the early 1960s) but by the late 1960s the labor force participation of the Boomers would really be kicking in.&lt;/p&gt;

&lt;p&gt;And once they entered the work force, what happened? Very clearly hours started to grow faster (1.55% versus 0.38%) but output did not. Capital accumulated faster (3.98% versus 3.02%) but output did not. And if you raise the growth rate of inputs like labor and capital, but nothing happens to the growth rate of output, then by necessity the growth rate of TFP must be lower.&lt;/p&gt;

&lt;p&gt;One possibility is that it just so happens that around 1965 when the Boomers hit the labor market, the pace of innovation or technological change or &lt;em&gt;something&lt;/em&gt; slowed down. And that it slowed down just enough to offset the increase in input growth, and left us with the same growth rate of output. You cannot rule that out. You could probably even make an okay case for this by talking about how the build-out of the electric grid or phone service or the interstate highway system were winding down starting in 1965?&lt;/p&gt;

&lt;p&gt;But that also seems kind of coincidental. A different story is that the economy kept expanding at about 3.3% per year after 1965 for some fundamental reasons like continued technological change or even continued expansion in natural resource use, and that we then tried to stuff a whole outsized generation of workers into that same economy (along with extra buildings so they’d have a place to sit). Like “Okay, your parents own the company so we have to find &lt;em&gt;something&lt;/em&gt; for you to do, so why don’t you sit here and move these papers from that file to that one.”&lt;/p&gt;

&lt;p&gt;That’s a cruel way to phrase things, but I think there is something to idea that the Baby Boom generation came along and was just too big to absorb all at once. We normally think of production expanding as you add more labor, yes. But what if that really only makes sense if you add small amounts of labor at any given time?&lt;/p&gt;

&lt;p&gt;Having an additional worker show up at your construction site probably helps move things along. Having three show up might be useful. Having twenty show up becomes a management problem. In more mathemetical terms, I’m thinking that the elasticity of output with respect to labor to a first order approximation is positive and something like, say, 0.6 or 0.7. But that “to a first order approximation” part is important. That means the elasticity holds for small percent changes in labor. There could well be second-order effects (like when the 20 people show up at the site) that cause the elasticity to plummet when the percent change in labor gets large.&lt;/p&gt;

&lt;p&gt;To belabor this further, I’m not just talking about a diminishing marginal product for labor. Having an elasticity of 0.6 or 0.7 (i.e. less than one) already incorporates a diminishing marginal product. I’m talking about a second-order effect that says the elasticity itself falls, and so the marginal product of labor diminishes even faster as you add more labor. It’s like talking about acceleration versus velocity, sort of.&lt;/p&gt;

&lt;p&gt;The drop in TFP growth starting in 1966 (ish) may reflect the fact that it is just hard to accommodate that big of a generation into the labor force over a short time. Maybe it didn’t reflect a real change in our ability to innovate at all.&lt;/p&gt;

&lt;h3 id=&quot;the-olds&quot;&gt;The olds&lt;/h3&gt;
&lt;p&gt;One reason I might be wrong about all that is what happened in 2001-18. We’re looking now at the tail end of the Boomers work life. They’re kind of at their career peaks around 2000, and then start the process of extracting themselves from the workforce. You can see the drop in both labor hours growth (from 1.55 to 0.44%) and the drop in capital growth (from 3.98 to 2.54%) that occur. But output growth does not stay around 3.3%. Instead it drops to 2.05%. With the end result that productivity growth stays low, and in fact drops a little more (from 0.75 to 0.61%).&lt;/p&gt;

&lt;p&gt;Why didn’t the effect work in reverse? Why didn’t output growth stay at around 3.3% and TFP growth go back up to something close to 2% per year as the Boomers exited? One very plausible reason is that I’m just wrong about this idea regarding the first and second order effects in 1965. What the transition to 2001-18 might indicate is that there really was some slowdown in innovation or technological change or &lt;em&gt;something&lt;/em&gt; during the 1966-2000 period that stuck. Maybe it was the drop in manufacturing as a share of economic activity, or changes in some policies, or globalization, or whatever.&lt;/p&gt;

&lt;p&gt;That could well be the case. It still leaves me wondering why we should focus hard on the period 2001-18 for the source of the slowdown in productivity growth, though. It may well be something that occurred earlier.&lt;/p&gt;

&lt;p&gt;Or, perhaps there is some fundamental asymmetry between growing and shrinking. Maybe the second-order effects that pushed down the elasticity with respect to labor in 1965 don’t work in reverse. What I mean is this. Starting around 1965, the marginal product of a new Boomer worker got pushed to zero because it was just too hard to absorb them all at once (the 20 new people on the construction site). But by 2000, we’ve had a few decades to figure out how to use those Boomers, and they each have a role and reason to be there that has positive marginal value. When they leave/retire, that lowers output. So rather than having the exit of the Boomers be reflected in higher TFP growth, it is reflected in lower GDP growth.&lt;/p&gt;

&lt;p&gt;In the construction analogy, after a few months with those 20 extra workers around, you’ve worked out a nice system, and can now slap up a house without them all sitting around. If I then come along and tell you to get rid of 10 of those extra workers, or all 20 of them, that is now going to have a big impact on your house-building. You’ve got to re-adjust &lt;em&gt;again&lt;/em&gt; to dealing with a smaller workforce. And you may no longer remember how you did it with fewer people.&lt;/p&gt;

&lt;p&gt;This might all sound like I’m working really hard to blame Boomers for current economic problems. I’m not out to get them. I’m not even convinced that this represents an economic problem (&lt;a href=&quot;https://amzn.to/35mzPfg&quot;&gt;buy my book!&lt;/a&gt;). But the sheer scale of their impact is easy to forget. You can see it in the numbers of the above table just in the hours growth. Going from 0.38% growth in hours per year to 1.55% growth is a factor of &lt;em&gt;four&lt;/em&gt;. Four times the rate of new employees and hours entering the economy every year. That’s massive.&lt;/p&gt;

&lt;p&gt;My argument depends on some kind of second-order effect, or that there isn’t a strict mechanical relationship of the number of workers to output. One way to think about this is with one of my all-time favorite papers, &lt;a href=&quot;https://ideas.repec.org/a/ucp/jpolec/v113y2005i3p582-625.html&quot;&gt;James Schmitz’s 2005 work&lt;/a&gt; on the US and Canadian iron ore industries. The point of that paper was that competition (from Brazil) lead to fundamental changes in labor productivity despite no changes in underlying technology. It’s an example of an industry that originally absorbed a lot of labor without changing output much. In this case once competition arrived they were able to shed a lot of that labor but keep output the same. No strict mechanical relatonships of labor to output.&lt;/p&gt;

&lt;p&gt;A second way to think about this is with a paper on the demographics of firms by &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/25382.html&quot;&gt;Hopenhayn, Neira, and Singhania&lt;/a&gt;, which I talked about in a &lt;a href=&quot;https://growthecon.com/blog/Aging-Growth/&quot;&gt;post&lt;/a&gt; a little over a year ago. Flooding the economy with new labor could lead to a flood of new firms, and new firms tend to be less productive than old firms, even if they &lt;em&gt;might&lt;/em&gt; be liable to grow faster. Again, it’s a story about slowly adapting to a surge in labor.&lt;/p&gt;

&lt;p&gt;Again, this isn’t some screed about Boomers ruining everything. It is an observation that our understanding of slow growth may need to back up a few decades, and may involve taking seriously second-order effects of labor force growth.&lt;/p&gt;

&lt;p&gt;And it got me from doom-scrollling for a while. Which reminds me:&lt;/p&gt;

&lt;p&gt;Ted Cruz is a seditious grifter who should be removed from the Senate.&lt;/p&gt;

&lt;p&gt;Happy New Year!&lt;/p&gt;

</description>
        <pubDate>Fri, 08 Jan 2021 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>When did productivity growth slow down?</title>
        <link>http://localhost:4000/feed/2020/12/07/BLS-TFP.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2020/12/07/BLS-TFP.html</guid>
        <description>&lt;p&gt;A few weeks ago I participated in a discourse on &lt;a href=&quot;https://www.pairagraph.com/dialogue/ee04c261817f45f39e1d0bb5f63e0b90&quot;&gt;Pairagraph&lt;/a&gt; with &lt;a href=&quot;https://twitter.com/elidourado&quot;&gt;Eli Dourado&lt;/a&gt; of the Center for Growth and Opportunity. The prompt was “Economic growth is stagnating, but there’s more to the story.” I argued that one should not interpret stagnation as implying something is wrong with the economy, and Eli argued that there was evidence of a real slowdown not just in technological growth, but in growth of welfare/well-being. You will be shocked to learn that I think my take on this subject is more accurate. But you should check out both sides of this because Eli’s position is a credible one and he does a good job of arguing it.&lt;/p&gt;

&lt;p&gt;One thing Eli and I agreed on was that looking at growth in &lt;em&gt;total factor productivity&lt;/em&gt; (TFP) was more relevant than looking at growth in GDP per capita. Growth in productivity allows you to either produce more stuff (good for growth in GDP per capita) or use fewer inputs (which is not good for growth in GDP per capita even if it is good for you or the environment). The growth rate of TFP is the better thing to focus on in asking whether stagnation matters.&lt;/p&gt;

&lt;p&gt;Here’s where I want to jump off from the original discussion. The received wisdom is that we are living through a period of slow TFP growth, and that this slowdown in TFP growth kicked in around the early 2000s.&lt;/p&gt;

&lt;p&gt;But I’m not sure that’s the whole story. When you zoom out further you’ll find that if there was a slowdown in productivity growth it started in the late 1960s or early 1970s and has continued through today. If we’re having a discussion about what went “wrong”, then we need to look &lt;em&gt;way&lt;/em&gt; earlier than the early 2000s to figure it out.&lt;/p&gt;

&lt;h3 id=&quot;measuring-tfp-growth&quot;&gt;Measuring TFP growth&lt;/h3&gt;
&lt;p&gt;The series on TFP that Eli and I reference in our discussion is from &lt;a href=&quot;https://www.frbsf.org/economic-research/indicators-data/total-factor-productivity-tfp/&quot;&gt;John Fernald of the SF Fed&lt;/a&gt; and you can download his series from that link. This series of TFP growth incorporates an adjustment for the utilization of inputs (capital and labor) based on John’s work with &lt;a href=&quot;https://ideas.repec.org/a/aea/aecrev/v96y2006i5p1418-1448.html&quot;&gt;Susanto Basu and Miles Kimball&lt;/a&gt;. The unadjusted growth in TFP he starts with is essentially just the standard BLS series on &lt;a href=&quot;https://www.bls.gov/mfp/mprdload.htm&quot;&gt;multi-factor productivity&lt;/a&gt;, which is just a synonym for TFP.&lt;/p&gt;

&lt;p&gt;In the following figure there are a few things going on. First, since I figured out how to use Plotly this fall, you get an interactive figure. You’re welcome.&lt;/p&gt;

&lt;p&gt;Second, and more important, there are three series plotted. The “Fernald Baseline” is the un-adjusted series on TFP growth. The “Fernald Util-Adjust” is that series adjusted for utilization of capital and labor. The “Original BLS” is my own calculation from the BLS data on the growth rate of TFP that Fernald’s work starts with. As you can see there are some very slight discrepancies in the Fernald Baseline and Original BLS series, but those are so insignificant I’m not worried.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/173.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;The utilization adjustment is apparent, and seems to smooth out the growth rate of TFP somewhat over time. Those big dips in the baseline data are, in part, due to low output induced by having low capacity utilization for capital or labor during recessions.&lt;/p&gt;

&lt;p&gt;What is kinda-sorta apparent from the figure is the slowdown in the growth rate of TFP. It definitely looks as if around 2010 the average growth rate of TFP was lower than during the early 2000s and late 1990s. It was as low as you see in the early 1980s, and definitely seems lower than the average rates you see in the 1950s and 1960s.&lt;/p&gt;

&lt;p&gt;With growth rates like this it is often hard to see real trends because of the noisiness. One option is to smooth the growth rates, but I find a very handy way to clarify things is just to look at the &lt;em&gt;log level&lt;/em&gt; of TFP that each of these growth rates implies over time. When you plot something in log terms (or a “ratio scale” as some people like to call it) over time, the slope of the line tells you about the growth rate, and can make trend breaks pop out.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/175.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This second figure shows those log TFP levels. To me, this makes it less obvious that 2000 was the real trend break we should be looking at. Yes, I know you’re all staring at that orange line with the “Fernald Util-Adjust” series and how it flatlines after 2000. Hang in there, and in the next section I’m going to tell you why the capacity utilization series doesn’t really change the conclusion.&lt;/p&gt;

&lt;p&gt;If you back up and look at the Fernald Baseline (blue) and BLS Original (green) series, they definitively grow faster from 1948 to around the early 1970s, and then things slow down. Yes there is some recovery in the 1990s (a higher slope) but that looks a lot like a temporary spike in a long series of slow TFP growth.&lt;/p&gt;

&lt;p&gt;To focus on that, zoom in on just the Fernald Baseline. We’d get a similar story using the BLS Original series. What I’ve done in the following figure is plot two trendlines. The first is for 1948-1972 (orange) and the second is for 1973-2019 (green).&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/177.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;It is clear that the earlier trend line had a much higher slope, and hence a much higher TFP growth rate, of about 1.98% per year. The 1973-2019 trend line had growth of only about 0.87% per year. Are the trendlines perfect fits? Nope. Notice how in the early 1990s actual TFP is below trend for a while, and then there is a spike in TFP growth until about 2005 which puts actual TFP growth above trend. After 2005 the growth rate of TFP is slow, but notice that this means we’re falling almost exactly on the trendline that kicked in around 1972. The &lt;em&gt;level&lt;/em&gt; of productivity by 2019 is not very far from what we’d have guessed if we had made a projection around 1990.&lt;/p&gt;

&lt;p&gt;Why was 1972 the cutoff? Because I’m a narcissist, and that’s the year I was born. If you cut the series at any year from about 1968 to 1978 you’ll get the same story. Extremely rapid growth in the middle-20th century, and relatively slow growth in productivity in the late 20th-early 21st century. The productivity growth slowdown is not just a 21st century issue.&lt;/p&gt;

&lt;p&gt;To give a sense of the scale of the effects of the slowdown that started around 1972, take a look at the extrapolation of the orange line. That is where productivity would have been, roughly, if we had continued at 1.98% TFP growth after my birth. By 2019, TFP would have been $e^{6.01}/e^{5.44} = 1.77$ times higher. That’s a massive difference.&lt;/p&gt;

&lt;p&gt;Hence my conclusion that if we’re going to argue about a productivity growth slowdown, we need to be arguing about what happened in the late 1960s and early 1970s and not what happened in 1999 or 2001 or 2009. We’ve been a slow-TFP growth economy for &lt;em&gt;decades&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;to-adjust-or-not&quot;&gt;To adjust or not&lt;/h3&gt;
&lt;p&gt;But what about the capacity utilization adjustment? If you back up two figures, that orange line for “Fernald Util-Adjust” just looks ugly starting in about 2005. The following figure does the same trendline breakdown for this series around 1972 as above. It has a very similar flavor, except that around 2005 things just plateau and we end up farther below the trendline by 2019.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/179.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Hover over the figure and you can see that log TFP in 2005 was 5.41, and in 2019 was …. 5.43. That’s a sum total of 2% TFP growth in 14 years, or about 0.14% per year. That &lt;em&gt;has&lt;/em&gt; to indicate there is a problem, right?&lt;/p&gt;

&lt;p&gt;Maybe. Even with the 2005-2019 slowdown, the economy isn’t that far off the trendline for 1973-2019. The gap between the actual series (blue) and the trendline (green) implies TFP is about 3% below where it “should” have been given the trend. But it’s 73% behind the 1948-1972 trend. Relatively speaking, the recent sluggish growth in TFP isn’t really important to the larger story of what happened somewhere between Stevie Wonder’s release of &lt;em&gt;Music of My Mind&lt;/em&gt; and &lt;em&gt;Innervisions&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Even if you want to contend that 1995-2005 is the right period to compare our current TFP growth to, that still leaves 1972 (or thereabouts) as the more important breakpoint. Consider the red line, which plots the trendline as if 1995-2005 became the “new normal” starting in 2005, with a growth rate of TFP of 2%. By 2019 actual TFP was 31% behind that 1995-2005 trend.&lt;/p&gt;

&lt;p&gt;But in 2019 even that “new normal” trendline was &lt;em&gt;still&lt;/em&gt; 36% behind the 1948-1972 trendline. You cannot escape the fact that the slowdown in TFP growth starting in the early 1970s was a massive event in the history of TFP growth. Explaining why TFP growth slowed down in 2005 is less imperative than explaining why it slowed down in 1972. And that is not just my narcissim or love of Stevie Wonder talking (well, okay, maybe a little).&lt;/p&gt;

&lt;h3 id=&quot;dont-you-worry-about-a-thing&quot;&gt;Don’t you worry about a thing?&lt;/h3&gt;
&lt;p&gt;This isn’t to say that the slowdown in TFP growth was a good thing. But trying to locate it in some breakdown or policy change around 2005 or the financial crisis is misguided. Conceiving of this as a early-70s change in trends rearranges my priors on a few things.&lt;/p&gt;

&lt;p&gt;First, I think it makes the argument that structural change is important for productivity growth. The early 1970s coincide roughly with the peak of American manufacturing as a share of economic activity. Is this the a demonstration of Baumol effects really kicking in? Or did the rise of competitors like Japan, and less favorable exchange rates, constrict manufacturing activity enough to make its weight felt on productivity growth?&lt;/p&gt;

&lt;p&gt;Second, even if it is due to changes in manufacturing activity, does a trend break around 1972 absolve China (WTO acession) and Mexico (NAFTA) of blame for a TFP growth slowdown? Probably?&lt;/p&gt;

&lt;p&gt;Third, is it evidence that significant financial events have lasting real effects? Did the inflation of the 70s and the Volcker disinflation do &lt;em&gt;something&lt;/em&gt; to productivity growth? You’d have to entertain that possibility, right?&lt;/p&gt;

&lt;p&gt;Fourth, is Bob Gordon more right than he thinks? Did the build-out of things like the interstate highway system, major airports, the electrical grid, and the telephone system exhaust the possibilities for significant step-ups in productivity? Should we think more about general purpose technologiges (GPTs) as drivers or bursts of productivity growth?&lt;/p&gt;

&lt;p&gt;Fifth, this puts another hole in the “market power” story of slow TFP growth. None of the series I see on this suggest any kind of prima facie case for market power changing until well after this slowdown starts in the early 1970s. Might one make the case that market power is a consequence of slow TFP growth, and not a cause?&lt;/p&gt;

&lt;p&gt;Sixth, demographics matter even more than I thought? The late 1960s/early 1970s coincide with the flood of Baby Boomers into the labor market. Are the returns to experience much more severe than we think from Mincer regressions, and so their entry lowered productivity growth before creating a spike in the late 90s as they really reached their peak?&lt;/p&gt;

&lt;p&gt;Seventh, is it possible that &lt;em&gt;Innervisions&lt;/em&gt; was so good that people no longer felt it was worth trying to innovate? Once you have that album in your life, is there a reason to ask for more?&lt;/p&gt;

&lt;p&gt;I have no answers to these questions, and I probably have more. If we’re looking too closely at the early 2000s we are probably missing the larger story. Don’t let recency bias narrow the field of inquiry!&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/RxsBc5p-dPU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
</description>
        <pubDate>Mon, 07 Dec 2020 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>The Silicon and Industrial Revolutions</title>
        <link>http://localhost:4000/feed/2020/08/13/Silicon-Valley.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2020/08/13/Silicon-Valley.html</guid>
        <description>&lt;p&gt;You can see this post as a way of thinking about &lt;em&gt;anything&lt;/em&gt; other than …. whatever real life has going on right now. And a warning that I posted this without a real close edit, because otherwise it would be another month before it saw the light of day.&lt;/p&gt;

&lt;p&gt;I read &lt;a href=&quot;https://amzn.to/31RI1Sb&quot;&gt;Making Silicon Valley&lt;/a&gt; by Christopher Lecuyer this summer. It’s a fairly straightforward business history of the origins of Silicon Valley, stretching back in time prior to my own vague notion of “something something Fairchild Semiconductor”. I would not recommend it as a casual read, it is very much a “and then this happened” slog through company origins, contracts, and inventions. That said, it is addressing some real historical questions about the role of military contracts and the presence of Stanford in fostering the Silicon Valley of the late 1970s/eary 80s.&lt;/p&gt;

&lt;p&gt;I found the book far more interesting for the somewhat casual asides about what motivated various company founders and inventors, and what led to the concentration of so much activity in that area. As source material for thinking about agglomeration and spillovers, the book has a lot to say. Beyond that, I found myself thinking that Lecuyer was implicitly making a very Joel Mokyr-ian argument that it was ideology and culture that drove this particular silicon revolution.&lt;/p&gt;

&lt;p&gt;It also reinforces this idea (which I tend to associate with Mokyr as well) that these kind of industrial revolutions are dependent on small networks of capable tinkerers, and not on either the average level of human capital or on a few heroic innovators. While all the names you’d expect are there (e.g. Shockley, Moore), my impression of their importance was significantly &lt;em&gt;deflated&lt;/em&gt; by Lecuyer’s book.&lt;/p&gt;

&lt;h2 id=&quot;a-overly-simplified-history&quot;&gt;A overly simplified history&lt;/h2&gt;
&lt;p&gt;To give you an idea of the scope of what the book covers, I’ll give you my own 10-cent summary. It starts with the formation of local vacuum tube companies in the San Francisco area in the 1930s, in particular Eitel-McCullough. Those two were amateur radio hobbyists, and starting making tubes to service that community. This company became a central node of the network of capable mechanics and engineers that would evolve over time and spawn most of the important firms and innovations.&lt;/p&gt;

&lt;p&gt;World War II created massive demand for vacuum tubes of all types. By the way, I am committing significant technological heresy here by using “vacuum tube” as a catch-all for the products Eitel-McCullough were producing. But this review isn’t about the technology itself, but the process that led to it. And to add another “by the way”, if you read the book you’re going to want Wikipedia open at all times to look up what the hell a klystron is.&lt;/p&gt;

&lt;p&gt;Firms connected to Eitel-McCullough as suppliers, like Litton Engineering, emerged in this period as well. They in turn sponsored new firms like Varian Associates, and what you really had by the early to mid 1950s was “Vacuum Valley”. What will be important for the story below is that these firms required a host of specialized equipment that was provided by smaller firms in the area, and thus the Vacuum Valley had at this point a tightly integrated network of engineers available to be leveraged in other ways.&lt;/p&gt;

&lt;p&gt;Vastly over-simplifying, vacuum tubes are just electrical switches, and so it became possible to think of other ways to do electrical switching, like using semiconductors. This is where Shockley Semiconductor appears in the story, although others like Hewlett-Packard were also working on semiconductors. Regardless, you now get a second wave of expansion as semiconductors become the electrical switch of choice, and the network of firms that grow out of Shockley includes Fairchild Semiconductor, which becomes its own massive node in that network. The most recognizable descendant of Fairchild is Intel. All of these firms took advantage of the engineering network of the Vacuum Valley, not just to provide equipment but to make crucial innovations.&lt;/p&gt;

&lt;p&gt;The larger point to take away from this tiny history is that the network &lt;em&gt;preceded&lt;/em&gt; the breakthroughs, not the other way around.&lt;/p&gt;

&lt;h2 id=&quot;iron-steel-and-silicon&quot;&gt;Iron, steel, and silicon&lt;/h2&gt;
&lt;p&gt;There is no question that some individuals played outsized roles in the development of Silicon Valley. Eitel, McCullough, Litton, Varian, and others in the first phase built firms from basically nothing. William Shockley won a Nobel prize for a reason. Fortunately for your iPhone, he was also a major asshole, but we’ll get to that. The guys who left Shockley to found Fairchild included people that would have an argument to be on a Mt. Rushmore of Silicon Valley: Robert Noyce, Gordon Moore, Jean Hoerni. If you were looking for “the” innovation that created Silicon Valley, then Hoerni’s creation of the planar process for creating transistors in silicon is probably it. If you want an analogy with the original Industrial Revolution, then Shockley is roughly Newcomen, and Hoerni is roughly Watt.&lt;/p&gt;

&lt;p&gt;But littered throughout Lecuyer’s book around these individuals are references to all the innovations and improvements made by the network of engineers working in the Valley in these decades.&lt;/p&gt;

&lt;p&gt;Let me just focus on Fairchild and their contribution to give you a flavor for what I mean:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Newly available historical materials … the shaping of silicon technology … was a group effort rather than the creation of ‘heroic’ individuals such as Noyce. (p. 130)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…their first task was to build a strong technical and management team. … The founders also recruited local electronics technicians. Those who had worked in the Peninsula’s tube industries brought with them knowledge of chemical handling, glass working, and vacuum techniques. (p. 139)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;… designed the equipment needed for device development and eventual production, and outsourced its construction to local machine shops. (p. 143)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Fairchild’s engineers also developed a radically new planar component, the integrated circuit. (p. 155)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It was Last and his engineers … who made the revolutionary step of engineering and fabricating planar integrated circuits. (p. 157)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Like vacuum tube corporations, Fairchild Semiconductor was dependent on a highly skilled workforce to control complex manufacturing processes and design advanced products. (p. 163)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;In addition, it [Fairchild] trained hundred of engineers and technicians in these new techniques. (p. 167)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I could go on and on with quotes like these from Lecuyer’s book. Every advance is shepherded into existence by a small group of skilled engineers, perhaps with a single individual named as the motive force or originator of an idea. But the success of all these inventions - transisitors, integrated circuits - is the continual series of improvements to production techniques and performance that were made by the unnamed engineers of the Valley.&lt;/p&gt;

&lt;p&gt;Which is why my mind went to Mokyr’s work. In &lt;a href=&quot;https://amzn.to/33YHWiq&quot;&gt;The Englightened Economy&lt;/a&gt; this is one of his themes. Chapter 3 of that book is about “Useful Knowledge and Technology”, and discusses the relative importance of captial-S science versus incremental improvement.&lt;/p&gt;

&lt;p&gt;A few items from Mokyr to compare to the quotes regarding Silicon Valley:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;But the spirit of mechanical improvement through better access to knowledge is symbolized by many other figures whose mechanical aptitude and ability to tease out every drop of economic value out of what they knew never ceases to astonish us. (p. 55)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tacit artisinal &lt;em&gt;savoir-faire&lt;/em&gt;, experience-driven insights, trial and error, and serendipity drove many of the eighteenth-century inventions, especially in mechanical engineering and iron and coal, far more than any solid scientific base. (p. 60)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It’s not that during either revolution (Industrial or Silicon) the people at work were blind to scientific principles, but knowing them doesn’t necessarily get the efficiency of your steam engine any or yield from your silicon wafers any higher. For that you need to do the thing, and by “you” I mean a small cadre of skilled “mechanics” for lack of a better term. Mokyr uses the example of John Smeaton, known for no specific invention in particular, but who developed much more efficient water mills, among his many very-important-but-not-notable accomplishments.&lt;/p&gt;

&lt;p&gt;But do not take the Silicon or Industrial revolution to mean that it is the mass of workers who are responsible for these improvements.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;… the Industrial Enlightenment was not the realm of a few heroic inventors and engineers, but neither was it a mass phenomenon that included the working class. It was a minority affair, confined to a fairly thin sliver of a technological elite of well-trained and often literate men. (p. 57)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is something that Lecuyer doesn’t speak to head on, but it’s lurking in the background of his entire book. Silicon Valley was built by a small group of engineers and technicians that revolved around this geographic area and its corporations. The origin of that thin sliver of the well-trained was the vacuum tube industry.&lt;/p&gt;

&lt;p&gt;As Mokyr notes, it is probably impossible to separate the causation between science and practical know-ho, or to separate the causation between flashes of individual insight and the boring accumulation of process improvements. Lecuyer’s book doesn’t provide proof one way or the other. I was just more struck by symmetric the two situations were in this respect.&lt;/p&gt;

&lt;p&gt;I think the tendency is to lean on the stories of individual insights and singular inventions. They are better stories, after all. There is a reason that James Burke’s &lt;a href=&quot;https://amzn.to/2POzyJU&quot;&gt;The Day the Universe Changed&lt;/a&gt; is such compelling TV. And I’ve always read Mokyr, despite his acknowledgement that there is a role for such individual moments, as pulling hard in the other direction to try and correct our overall outlook on what drove innovation, and ultimately economic growth, in the long run.&lt;/p&gt;

&lt;h2 id=&quot;nocal-baby&quot;&gt;NoCal, baby&lt;/h2&gt;
&lt;p&gt;So Joel Mokyr is really smart, and the history of Silicon Valley is consistent with his views on how industrial revolutions work. But the other element of Lecuyer’s book that stands out is the pure contingency involved in Silicon Valley evolving where it did. Remember that in the 1930s-50s when the vacuum tube industry and then the nascent semiconductor industry were developing, there was &lt;em&gt;no question&lt;/em&gt; that the beating technological heart of the U.S. was located in the Northeast. In 1948 you would have placed a more money on Rochester, N.Y. than San Francisco being the home of an innovative electronics industry.&lt;/p&gt;

&lt;p&gt;What put this network of capable engineers in northern California rather than upstate New York. Have you been to either place in February? Lecuyer cites numerous examples of how it was simply a case of people preferring to live around Santa Clara rather than out east that helped Silicon Valley develop. The geographic advantages of Northern California didn’t &lt;em&gt;cause&lt;/em&gt; smart engineers to emerge there, but they did ensure that the smart engineers that did emerge &lt;em&gt;didn’t leave&lt;/em&gt;. If you were a sharp engineer in Indianapolis in 1950 and RCA came calling, you probably packed up and moved to New York. But when RCA (and Westinghouse and GE and ….) tried to poach these engineers from Silicon Valley - and they did repeatedly - these guys stayed put because Northern California is delightful. And at that point, &lt;em&gt;not&lt;/em&gt; a housing nightmare.&lt;/p&gt;

&lt;p&gt;This goes all the way back to the vacuum tube origins of Silicon Valley. Many of the engineers at Eitel-McCullough, Varian, and Litton ended up working in the East during World War II, either as employees of eastern firms, or as representatives for their California-based firms. But:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;They longed for more congenial and familiar surroundings. The sentiment was not specific the Varians and their friends. It was shared by many western engineers who had moved to the East Coast in the late 1930s and during World War II. Most of these men desired to go back to the West and were afflicted by what was often called at the time “Californiaitis” - the intense desire to relocate to California.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Motivated in part by a similar attachment to California, and also to help care for his ailing mother, Bill Shockley decided to open up his semiconductor firm in Mountain View. This might have been just another example of NoCal keeping the local boys home, but a second example of contingency in the development of Silicon Valley came from his choice. Turns out Shockley was kind of an asshole to work for. He apparently tried to use lie detectors more than once on his employees, among other stories.&lt;/p&gt;

&lt;p&gt;This led to a group of his top engineers - including Hoerni, Moore, and Noyce - to leave the company and set up on their own. They were funded by Fairchild Camera, and hence Fairchild Semiconductor was born. One of their great disagreements with Shockley was over the technical direction to take semiconductors, and it is arguable that had they not left, the arrival of integrated circuits would have been delayed or lost. You’ll have to leave that contention to someone who knows more about the actual engineering than me. But the combination of Shockley’s poor management style combined with the insistence of the Fairchild group that they stay in Northern California meant that the pool of engineers and knowledge stayed local to the area.&lt;/p&gt;

&lt;p&gt;I think it is hard to understate how important it was that as new firms hived off and split from existing ones - including from Fairchild, which spawned numerous children - they &lt;em&gt;stayed&lt;/em&gt; in Northern California. And while some of that was for obvious economic reasons like the availability of engineers, a lot of it was also based purely on geographic preference.&lt;/p&gt;

&lt;p&gt;The origin of the agglomeration economies that we think lie behind the relative productivity of particular cities may well be random. Beyond that origin, Lecuyer’s book provides some ideas for &lt;em&gt;how&lt;/em&gt; agglomeration economies work, and it is very much about the informal social networks formed that pass around tacit knowledge.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Beneath this atmosphere of intense and often ruthless competition was an undercurrent of information sharing. Engineers involved in MOS [metal oxide semiconductors] startups exchanged process and design data with engineers in other firms in an informal way. Most MOS engineers face the same difficult task of developing and stabilizing complex manufacturing techniques. Any information that would help them solve the numerous process issues that they were encountering was welcome. … A web of previous associations also facilitated information sharing. Most of the MOS engineers had worked for other corporations before …. At these firms they built friendships … These previous associations made it easy to contact engineers at other firms and ask their advice. (p. 275)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bars also fostered the exchange of information among engineering groups. In the first half of the 1960s engineers and managers at Fairchild and other silicon corporations on the Peninsula had developed the habit of meeting after work at a local bar. (p. 275)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;… the MOS community on the Peninsula developed a repertoire of process “tricks” that were known only in the area. … In contrast, MOS firms located outside Northern California were not plugged into these networks and did not benefit from their shared knowledge. (p. 275)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To draw this back to the Mokyr work and the Industrial Revolution, we’re back to the idea that the “Tacit artisinal &lt;em&gt;savoir-faire&lt;/em&gt;, experience-driven insights, trial and error, and serendipity” were as important as any scientific insights in driving innovation. But again, this was a thin sliver of highly skilled engineers circulating in a small geographic area from firm to firm, not a body of knowledge spread out across the entire workforce.&lt;/p&gt;

&lt;p&gt;None of this changes the underlying idea in growth economics that it is innovations and invention that drive growth in the long run. But the similarity of the Silicon Valley experience to how Mokyr describes the Industrial Revolution experience does suggest that this innovation and invention is less a function of economy-wide aggregate features (e.g. demographics, trade) and more on niche groups of innovators embedded in specific places and cultures. Put it this way, my Bayesian posterior on the origins or economic growth took a step in Mokyr’s direction after reading Lecuyer.&lt;/p&gt;

&lt;p&gt;You could also file this as an example of the idea that it is better to concentrate your investment and R&amp;amp;D (and education?) rather than making it broad-based. For a couple of other posts I did thinking along those lines, see &lt;a href=&quot;https://growthecon.com/blog/should-developing-countries-try-to-create-a-business-elite/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://growthecon.com/blog/focused-or-broad-based-growth/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I’m also wondering if this should make me revise opinion on how robust growth is in the long run? If growth depends on some contingent factors leading to niches of innovation, then wouldn’t we expect that to fail every now and then? Or is this where the non-rivalry of the the production processes - once they are developed - kick in a la Romer and save us?&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Aug 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Economic impacts of the coronavirus - part 3/n(?)</title>
        <link>http://localhost:4000/feed/2020/04/02/Labor-IO.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2020/04/02/Labor-IO.html</guid>
        <description>&lt;p&gt;If you’re wondering what I’m attempting to do in these posts, then join the club. I’m just sort of grasping around for a way of thinking about the aggregate impacts of the shutdowns that takes into account the fact that it will hit particular industries directly (e.g. restaurants) but that this will have ripple effects on other sectors. The prior posts (&lt;a href=&quot;https://growthecon.com/blog/IO-Tables/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://growthecon.com/blog/Base-IO/&quot;&gt;here&lt;/a&gt;) were building up some understanding of a baseline model to do this.&lt;/p&gt;

&lt;p&gt;The big problem with the baseline model is the fact that it assumes a lot of flexibility in the economy, especially in terms of labor moving around between industries in response to productivity or demand shocks. We’re not seeing the kind of perfect flexibility the baseline model assumes. We are seeing &lt;em&gt;some&lt;/em&gt; flexibility, as Amazon, Costco, and other firms are hiring even as many industries are laying people off. But there is nowhere close to enough of this new hiring to offset the massive job losses that have occurred. We’re at 10 million UI claims in the last two weeks as of today.&lt;/p&gt;

&lt;p&gt;Like a lot of macro models, the baseline version I started with is useful for thinking about relatively long-run changes when the frictions (search and match, for example) have had time to work themselves out. But I think I can still leverage this baseline model to get some idea of the short-run impacts by ignoring some of it and then making some simplifying assumptions of my own.&lt;/p&gt;

&lt;h3 id=&quot;the-industries&quot;&gt;The industries&lt;/h3&gt;
&lt;p&gt;To explain, let me start with the input/output structure. I’m going to play around with fifteen industries (okay, 17, but the last two are tiny and mainly there so that things add up). I could do this for 71 or (God forbid) 405 industries using I/O tables provided by the BEA, but this is sufficient to get the idea and calculate some effects.&lt;/p&gt;

&lt;p&gt;You can see the 15 main industries and some summary information in the following figure. Yes, that’s just a clip from a spreadsheet, which you can find &lt;a href=&quot;https://www.dropbox.com/s/sk1o0xd8omjrbll/IO_sim.xlsx?dl=0&quot;&gt;here&lt;/a&gt; if you want to play with it. This data is all from 2018 - I know, I know - but that is the latest version of the full I/O tables you can get. For my purpose of seeing how things spread around the economy, I’m okay with that. I’m not trying to give you a precise estimate of GDP in the 2nd quarter of 2020.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/IOsetup.png&quot; alt=&quot;Industry information&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first column shows the share of “final use”, which is another way of referring to GDP. Final use of an industry’s output is that output which is not used as an intermediate good by some other industry. The sum of final use across industries adds up to GDP. Agriculture constitutes 0.3% of GDP, and manufacturing is 9.6%, for example.&lt;/p&gt;

&lt;p&gt;The second and third columns show the Domar weight for each industry, which I explained in the prior post. It’s calculated twice as a check on myself. Once calculated the normal way, by dividing gross output of an industry (Q) by GDP. The second time is calculated by using the I/O matrix itself, and this was just to make sure I wasn’t making some mistake with that matrix. If you take a look at the Domar weights, you can see which industries have a lot of connections as suppliers to other industries. Manufacturing, for example, has a Domar weight of 29.2% even though it is only 9.6% of GDP. That is because manufacturing produces a lot of output that is used as intermediates by &lt;em&gt;other&lt;/em&gt; industries, so its influence on the economy outweighs its final use. Retail, on the other hand, has a Domar weight of 8.3% compared to a share of GDP of 7.5%, not much different. That is because retail isn’t used much as an input by &lt;em&gt;other&lt;/em&gt; industries.&lt;/p&gt;

&lt;p&gt;Following that you can see the total final use and gross output of each industry. And next to those in the final columns are the payroll of each industry (labor compensation as reported in the I/O accounts) and the number of employees (in thousands, which I pulled from a different BEA account).&lt;/p&gt;

&lt;h3 id=&quot;the-shock&quot;&gt;The shock&lt;/h3&gt;
&lt;p&gt;I said I was going to ignore some of the baseline model in order to make sense of the current shock. I’m going to shove through an exogenous drop in final use spending on a few industries (e.g. art, entertainment, and food service) and then &lt;em&gt;ignore&lt;/em&gt; that in the baseline model this spending would end up being done on other industries. In the baseline model there is no place for consumers money to go other than spending on final use goods or services from the industries. So if you spend less on food service, you would spend that money in the retail industry, for example.&lt;/p&gt;

&lt;p&gt;What I’m doing is assuming that you can just not spend that money. I’m allowing people to have a bank account, or a mattress, or a shoebox, or whatever, and to just stop spending as much. If people spend less on goods and services, GDP will shrink. This is all pretty old school Keynsian cross stuff. And for the purposes of evaluating the effect of a massive spending shock over the horizon of a couple of weeks, I’m good with that. We’re well within the window of time when it makes sense that things like relative prices, wages, and labor allocations across industries aren’t able to adjust. If you aren’t comfortable with that, I could also introduce a “household production” industry into the mix which people spend resources on, but which doesn’t get added up as part of GDP. The drop in spending on food service and other industries would be matched by an increase in “spending” on home production.&lt;/p&gt;

&lt;p&gt;Either way, measured GDP will fall. What is more interesting to me here is the impact of these immediate spending shocks on the gross output of &lt;em&gt;other&lt;/em&gt; industries. When we all spend less at restaurants and hotels, that impacts the industries they use like wholesalers, professional services, and finance. And that in turn impacts their suppliers, which in the restaurant example you might imagine includes the agricultural sector.&lt;/p&gt;

&lt;p&gt;The gross output of each industry is going to be affected negatively by this spending shock, and the size of the negative effect is going to depend on how tied together they are by the I/O matrix. Without my Keynsian-like assumption, there would be some countervailing force propping up other industries as spending shifted from restaurants towards other areas. That could well be part of a response. We already see that some retail institutions (Amazon, some grocery stores) are seeing increased activity. You could play with that in the spreadsheet if you want.&lt;/p&gt;

&lt;h3 id=&quot;the-effect&quot;&gt;The effect&lt;/h3&gt;
&lt;p&gt;I pushed some numbers through this, and the figure below shows what I’m getting. I assumed that spending on retail fell by 50%, on arts/entertainment/food service by 75%, and on other services by 75%. This is nothing other than gut feel. This is a back of the (very large) envelope stuff. The column showing these percent changes in outlined in red in the figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/IOeffect.png&quot; alt=&quot;Effects of shock&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What follows are the implications. First comes the absolute change in final use spending in each industry. That’s 766 billion less in retail spending, 944 billion less on arts/ent/food, and 488 billion less on other services. Next comes the impact on &lt;em&gt;all&lt;/em&gt; the industries due to this shock to final use spending. The “Chg Gross Output” column takes the spending shock and pushes it through the I/O matrix to figure out the impact on each industry due to the logic I explained above.&lt;/p&gt;

&lt;p&gt;Gross output in agriculture falls by 24 billion, and in mining by 26 billion, for example. You get big effects in manufacturing, with a drop in 287 billion, in finance with a 388 billion hit, and in professional services with 415 billion. Also notice that in retail, arts/ent/food, and other services, the drop in gross output is &lt;em&gt;bigger&lt;/em&gt; than just that from the drop in spending. The ripple effects from other industries come back to haunt them further.&lt;/p&gt;

&lt;p&gt;Next to the absolute change in gross output is the percent change in each industry, giving you a better idea of the shock to each. No one really escapes here, except perhaps education/health, with only a drop of 0.2%. This small effect is due to the fact that education/health isn’t a big &lt;em&gt;supplier&lt;/em&gt; of intermediate goods to other industries, and so lower demand for things like retail don’t really impact this industry much.&lt;/p&gt;

&lt;p&gt;We can now get to the additional simplifying assumptions I am making to parse through the effects. First, I’m assuming that the share of industry gross output used on payrolls stays constant, as if the industry had a Cobb Douglas production function. This means that payrolls scale up and down with gross output, or that the percent change in total payroll in an industry is the same as the percent change in gross output. This is the last column in the above figure.&lt;/p&gt;

&lt;p&gt;The second assumption is that within an industry the wage is sticky. If the wage is sticky, then any drop in payroll has to be accomplished by firing people. So the percent change in employment in an industry is &lt;em&gt;also&lt;/em&gt; the same as the percent change in gross output. This is in the second to last column of the figure.&lt;/p&gt;

&lt;p&gt;For retail, this implies a drop in employees of 7,336,000, and in arts/ent/food a drop of 1,454,000. Other services lose 4,145,000 workers. But note that professional services sees a substantial drop of 1,802,000, all because of the ripple effects of the initial spending shocks. There are hundreds of thousands of jobs lost in other industries like manufacturing and finance. None of these should be taken too seriously, as again I’m just doing back of the envelope stuff here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/IOaggregate.png&quot; alt=&quot;Aggregate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I can aggregate all this as well. The last figure here shows those aggregations. GDP falls by 11%, which is entirely due to the assumed collapse in final use spending in those three industries. There is nothing magic about getting that number, but I did choose the shocks to get something like this, as it jives with some reports about the size of the drop in GDP we might expect over the next few months. Gross output drops by 10%, in line with GDP, and payrolls by 11%, neither of which are surprising given the assumed drop in GDP.&lt;/p&gt;

&lt;p&gt;Total employment in this scenario falls by 16,886,000, which is 12% of employment in 2018. That’s not something I was trying to hit, but it is line with reports that the unemployment rate could jump by something in that neighborhood. We’re already at 10 million UI claims, so the question may be whether the negative shocks I threw in the spreadsheet are large enough.&lt;/p&gt;

&lt;p&gt;What you can play with in the spreadsheet are also stimulus scenarios. Be careful here. The stimulus involves very little spending &lt;em&gt;on&lt;/em&gt; government services directly, but instead is mainly transfers by the government to others to spend on any industry they like. So don’t add a big percent increase in the “Government” final use line. Instead add a positive percent to industries you think people will spend UI benefits or the $1200 checks on.&lt;/p&gt;

&lt;h3 id=&quot;doing-it-right&quot;&gt;Doing it right&lt;/h3&gt;
&lt;p&gt;I can’t emphasize enough that this is not some kind of calibrated forecast of what is going to happen in Q2 or Q3 of this year. It is solely an exercise in seeing how &lt;em&gt;some&lt;/em&gt; kind of shocks will permeate throughout the entire economy, even if they are centered on only a handful of industries.&lt;/p&gt;

&lt;p&gt;If you &lt;em&gt;did&lt;/em&gt; want to do something more accurate, what else would you have to do? I can think of several important ones.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Expectations. It’s not like the pandemic is a secret, so people are presumably adjusting their spending on other industries in &lt;em&gt;anticipation&lt;/em&gt; of the possible effects this year. For example, businesses may be lowering capex because they don’t think demand will materialize until end of this year. That would act like another spending shock to manufacturing or construction. Workers who are worried about getting laid off in the future will pull back on spending as well.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Payrolls and spending. I’m not enforcing any relationship between the drop in payrolls and the drop in spending. If my little exercise is the “through mid-April” forecast, then you have to think through how the drop in payrolls will influence spending across industries in the “mid-April to mid-May” period, and so on.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Relative price changes. I didn’t say it explicitly, but this little exercise assumes that the relative prices of industries don’t change. If retail locations slash prices to salvage &lt;em&gt;something&lt;/em&gt; out of the next few weeks, then this may get people to substitute spending towards them. Although perhaps lockdowns prevent this from doing anything about it?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Industry substitutions. Similar to above, if relative prices change then industries may decide to spend more on cheaper intermediates and less of more expensive ones. That changes the I/O matrix. I’m assuming the matrix stays constant, or that the “recipe” each industry follows for production stays constant. That may not be a bad assumption for small shocks, but is probably wrong for large shocks like these.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A lot of things missing, as you can tell. The farther forward you want to forecast, the more things my simplistic model is going to get wrong. But I find the simplistic model useful just for thinking about the rough scale of the shocks occurring and how they influence the whole economy. We’re starting to see papers coming online that are doing more sophisticated macro modeling of the impact of the virus, which from my very brief scan of intros are taking at least some of these effects into account. Those will be helpful for thinking about how long the dip will last and how significant the rebound will be, which my little spreadsheet has zero information about.&lt;/p&gt;

&lt;p&gt;Stay safe. Stay home. Wash your hands. And you should probably wear a mask.&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Apr 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Economic impacts of the coronavirus - part 2/n(?)</title>
        <link>http://localhost:4000/feed/2020/03/21/Base-IO.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2020/03/21/Base-IO.html</guid>
        <description>&lt;p&gt;There isn’t a real question about there being severe negative impacts of the virus on employment, household finances, or the overall growth rate. What I’m after here is trying to understand how shocks (and what kind of shocks?) to some industries ripple through the economy to influence others. For example, when you shut down hospitality businesses like restaurants, bars, and hotels, how does that affect suppliers like the food processing or farming industries?&lt;/p&gt;

&lt;p&gt;I’ve got no chance at coming up with something coherent in a small enough time frame to speak to the current round of proposed stimulus. At this point the scale of the problems are so large, and so apparent, that the kinds of things I’m thinking about here are second order. Treasury rates are historically and ridiculously low. Borrow like crazy and push a bunch of that money out to households (without a stupid phase-in) and businesses so that the former can keep paying bills and the latter can keep making payroll. Keep the circulation going. If you want to claw back some of that by making the household payments taxable later on, or make the business payments 30-year 0% loans, okay. That is less relevant than the speed of action now.&lt;/p&gt;

&lt;p&gt;Okay, throat clearing aside, let me step back into my second-order considerations of how industry shocks propagate through the economy. If you’re looking for a reason to keep reading, by the way, then I’d consider this useful information for thinking about how to build a more resilient economic stabilization system after the coronavirus has died down.&lt;/p&gt;

&lt;p&gt;In the last &lt;a href=&quot;https://growthecon.com/blog/IO-Tables/&quot;&gt;post&lt;/a&gt; I started outlining what an I/O table. That shows us how much of the output of one industry is used as an input by other industries - intermediate goods and services. Once you allow for industries to supply one another, then the concepts of gross output and GDP become distinct. Gross output is, to put it simply, GDP plus intermediates. What I noted in that post was that just knowing what the I/O table looks like doesn’t tell you how much economic activity there is. And the I/O table is necessary, but not sufficient, for figuring out how shocks to one industry influence others.&lt;/p&gt;

&lt;p&gt;This post is going to verbally lay out the implications of a baseline model. If you’re digging this, then you should look closely at &lt;a href=&quot;http://vasco-m-carvalho.github.io/pdfs/ProductionNetworks.pdf&quot;&gt;Carvalho and Tahbaz-Salehi&lt;/a&gt; and &lt;a href=&quot;http://vasco-m-carvalho.github.io/pdfs/Carvalho_JEP_2014.pdf&quot;&gt;Carvalho&lt;/a&gt;, who go into the math. I may post up a more formal version of this verbal model in the near future.&lt;/p&gt;

&lt;p&gt;Before we get going, be aware that this baseline model is only kinda-sorta going to be useful for thinking about shocks like the coronavirus, because it is going to assume a lot of flexibility in prices and employment across industries, neither of which are going to be good assumptions for short-run impacts of something like the virus shutdowns. But I don’t know how to think about a better model for the shutdowns without having this baseline to work from. So here we go.&lt;/p&gt;

&lt;h3 id=&quot;the-supply-side-in-words&quot;&gt;The supply side in words&lt;/h3&gt;
&lt;p&gt;Imagine that some industry A experienced a 10% decline in its total factor productivity. For the same amount of capital, labor, and intermediates its real production today is only 90% of what it was yesterday. What is the effect on total GDP?&lt;/p&gt;

&lt;p&gt;That depends on how important the industry was to begin with, of course. You might be tempted to say that the importance could be measured by the share of GDP (value added) accounted for by industry A. If industry A’s value added was 15% of GDP yesterday, then you might predict that GDP would be lower by .1 times .15 = .015, or lower by 1.5% today. And the rough intuition is right that the “bigger” the industry, the more consequential a drop (or increase) in productivity in that industry is for GDP.&lt;/p&gt;

&lt;p&gt;The problem is that the share of GDP is not the right way to measure the impact of industry A, because industry A might be a supplier to other industries. If their productivity goes down, then there are fewer products from A flowing to industries B, C, D, … and Z. And thus those industries cannot produce as much today as they did yesterday. And therefore the output of &lt;em&gt;all&lt;/em&gt; of those industries will fall, and the actual impact on GDP will be more severe than the 1.5% we just calculated.&lt;/p&gt;

&lt;p&gt;The I/O table I mentioned in the last post allows us to figure out the final effect of the productivity shock to industry A by working through the ripple effects on B, C, D, … and Z. The I/O table tells us how much spending on intermediates by B, say, comes from industry A. The larger this share, the bigger the effect on B’s production, and vice versa. And it doesn’t stop there. Because if B is a big supplier to C, then when A’s productivity falls, B’s production falls, and hence C’s production falls as well. Even worse, if C is a big supplier to A, then A’s production is going to fall even further, meaning B’s falls again, and so on.&lt;/p&gt;

&lt;p&gt;We aren’t doomed. Using the I/O table we constructed the &lt;em&gt;Leontief inverse&lt;/em&gt; in the last post, which is essentially the solution to following all of these paths throughout the economy. It tells us the final effect of the productivity shock to industry A (or to any industry) on all other industries. We can combine that with how much final consumers like to buy the products of industry A to come up with the right way to measure the impact of industry A on the whole economy.&lt;/p&gt;

&lt;p&gt;Those impacts are referred to as “&lt;a href=&quot;https://www.jstor.org/stable/2228246?seq=1#metadata_info_tab_contents&quot;&gt;Domar weights&lt;/a&gt;” after Evsey Domar, the same guy from the Harrod/Domar model of economic growth and the papers on serfdom and slavery. What’s cool about Domar weights is that even though they are built from an underlying I/O table and all that, in the end they can be calculated very simply. The Domar weight for industry A, for example, is just the &lt;em&gt;gross output&lt;/em&gt; of industry A divided by GDP.&lt;/p&gt;

&lt;p&gt;Our naive calculation above (15%) was the &lt;em&gt;value added&lt;/em&gt; of industry A divided by GDP, but that understated the role of A in the economy. The Domar weight might be something like 20%, with the extra five percentage points coming from the ripple effects of A on other industries. For an industry that has very little final demand but is used as an intermediate by lots of other industries (e.g. warehousing, ocean shipping, semiconductor manufacturing, crude oil production) the actual value-added weight could be very small but the Domar weight could be huge. For an industry that is mainly final demand but isn’t a big supplier of other industries (e.g. restaurants) the Domar weight is probably very close to the share of value-added.&lt;/p&gt;

&lt;p&gt;Regardless, if we use the Domar weight of 20% for industry A, then the actual impact of the 10% drop in industry A’s productivity will lower GDP today by .1 times 0.2 = .02, or 2%.&lt;/p&gt;

&lt;p&gt;This has some interesting implications for overall GDP and the impact of productivity shocks. We’ll take those Domar weights seriously, but for the moment be naive about other aspects of the economy. In particular, we’re going to assume that the labor force and capital stock stay constant in response to any productivity shocks (hey, I told you it was a baseline model). Then you can do some math and show that the percentage change in GDP is equal to the Domar-weighted percentage change in &lt;em&gt;all&lt;/em&gt; industry productivity levels. That makes some sense, I would think. The change in GDP (since we are holding labor and capital constant) has to depend on the change in productivity of all the industries that make up the economy.&lt;/p&gt;

&lt;p&gt;Here’s the weird/cool/scary part of this. Because of the interactions between industries in the I/O table, the Domar weights need not add up to one. And this means that the effect on GDP of productivity shocks can be &lt;em&gt;bigger&lt;/em&gt; than any of the individual industry shocks. The interrelated nature of the industries is going to amplify productivity shocks beyond their initial size.&lt;/p&gt;

&lt;p&gt;Let’s take an example. If we had 3 industries A, B, and C that are all interrelated, we could easily have Domar weights for the three of them that are 20%, 60%, and 50%. And if the coronavirus or anything else were to lower productivity in &lt;em&gt;each&lt;/em&gt; industry by exactly 10% then the interrelated nature of the economy tells us that the drop in GDP is equal to .2 times .1 + .6 times .1 + .5 times .1 = .13, or 13%. No industry experiences more than a 10% drop in productivity, but GDP falls by 13%. Why? Industry B gets hit by its own 10% drop in productivity but it &lt;em&gt;also&lt;/em&gt; loses inputs from A and C, meaning its production goes down by more than 10%. And that in turn means A and C have fewer inputs, which lowers their production by more than 10%.&lt;/p&gt;

&lt;p&gt;If you think of the virus as some sort of common productivity shock across industries (or firms, or whatever) then it is their relationships with one another as suppliers and customers that create a massive economic shock in the aggregate. The more related industries are, the larger the sum of the Domar weights, and the larger the aggregate effect of the initial productivity shock.&lt;/p&gt;

&lt;p&gt;One thing you might have picked up on here is that I’ve described the effects of the productivity shocks in any industry in terms of their effect on its “downstream” customers. That is, I described how if A has a negative productivity shock, this influences B because B needs inputs from A. I didn’t speak directly about the “upstream” effects of the productivity shock in A, meaning I didn’t describe the fact that A may buy fewer inputs itself in response to its productivity shock, hurting its suppliers.&lt;/p&gt;

&lt;p&gt;The concept that changes in GDP are a Domar-weighted combination of changes in productivity by industries is usually known as “&lt;a href=&quot;https://academic.oup.com/restud/article-abstract/45/3/511/1573872?redirectedFrom=fulltext&quot;&gt;Hulten’s Theorem&lt;/a&gt;”, and holds in many more generic cases than what I’ve described. My focus on the “downstream” effects only was partly for exposition, and partly based on assumptions in the baseline model I’m working off of. There has been a bunch of work on this recently, so see things like &lt;a href=&quot;http://pages.stern.nyu.edu/~xgabaix/papers/granular.pdf&quot;&gt;Gabaix&lt;/a&gt;, &lt;a href=&quot;https://uc5832d6123d2287a8e4ddd2f84e.dl.dropboxusercontent.com/cd/0/inline2/A0R7Sfb3T_4Mil-lGIBDBo69kic-FKYnqi4nJLYV6mjPmLM3s3JtarEQPboDBV9ovo-DXg53pLw5ECtih1mfOvqf_5STzfYfIKyxJgnkeRvqxRduBJg80bubFMAEXV8UAqbQ1kujnYdVkDTuuQBWSolfTp7UhxnaLJOD7excArGIe4-w3-gZNKSD4XztnmL8ZertaCqteFrTBJmsj1ZP4u4gqVPuIiXyIuby1TbUhUYJoX48mKijbz-cm3jRbb8p2VU5tTQ8mONZP_P7xAvEfHOJf_JzzvmBACyuyRKbr8KktQMFpCsOy34k0wAvsICpNcfmPkGJ9VCDU13e9PYXbIbZ/file&quot;&gt;Baqaee and Farhi&lt;/a&gt;, or the papers I linked above to dig into the generality or non-generality of that Theorem.&lt;/p&gt;

&lt;h3 id=&quot;the-demand-side-in-words&quot;&gt;The demand side in words&lt;/h3&gt;
&lt;p&gt;Thinking through the supply side was just half the problem. And to be honest, I’m not sure that for the specifics of the corona-virus we should be thinking in terms of productivity shocks. Restaurants did not suddenly forgot how to cook when people got sick. This was more about significant changes in demand, whether those were chosen by individuals or ordered by governments.&lt;/p&gt;

&lt;p&gt;With this baseline model, think about a change in the share of their spending that people choose to do on the products of different industries. So everyone decides to decrease the fraction of their spending they want to do on industry B (e.g. restaurant meals) and increase the spending they want to do on industry A (insert toilet paper joke here). What affect does this change in the composition of demand have on an economy where A and B &lt;em&gt;and C&lt;/em&gt; are linked through the I/O table?&lt;/p&gt;

&lt;p&gt;In short, what is going to matter is how this change in demand changes the Domar weights. Those weights, recall, are based not only on the I/O relationships which capture intermediate use but also depend on final demand for products. Our change in what final consumers want to spend their money on is going to change the Domar weights.&lt;/p&gt;

&lt;p&gt;This could be good or it could be bad for aggregate output, in theory. If industry A is not a big user of intermediate goods for whatever reason, but industry B is a big user of intermediate goods, then this shift in spending could be very &lt;em&gt;bad&lt;/em&gt; for aggregate output. Why? If we decide to spend all of our money on products from industry A this creates very little “upstream” demand for intermediates from other industries, which limits their economic activity. When we spend more on industry A we’re going to push up it’s Domar weight, but not by very much.&lt;/p&gt;

&lt;p&gt;The drop in spending on industry B reduces its Domar weight directly. But because this industry uses a lot of intermediates that reduces even further the upstream demand by industry B from other industries, reducing B’s Domar weight further. And don’t forget industry C, who is standing there trying to act like nothing is happening. It’s Domar weight will be pulled down to some extent because of the change in demand for its products by both A and B (and that will feed back to the Domar weights of A and B).&lt;/p&gt;

&lt;p&gt;If industry A does not have a lot of upstream demand then the increase in its Domar weight is going to be &lt;em&gt;more&lt;/em&gt; than offset by the drop in the Domar weights of B and C. Remember from above how the Domar weights could sum to a number more than one? Here, the shift of spending from B to A is going to lower that &lt;em&gt;sum&lt;/em&gt;. And &lt;em&gt;maybe&lt;/em&gt; that will lower aggregate economic activity.&lt;/p&gt;

&lt;p&gt;Why maybe? With the demand shift we have to consider the &lt;em&gt;level&lt;/em&gt; of productivity across industries and how that interacts with the change in Domar weights. Yes, shifting spending to industry A from industry B may lower the sum of the Domar weights. But if the level of productivity in industry A is very high and productivity in B and C is very low then deciding to spend more money on A would be good for aggregate output.&lt;/p&gt;

&lt;p&gt;The ultimate effect of a demand shock from the virus will depend on (1) which industries our spending shifts into and (2) whether those industries have relatively high or low productivity.&lt;/p&gt;

&lt;p&gt;Notice that the effect of demand shocks in this baseline model are all about the “upstream” connections of an industry to its suppliers. The productivity shocks were all about the “downstream” connections of an industry to its customers. It’s not true that the distinction is that clean. Demand shocks can have upstream and downstream effects, as can productivity shocks. But in this baseline version things separate out cleanly. That said, &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/21344.html&quot;&gt;Acemoglu, Akcigit, and Kerr&lt;/a&gt; find evidence that shocks do tend to propagate this way. So the baseline model is not a terrible first pass.&lt;/p&gt;

&lt;h3 id=&quot;were-not-done-yet&quot;&gt;We’re not done yet&lt;/h3&gt;
&lt;p&gt;The big missing link here is that the baseline model is built on the assumption that the labor and capital supplies are held constant. And that is obviously not what we’re seeing in the short-run response to the coronavirus, where layoffs and firings are proceeding at a staggering pace. What comes next in figuring this out is shutting down the ability of labor to shift freely between industries, so that the productivity and/or demand shocks that hit the economy lead to labor being unemployed. Then the I/O network is going to tell us how the demand shock that is killing restaurants, for example, not only leads to unemployment in that industry, but propagates to unemployment in other industries that supply it. But I still need to figure that out, so stay tuned.&lt;/p&gt;
</description>
        <pubDate>Sat, 21 Mar 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Economic impacts of the coronavirus - part 1/n(?)</title>
        <link>http://localhost:4000/feed/2020/03/16/IO-Tables.html</link>
        <guid isPermaLink="true">http://localhost:4000/feed/2020/03/16/IO-Tables.html</guid>
        <description>&lt;p&gt;I’m washing my hands, avoiding crowds (even more than normal), and thinking about the economic effects of the coronavirus. There is no question there has already been a significant effect, and there will be more effects to come. I’m thinking about what those effects are, how they are distributed across industries (e.g. airlines versus trucking), and how the affected industries influence &lt;em&gt;other&lt;/em&gt; industries and consumers.&lt;/p&gt;

&lt;p&gt;I think this is going to take a few posts, as I don’t have a solid feel for how to do this. And this is going to start theoretically before I (hopefully) get to putting some numbers on things. If you’re interested in some kind of real-time estimate of the effect on GDP and the stock market, this is very much &lt;em&gt;not&lt;/em&gt; the blog for you.&lt;/p&gt;

&lt;p&gt;Let’s get some definitions out of the way. We talk a lot about GDP ($Y$), which is the value of all &lt;em&gt;final&lt;/em&gt; goods and services produced in a year (or quarter, or whatever time frame). But many, many transactions are for &lt;em&gt;intermediate&lt;/em&gt; goods and services. Those intermediates are purchased by one firm from another in order to produce something else. The classic example here would be a bakery buying wheat (the intermediate good) from a farmer in order to sell bread (the final good). GDP only measures the value of the bread produced. &lt;em&gt;Gross output&lt;/em&gt; ($Q$) would measure the value of the bread &lt;em&gt;and&lt;/em&gt; the value of the wheat.&lt;/p&gt;

&lt;p&gt;The distinction between gross output and GDP, by itself, doesn’t tell us anything about the effects of the coronavirus. But it does remind us that final goods depend on the production of intermediate goods, and so anything that disrupts the production of those intermediates will affect GDP even if nothing directly impacts our demand for those final goods and services. To trace the impact of the shocks from the coronavirus we need to understand the input/output (I/O) relationships linking producers of final goods and services to producers of intermediates.&lt;/p&gt;

&lt;p&gt;Let’s think through some ways the virus would influence the economy in our toy farmer/baker example. If everyone stays home and cooks their own food, then demand for bread falls. The baker will sell less, demand less wheat, and in turn the farmer will suffer a loss of sales. We can use the I/O relationships to tell us how a shock to final demand influences intermediate producers.&lt;/p&gt;

&lt;p&gt;On the other hand, we could have a situation where the farmer gets the virus, say, and cannot work. Then this lowers the amount of wheat produced and hence the baker cannot make as much bread. Here the I/O relationships tell us how a shock to an intermediate producer influences the production of final goods and services.&lt;/p&gt;

&lt;p&gt;Of course both of these shocks are possible, and in reality both kinds of shocks are occurring. To get my head around how big of an impact those shocks could have, I want to build up the math behind the structure of these I/O relationships. This is going to be math-heavy relative to most posts, ultimately reaching matrix algebra. I’m sorry, I don’t know any other way to talk about this stuff. I’m adapting this from notes I’ve used in the past for a grad course. I have tried to keep in some simplified examples of what I’m doing, but it can get a little hairy.&lt;/p&gt;

&lt;h3 id=&quot;the-leontief-inverse&quot;&gt;The Leontief inverse&lt;/h3&gt;
&lt;p&gt;The connection of GDP ($Y$) to gross output ($Q$) depends on the input/output relationships of all the different units of production. Input/output refers to the fact that some of the output of one unit of production ($i$) is used as an input by another unit of production ($j$). As noted, those intermediate transactions are not part of GDP. But they do determine how much gross output is necessary to produce a given amount of GDP.&lt;/p&gt;

&lt;p&gt;Let’s set up a simple example. Consider an oil drilling company that produces barrels of oil. The barrels are used by a refining company that uses them to produce gasoline. But it is also the case that the oil drilling company needs to buy gasoline in order to run their equipment. In addition, there are consumers who have final demand for gasoline, but there is no final demand for oil (i.e. no one consumes oil directly). This is more complex than the wheat/bread example, as the two industries serve as intermediate good providers for each other. But that is something we want to allow for, as most industries are going to operate both as a user and provider of intermediate goods.&lt;/p&gt;

&lt;p&gt;Let’s say that 100 barrels of oil can produce 1,000 gallons of gasoline. And let’s say that consumers demand 1,000 gallons of gasoline. But it is &lt;em&gt;also&lt;/em&gt; the case that it takes 50 gallons of gasoline to produce 100 barrels of oil. So how much oil production is there? To get 1,000 final gallons of gasoline, we need 100 barrels of oil produced. But that requires an additional 50 gallons of gas, which requires an additional 5 barrels of oil. But that 5 additional barrels of oil requires 2.5 gallons of gas, which requires and additional 0.25 barrels of oil. And so on and so on.&lt;/p&gt;

&lt;p&gt;We can construct this interaction in a little system of equations.&lt;/p&gt;

\[\begin{aligned}
	y_B &amp;amp;= 0.1\times y_G + 0 \\
	y_G &amp;amp;= 0.5\times y_B + 1,000
\end{aligned}\]

&lt;p&gt;where $y_B$ are barrels produced, which are equal to one-tenth of the total gallons of gas produced, as that is the demand from the refinery. The zero in the first line represents the fact that there is zero final demand for oil (no one uses oil directly, it is only an intermediate good here). The second line shows that the total gallons of gas produced are equal to one-half the number of barrels produced (that is the demand from oil producers) plus the 1,000 gallons demanded by final consumers. This is just a two-equation, two-unknown situation. It can be solved to find $y_B = 105.26$ is the gross output of the oil drilling company, and $y_G = 1,052.63$ is the gross output of the refinery. That 1,000 gallons of final demand for gas leads to an extra 52-ish gallons produced, along with 105-ish barrels of oil as intermediate good.&lt;/p&gt;

&lt;p&gt;This same logic can be extended to the case of $J$ arbitrary units of production. Ultimately we’d have a $J$ equation system, with $J$ unknown gross outputs of $p_j y_j$, taking the final demands $p_j c_j$ of each unit as given. This is tedious, but it is a straightforward linear algebra problem, and can be set up in matrix form. The only difference with the little example of oil and gas is that here we’re going to use values (i.e. with relative prices included) rather than raw quantities.&lt;/p&gt;

\[\begin{aligned}
	p_1 y_1 &amp;amp;= p_1 y_{11} + p_1 y_{21} + ... + p_1 y_{J1} + p_1 c_1 \\
	p_2 y_2 &amp;amp;= p_2 y_{12} + p_2 y_{22} + ... + p_2 y_{J2} + p_2 c_2 \\
	 &amp;amp;...&amp;amp; \\
	p_J y_J &amp;amp;= p_J y_{1J} + p_J y_{2J} + ... + p_J y_{JJ} + p_J c_J \\ 
\end{aligned}\]

&lt;p&gt;where recall that $p_i y_{ji}$ is the intermediate demand by unit $j$ for output from unit $i$. Depending on the level of analysis you are working with - establishment, firm, sector - you might be able to assert that $y_{ii} = 0$. But we don’t have to assume this. It is okay if we think of units of production purchasing their own output to use as an intermediate good. Think of a refinery buying its own gas to run its own trucks and equipment. Now we can simplify this by building it into matrix form.&lt;/p&gt;

&lt;p&gt;Define the matrices as follows&lt;/p&gt;

\[\mathbf{q} = 
	\begin{bmatrix}
	p_1 y_1 \\
	p_2 y_2 \\
	... \\
	p_J y_J
	\end{bmatrix}
\mathbf{c} = 
	\begin{bmatrix}
	p_1 c_1 \\
	p_2 c_2 \\
	... \\
	p_J c_J
	\end{bmatrix}
\mathbf{A} = 
	\begin{bmatrix}
	\frac{p_1 y_{11}}{p_1 y_1} &amp;amp; ... &amp;amp; \frac{p_1 y_{J1}}{p_J y_J} \\
	\frac{p_2 y_{12}}{p_1 y_1} &amp;amp; ... &amp;amp; \frac{p_2 y_{J2}}{p_J y_J} \\
	... &amp;amp; \ddots &amp;amp; ... \\
	\frac{p_J y_{1J}}{p_1 y_1} &amp;amp; ... &amp;amp; \frac{p_J y_{JJ}}{p_J y_J} \\
	\end{bmatrix}\]

&lt;p&gt;The vector $q$ captures the gross output of each unit, the vector $c$ the final demand for each units output. The matrix $A$ is called a “technical coefficients” matrix. The raw data for these matrices come from something called a “use table”, which are part of input/output accounts produced by statistical agencies. I’ll probably go through one of those in a future post.&lt;/p&gt;

&lt;p&gt;$A$ tells us how much of each intermediate good is necessary to produce one (real) dollar of additional output from a given unit of production. It takes $p_2 y_{12}/p_1 y_1$ in purchases of intermediate good 2 to produce one real dollar of output of good 1, for example. $A$ thus tells us the “recipe” for producing gross output.&lt;/p&gt;

&lt;p&gt;With these matrices, we can simplify our system of equations down to&lt;/p&gt;

\[\mathbf{q} = \mathbf{A}\mathbf{q} + \mathbf{c},\]

&lt;p&gt;and solve this using normal matrix operations,&lt;/p&gt;

\[(\mathbf{I} - \mathbf{A})\mathbf{q}  = \mathbf{c}\]

&lt;p&gt;where $\mathbf{I}$ is an identity matrix, and so&lt;/p&gt;

\[\mathbf{q} = (\mathbf{I} - \mathbf{A})^{-1}\mathbf{c}.\]

&lt;p&gt;This is the matrix equivalent of our earlier example with the barrels and gas. The $(\mathbf{I} - \mathbf{A})^{-1}$ matrix is a Leontief inverse”. It isn’t obvious here, but this Leontief inverse summarizes all of the direct and indirect effects of final demand for $c$ on gross output $q$.&lt;/p&gt;

&lt;p&gt;To see what is going on, go back to the simple example involving barrels and gasoline. Write the matrix form of this as&lt;/p&gt;

\[\begin{bmatrix}
	y_B \\
	y_G
	\end{bmatrix}
=
	\begin{bmatrix}
	0 &amp;amp; 0.1 \\
	0.5 &amp;amp; 0 \\
	\end{bmatrix}
	\begin{bmatrix}
	y_B \\
	y_G
	\end{bmatrix}
+
	\begin{bmatrix}
	c_B \\
	c_G
	\end{bmatrix}\]

&lt;p&gt;where I’ve allowed both oil, $c_B$, and gas, $c_G$, to have some final demand. Our general setting says that we should form the Leontief inverse first, which in this case is&lt;/p&gt;

\[(\mathbf{I} - \mathbf{A})^{-1} =
	\begin{bmatrix}
	1.052 &amp;amp; 0.105 \\
	0.526 &amp;amp; 1.052 \\
	\end{bmatrix}.\]

&lt;p&gt;The entries in this table tell us the total effect of final demand, whatever that may be. For example, the upper right entry (0.105) tells us that every additional gallon of gas demanded induces 0.105 barrels of oil to be produced. We know that technically, only 0.1 barrels are necessary, but an extra 0.005 are produced because oil production requires some gasoline itself. The bottom left entry says that every additional barrel of oil demanded (if anyone wanted oil as a final good) would lead to 0.526 gallons of gas being produced, 0.5 because it takes that much gas to produce a barrel, and an additional 0.026 because that gas requires some oil itself.&lt;/p&gt;

&lt;p&gt;Given that Leontief inverse, we know that&lt;/p&gt;

\[\begin{bmatrix}
	y_B \\
	y_G
	\end{bmatrix}
=
\begin{bmatrix}
	1.052 &amp;amp; 0.105 \\
	0.526 &amp;amp; 1.052 \\
	\end{bmatrix}
\begin{bmatrix}
	c_B \\
	c_G
	\end{bmatrix}.\]

&lt;h3 id=&quot;accounting-for-shocks&quot;&gt;Accounting for shocks&lt;/h3&gt;
&lt;p&gt;Note that just knowing the matrix $\mathbf{A}$, and thus the Leontief inverse, doesn’t tell us how big GDP or gross output will be. It only allows us to solve for the relationship of gross output and GDP. Determining actual GDP or gross output would still depend on things like the supply of factors of production (e.g. labor, capital), the productivity of individual units of production, and the preferences of people involved. Nevertheless, this structure is still useful because it gives us the basis for understanding how to account for the interactions of different units of production.&lt;/p&gt;

&lt;p&gt;Ignoring all those other relevant factors (preferences, productivity, factor supply), let’s see a little of what we can do with the Leontief matrix.&lt;/p&gt;

&lt;p&gt;Let’s say that prior to the virus that final use of oil was $c_B = 100$ and final use of gasoline was $c_G = 1000$, and treating these as measured in real values, that means GDP was 1,100. Gross output (again in real values) of oil was $y_B = 210.2$ and of gasoline was $y_G = 1104.6$, for total gross output of 1314.8.&lt;/p&gt;

&lt;p&gt;If the virus meant a shock to demand for gasoline because we all stayed home to watch Netflix, we can work out the impacts. Let’s say that now $c_G = 500$, but that demand for oil stays the same at $c_B = 100$. This drops GDP to 600. But it also drops gross output to $y_B = 157.7$ and $y_G = 578.6$, for a total drop to gross output of 736.3. Because of the drop in gasoline demand, oil production overall falls from 210.2 to 157.7. A full analysis would account for whether there was any impact on final demand for oil due to the virus, whether the drop in gross output in the oil industry or gasoline industry led people to get fired and hence to even lower final demand, and so on and so on.&lt;/p&gt;

&lt;p&gt;We can make this harder. What if the virus means a drop in the production of oil, say because the virus gets loose on a drilling rig in the Gulf? Let’s say that total production of oil is forced to drop from 210.2 to $y_B = 100$. What happens? We have to solve this for the level of final demand such that the gross output of oil is only 100. We’re going to have to scale down everything in order to accommodate that drop in oil production. But how? There are a lot of solutions to this system such that $y_B = 100$, and nothing in the Leontief inverse itself pins down exactly which solution we’d end up at. One &lt;em&gt;possible&lt;/em&gt; answer is that we have $c_B = 0$ and $c_G = 950$, so that the 100 barrels of oil are used solely to provide final consumption of gasoline, but there is no oil left over for final use. Or, we could have $c_B = 20$ and $c_G = 750$ if people really, really want to consume some oil directly.&lt;/p&gt;

&lt;p&gt;The point is that we’re going to have to account for people’s spending preferences as well in order to parse out the shocks. Which is why this is probably going to take me a long time and a few posts to figure out how to think about this right. For now, let’s pretend that I’ll be all over that project, and you’ll see more information over the next few days.&lt;/p&gt;

&lt;p&gt;Until then, wash your hands and stay the f&amp;amp;#@ home.&lt;/p&gt;

</description>
        <pubDate>Mon, 16 Mar 2020 00:00:00 -0500</pubDate>
      </item>
    
  </channel>
</rss>
